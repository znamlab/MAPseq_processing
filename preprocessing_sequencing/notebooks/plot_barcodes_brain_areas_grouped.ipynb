{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf7bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "#from matplotlib import rcParam\n",
    "import seaborn as sb\n",
    "import os\n",
    "import sys\n",
    "sys.setrecursionlimit(1000000)\n",
    "from scipy.stats import spearmanr\n",
    "import pathlib\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "mcc = MouseConnectivityCache()\n",
    "from scipy.stats import pearsonr\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "#for_binary_barcode_path = pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/Sequencing/Processed_data/UpdatedApril/preprocessed_seq/Final_processed_sequences/filtered_barcode_matrix_for_binary_junk_test.pkl')\n",
    "#normalised_barcode_path_junk_test = pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/Sequencing/Processed_data/UpdatedApril/preprocessed_seq/Final_processed_sequences/barcode_matrix_normalised_junk_test.pkl')\n",
    "normalised_barcode_path= pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/Sequencing/Processed_data/UpdatedApril/preprocessed_seq_corrected/Final_processed_sequences/barcode_matrix_normalised.pkl')\n",
    "lcm_reg_dir = pathlib.PurePath('/nemo/lab/znamenskiyp/home/shared/code/MAPseq_processing/AC_MAPseq/Brain1_FIAA32.6a/LCM_registration')\n",
    "areas = pd.read_csv(lcm_reg_dir/'3d_areas.csv')\n",
    "RTtosample = pd.read_csv(lcm_reg_dir/'RTprimer_tosample.csv')\n",
    "areas = areas.merge(RTtosample, how='inner', on='sample')\n",
    "areas.sort_values(\"RT_primer\", inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e8653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load barcodes, and drop samples that have been qc'd out\n",
    "barcodes_across_sample = pd.read_pickle(normalised_barcode_path)\n",
    "\n",
    "areas =areas[areas['RT_primer'].isin(barcodes_across_sample.columns)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24a6c639",
   "metadata": {},
   "source": [
    "What is the conditional probability of co-projection between samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9e531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "barcodes_matrix = pd.read_pickle(normalised_barcode_path)\n",
    "columns = barcodes_matrix.columns.tolist()\n",
    "#conditional_prob = pd.DataFrame(columns=['A', 'B', 'conditional_probability'])\n",
    "i = 0\n",
    "for col_a, col_b in itertools.combinations(columns, 2):\n",
    "    prob_df = pd.DataFrame()\n",
    "    prob_df['a'] = barcodes_matrix[col_a].astype(bool)\n",
    "    prob_df['b'] = barcodes_matrix[col_b].astype(bool)\n",
    "    prob_df['matching'] = prob_df.sum(axis=1)\n",
    "    probability_b_a = len(prob_df[prob_df['matching']==2])/prob_df['a'].sum()\n",
    "    probability_a_b = len(prob_df[prob_df['matching']==2])/prob_df['b'].sum()\n",
    "    temp = pd.DataFrame({'A': col_a, 'B': col_b, 'conditional_probability_b_to_a': probability_b_a, 'conditional_probability_a_to_b': probability_a_b}, index=[0])\n",
    "    if i == 0:\n",
    "        conditional_prob = temp\n",
    "    else:\n",
    "        conditional_prob =pd.concat([conditional_prob, temp])\n",
    "    i = i+1\n",
    "    \n",
    "heatmap_df = np.zeros(shape=((len(columns), (len(columns)))))\n",
    "heatmap_df_matrix = pd.DataFrame(data= heatmap_df, columns=columns, index=columns).replace(0, np.nan)\n",
    "\n",
    "for i, r in conditional_prob.iterrows():\n",
    "    heatmap_df_matrix.loc[r['B'], r['A']] = r['conditional_probability_b_to_a']\n",
    "    heatmap_df_matrix.loc[r['A'], r['B']] = r['conditional_probability_a_to_b']\n",
    "\n",
    "\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 15\n",
    "sb.heatmap(heatmap_df_matrix, xticklabels=True, yticklabels=True, cmap =\"viridis\",  cbar_kws={'label': 'P B|A', \"shrink\": 0.4})\n",
    "plt.title('Conditional Probabilities of Shared Barcodes Across All Samples')\n",
    "plt.xlabel('Sample A')\n",
    "plt.ylabel('Sample B')\n",
    "#ax.set(xlabel=\"\", ylabel=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditional probabilities of co-projection between cortical areas\n",
    "cortical_areas =[6, 7, 10, 11, 12, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 59, 60, 61, 62, 63, 64, 65, 70, 80, 81, 82, 83, 84]\n",
    "cortical_areas_adj = list(filter(lambda x: x in barcodes_matrix.columns, cortical_areas))\n",
    "i = 0\n",
    "for col_a, col_b in itertools.combinations(cortical_areas_adj, 2):\n",
    "    prob_df = pd.DataFrame()\n",
    "    prob_df['a'] = barcodes_matrix[col_a].astype(bool)\n",
    "    prob_df['b'] = barcodes_matrix[col_b].astype(bool)\n",
    "    prob_df['matching'] = prob_df.sum(axis=1)\n",
    "    probability_b_a = len(prob_df[prob_df['matching']==2])/prob_df['a'].sum()\n",
    "    probability_a_b = len(prob_df[prob_df['matching']==2])/prob_df['b'].sum()\n",
    "    temp = pd.DataFrame({'A': col_a, 'B': col_b, 'conditional_probability_b_to_a': probability_b_a, 'conditional_probability_a_to_b': probability_a_b}, index=[0])\n",
    "    if i == 0:\n",
    "        conditional_prob = temp\n",
    "    else:\n",
    "        conditional_prob =pd.concat([conditional_prob, temp])\n",
    "    i = i+1\n",
    "    \n",
    "heatmap_df = np.zeros(shape=((len(cortical_areas_adj), (len(cortical_areas_adj)))))\n",
    "heatmap_df_matrix = pd.DataFrame(data= heatmap_df, columns=cortical_areas_adj, index=cortical_areas_adj)\n",
    "heatmap_df_matrix = heatmap_df_matrix.replace(0, np.nan)\n",
    "\n",
    "for i, r in conditional_prob.iterrows():\n",
    "    heatmap_df_matrix.loc[r['B'], r['A']] = r['conditional_probability_b_to_a']\n",
    "    heatmap_df_matrix.loc[r['A'], r['B']] = r['conditional_probability_a_to_b']\n",
    "\n",
    "\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "sb.heatmap(heatmap_df_matrix, xticklabels=True, yticklabels=True, cmap =\"viridis\",  cbar_kws={'label': 'P B|A', \"shrink\": 0.4})\n",
    "plt.title('Conditional Probabilities of Shared Barcodes Across Cortical Samples')\n",
    "plt.xlabel('Sample A')\n",
    "plt.yticks(rotation=0)\n",
    "plt.ylabel('Sample B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4105ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = barcodes_across_sample.columns.tolist()\n",
    "\n",
    "correlations = {}\n",
    "for col_a, col_b in itertools.combinations(columns, 2):\n",
    "    correlations[f\"{col_a}\" + '__' + f\"{col_b}\"] = pearsonr(barcodes_across_sample.loc[:, col_a], barcodes_across_sample.loc[:, col_b])\n",
    "\n",
    "result = pd.DataFrame.from_dict(correlations, orient='index')\n",
    "result.columns = ['PCC', 'p-value']\n",
    "\n",
    "print(result.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb760d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033da26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sb.clustermap(barcodes_across_sample, metric='canberra', standard_scale=0, norm=LogNorm(), cmap=\"Blues\", figsize=(20, 10), yticklabels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd6b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what about just cortex\n",
    "#no_source = barcodes_across_sample.drop([36, 64, 37, 52, 50, 42, 51, 65], axis=1)\n",
    "cortex_only = barcodes_across_sample[cortical_areas_adj]\n",
    "for column in cortex_only.columns:\n",
    "    if cortex_only[column].sum() == 0:\n",
    "        cortex_only.drop([column], axis=1, inplace=True)\n",
    "cortex_only = cortex_only.loc[~(cortex_only==0).all(axis=1)]\n",
    "sb.clustermap(cortex_only, metric='canberra', standard_scale=0, norm=LogNorm(), cmap=\"Blues\", figsize=(20, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0676adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_areas_fractions = pd.DataFrame(index=barcodes_across_sample.columns)\n",
    "all_areas_fractions['name'] = 'string'\n",
    "areas_to_look = areas.drop('sample', axis=1).set_index('RT_primer')\n",
    "for i, row in areas_to_look.iterrows():\n",
    "    row /= row.sum(0)\n",
    "    \n",
    "    if row[row.idxmax()]>0.9999:\n",
    "        name= str(row.idxmax()) + ' ' + str(row[row.idxmax()].round(2))\n",
    "    else:\n",
    "        second_highest_row = row.drop(row.idxmax())\n",
    "        name= str(row.idxmax()) + ' ' + str(row[row.idxmax()].round(2)) + ' ' + str(second_highest_row.idxmax()) + ' ' + str(row[second_highest_row.idxmax()].round(2))\n",
    "    all_areas_fractions.loc[i] = name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac02b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_across_sample_renamed = barcodes_across_sample.copy()\n",
    "\n",
    "barcodes_across_sample_renamed.columns = all_areas_fractions['name'].tolist()\n",
    "barcodes_across_sample_renamed =barcodes_across_sample_renamed.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5308d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.clustermap(barcodes_across_sample_renamed, metric='canberra', standard_scale=0, norm=LogNorm(), cmap=\"PuBuGn\", figsize=(20, 10), yticklabels=False, cbar_pos=(1.01, 0.5, 0.02, 0.18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f25c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = barcodes_across_sample_renamed.corr()\n",
    "plt.figure(figsize=(30,20))\n",
    "mask = np.zeros_like(matrix, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#_ = sb.heatmap(matrix, center=0, annot=True, \n",
    " #               fmt='.2f', square=True, cmap='coolwarm')\n",
    "sb.clustermap(matrix, cmap='PuBuGn', yticklabels=True, xticklabels=True,  cbar_kws={'label': 'pearson r', \"shrink\": 0.4}, cbar_pos=(1.01, 0.5, 0.02, 0.18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9973d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sb.clustermap(matrix, metric='euclidean', cmap=\"PuBuGn\", figsize=(10, 10), xticklabels=True, yticklabels=True, cbar_pos=(1.01, 0.5, 0.02, 0.18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da90516",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cortex = ['CP 0.95 fa 0.01', 'AId 0.33 CLA 0.23', 'Contra-SSp-tr 0.87 Contra-SSp-ll 0.11', 'CP 0.92 LA 0.06', 'Contra-SSs 0.62 Contra-AUDd 0.19', 'Contra-VISa 0.52 Contra-SSp-tr 0.38', 'Contra-AUDv 0.43 Contra-or 0.2', 'LP 0.42 SGN 0.23', 'POL 0.35 PoT 0.28', 'POL 0.64 TH 0.21', 'MGv 0.59 MGd 0.29', 'PG 0.84 P 0.08', 'ICe 0.47 MB 0.22', 'ICc 0.51 ICe 0.27', 'ICc 0.4 ICd 0.25', 'SCiw 0.69 SCig 0.21', 'SCsg 0.54 SCop 0.31']\n",
    "cortex_only_matrix = matrix.drop(non_cortex, axis=0)\n",
    "cortex_only_matrix = cortex_only_matrix.drop(non_cortex, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b7ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sb.clustermap(cortex_only_matrix, metric='canberra', cmap=\"PuBuGn\", figsize=(10, 10), xticklabels=True, yticklabels=True, cbar_pos=(1.01, 0.5, 0.02, 0.18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a806ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_dir = pathlib.Path('/nemo/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/LCM_registration/allenccf/allen_ccf_coord')\n",
    "ROI_path = pathlib.Path('/nemo/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/LCM_registration/rois')\n",
    "ROI_table = pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/LCM_registration/allenccf/ROI_vol.pkl')\n",
    "ROI_vol = pd.read_pickle(ROI_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe043923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nrrd\n",
    "anno_path = reg_dir.parents[1]/'reference/annotation_25.nrrd'\n",
    "allenanno = nrrd.read(anno_path)\n",
    "allenanno = np.array(allenanno)\n",
    "annotation = allenanno[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53625f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#re-get registration info on each ROI\n",
    "#iterate through individual slices, take average difference in in coordinates in z (which is x axes in allen ccf) for last slice (slice s001 for brain 1), take average of previous slices\n",
    "add_z = pd.DataFrame(columns=['slice', 'amountz'], dtype=int)\n",
    "#need to change for mega thick last bit of cortex section, so extend ROI through 3slices\n",
    "for file in os.listdir(reg_dir):\n",
    "    if file.startswith('allen_ccf_converted_'):\n",
    "        slice_name = file[20:24]\n",
    "        slicenum = int(file[21:24])\n",
    "        if slice_name != 's001' and slice_name != 's012' and slice_name != 's048' and slice_name != 's053':\n",
    "            slice_before= slicenum-1\n",
    "            if slice_before >9:\n",
    "                slicebefore_name = f's0{slice_before}' \n",
    "            if slice_before<10:\n",
    "                slicebefore_name = f's00{slice_before}' \n",
    "            [x1a, y1a, z1a, one1] = np.load(reg_dir/file)\n",
    "            [x2a, y2a, z2a, one2] = np.load(reg_dir/f'allen_ccf_converted_{slicebefore_name}.npy')\n",
    "            dif = np.average(x2a.flatten()-x1a.flatten())\n",
    "            add_z= add_z.append({'slice': slice_name, 'amountz': dif},ignore_index=True)\n",
    "#for slices where the one's before are missing, extend them by the mean of slice z extensions for the others\n",
    "s001_add =add_z['amountz'].mean()\n",
    "add_z= add_z.append({'slice': 's001', 'amountz': s001_add},ignore_index=True)\n",
    "s012_add =add_z['amountz'].mean()\n",
    "add_z= add_z.append({'slice': 's012', 'amountz': s012_add},ignore_index=True)\n",
    "s048_add =add_z['amountz'].mean()\n",
    "add_z= add_z.append({'slice': 's048', 'amountz': s048_add},ignore_index=True)\n",
    "s053_add =add_z['amountz'].mean()\n",
    "add_z= add_z.append({'slice': 's053', 'amountz': s053_add},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ad8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_vol = pd.DataFrame()\n",
    "for region in os.listdir(ROI_path):\n",
    "    if region.startswith(\"s0\"):\n",
    "        slicename = region[0:4]\n",
    "        tube = region[5:len(region)].split('TUBE', 1)[1]\n",
    "        tube =tube[:-4]\n",
    "        converted_slice = reg_dir/ f'allen_ccf_converted_{slicename}.npy'\n",
    "        [xa, ya, za, one] = np.load(converted_slice)\n",
    "        roi_path = ROI_path / f'{region}'\n",
    "        roi = plt.imread(roi_path)\n",
    "        allencoord_roiya = roi*ya\n",
    "        allencoord_roiza = roi*za\n",
    "        z_axis =roi*xa\n",
    "        z_axis[z_axis == 0] = np.nan\n",
    "        most_anterior = np.nanmin(z_axis)\n",
    "#iterate image by z slices, each additional z, annotate then add to list\n",
    "        z_to_add = add_z.loc[add_z['slice'] == slicename, 'amountz'].iloc[0]\n",
    "        most_posterior = np.nanmax(z_axis) - z_to_add\n",
    "        \n",
    "        ROI_vol= ROI_vol.append({'slice': slicename, 'tube': tube, 'z_added': z_to_add, 'most_anterior': most_anterior, 'most_posterior': most_posterior},ignore_index=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf09b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ROI_vol.groupby(['tube']).agg(', '.join).reset_index()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['most_anterior'] = \"\"\n",
    "result['most_posterior'] =\"\"\n",
    "result['RT_primer'] = \"\"\n",
    "for i, row in result.iterrows():\n",
    "    result.loc[i]['most_anterior'] = ROI_vol[ROI_vol['tube'] ==row['tube']].most_anterior.min(axis=0)\n",
    "    result.loc[i]['most_posterior'] = ROI_vol[ROI_vol['tube'] ==row['tube']].most_posterior.max(axis=0)\n",
    "    if pd.isnull(RTtosample[RTtosample['sample']==int(row['tube'])].RT_primer).all() == False:\n",
    "        result.loc[i]['RT_primer'] = int(RTtosample[RTtosample['sample']==int(row['tube'])].RT_primer.values)\n",
    "    else:\n",
    "        result.loc[i]['RT_primer'] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daea8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result =result[result['RT_primer'].isin(barcodes_across_sample.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ed20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['fraction_name'] = \"\"\n",
    "for i, row in result.iterrows():\n",
    "    result.loc[i]['fraction_name'] = all_areas_fractions.loc[int(row['RT_primer'])]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.sort_values(by=['most_anterior'])\n",
    "result = result.set_index('RT_primer')\n",
    "anterior_pos_sorted = result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_across_sample_AP_sorted = barcodes_across_sample[anterior_pos_sorted.columns]\n",
    "\n",
    "barcodes_across_sample_AP_sorted.columns = result.fraction_name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d8aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = barcodes_across_sample_AP_sorted.corr()\n",
    "plt.figure(figsize=(30,20))\n",
    "mask = np.zeros_like(matrix, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_ = sb.heatmap(matrix, cmap='PuBuGn', cbar_kws={'label': 'pearson r', \"shrink\": 0.4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc2278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at conditional probability ordered in AP axis\n",
    "heatmap_df_matrix_AP_sorted = heatmap_df_matrix[anterior_pos_sorted.columns]\n",
    "heatmap_df_matrix_AP_sorted.columns = result.fraction_name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e8204",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_df_matrix_AP_sorted = heatmap_df_matrix_AP_sorted.T\n",
    "heatmap_df_matrix_AP_sorted = heatmap_df_matrix_AP_sorted[anterior_pos_sorted.columns]\n",
    "heatmap_df_matrix_AP_sorted.columns = result.fraction_name.to_list()\n",
    "heatmap_df_matrix_AP_sorted= heatmap_df_matrix_AP_sorted.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0befae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.heatmap(heatmap_df_matrix_AP_sorted, cmap = 'PuBuGn',cbar_kws={'label': 'P B|A', \"shrink\": 0.4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = barcodes_across_sample_renamed.corr()\n",
    "plt.figure(figsize=(30,20))\n",
    "mask = np.zeros_like(matrix, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_ = sb.heatmap(matrix, center=0, annot=True, \n",
    "                fmt='.2f', square=True, cmap='coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1da50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas =areas.drop(['sample'], axis=1)\n",
    "areas =areas.set_index('RT_primer').sort_index()\n",
    "areas_matrix = areas.to_numpy()\n",
    "total_frac = np.sum(areas_matrix, axis=1)\n",
    "frac_matrix = areas_matrix/total_frac[:, np.newaxis]\n",
    "areasFrac = pd.DataFrame(frac_matrix, columns=areas.columns, index= areas.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_matrix = areas.to_numpy()\n",
    "total_frac = np.sum(areas_matrix, axis=1)\n",
    "frac_matrix = areas_matrix/total_frac[:, np.newaxis]\n",
    "areasFrac = pd.DataFrame(frac_matrix, columns=areas.columns, index= areas.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699fd4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "areasFrac[areasFrac['AUDp']>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a28d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in areasFrac.columns:\n",
    "    print(column, areasFrac.loc[36][column])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c4b4db",
   "metadata": {},
   "source": [
    "Manual annotation of subcortical structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaaa4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_to_add = {}\n",
    "regions_to_add['MG'] = [55, 66]\n",
    "regions_to_add['LP'] = [30, 39, 54]\n",
    "regions_to_add['POL'] = [44, 56, 67]\n",
    "regions_to_add['Rstr'] = [8, 13, 19]\n",
    "regions_to_add['CLA/Epc'] = [9, 14, 20, 25]\n",
    "regions_to_add['Cstr'] = [29]\n",
    "regions_to_add['SCs'] = [87, 68, 78, 92]\n",
    "regions_to_add['SCm'] = [69, 79, 93]\n",
    "regions_to_add['IC'] = [86, 89, 90]\n",
    "regions_to_add['pons'] = [72, 80, 88]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7eff52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k, v in regions_to_add.items():\n",
    "    if k not in areas.columns:\n",
    "        areas[k] = 0\n",
    "    for value in v:\n",
    "        area_of_interest = areas.loc[areas['sample'] == value]\n",
    "        new_val = area_of_interest.sum(axis=1)-(area_of_interest['RT_primer']+area_of_interest['sample'])\n",
    "        to_add = pd.DataFrame(columns=areas.columns)\n",
    "        to_add[k] = new_val\n",
    "        to_add['sample']= value\n",
    "        to_add['RT_primer'] = area_of_interest['RT_primer']\n",
    "        to_add =to_add.fillna(0)\n",
    "        areas = areas.drop(area_of_interest.index)\n",
    "        areas= pd.concat([areas, to_add])\n",
    "areas =areas.set_index('RT_primer').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7300209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6808b952",
   "metadata": {},
   "source": [
    "Grouping LCM sections according to broad areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8311ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_areas = {\n",
    "    'tectum': ['SCs', 'SCm', 'IC'],\n",
    "    #'tectum': ['SCdg', 'SCdw', 'SCig', 'SCiw', 'SCop', 'SCsg', 'SCzo', 'ICc', 'ICd', 'ICe', 'NB'],\n",
    "    'thalamus': ['PoT', 'TH', 'MGm', 'MGv', 'MGd', 'LGd-co', 'LP', 'POL', 'PO', 'LD', 'VPL', 'PIL', 'Eth'],\n",
    "    'SS': ['SSp-bfd', 'SSp-ll', 'SSp-m', 'SSp-n', 'SSp-tr', 'SSp-ul', 'SSp-un', 'SSs'],\n",
    "    'M': ['MOs', 'MOp'],\n",
    "    'contra': areas.filter(like=\"Contra\").columns,\n",
    "    #'AudC': ['Contra-AUDd', 'Contra-AUDp', 'Contra-AUDv'],\n",
    "    #'VisC': ['Contra-VISa', 'Contra-VISam'],\n",
    "    'VisIP': ['VISa', 'VISal', 'VISam', 'VISl', 'VISp', 'VISpm', 'VISpor', 'VISrl', 'VISli', 'VISpl'],\n",
    "    #'Rstr': ['CP', 'STR', 'ACB'],\n",
    "    #'pons': ['SOCm', 'SOCl', 'POR', 'PRNr', 'PRNc', 'TRN', 'P', 'P-mot', 'PG', 'NLL']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_grouped = areas.copy()\n",
    "for group, columns in group_areas.items():\n",
    "    areas_grouped[group] = areas_grouped.filter(items=columns).sum(axis=1)\n",
    "    areas_grouped = areas_grouped.drop(columns, axis=1)\n",
    "areas_only_grouped = areas_grouped.drop(['sample', 'ar', 'bic', 'bsc', 'ccb', 'ccb', 'ccg', 'cing', 'cpd', 'csc', 'cst', 'ec', 'fa', 'fi',\n",
    "    'fiber tracts', 'fp', 'll', 'mcp', 'ml', 'onl', 'or', 'py', 'root', 'sctv', 'scwm', 'tb', 'CTXsp', 'act', 'alv', 'amc', 'cic', 'VL', 'MRN'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3291008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#areas_comp = ['Cstr', 'tectum', 'thalamus', 'contra', 'pons']\n",
    "areas_comp = ['M', 'Cstr', 'Rstr', 'tectum', 'thalamus', 'contra', 'VisIP', 'SS']\n",
    "areas_only_grouped = areas_only_grouped[areas_comp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbddd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we're directly comparing co-projection between different areas, we will drop any assigned areas where two areas\n",
    "# are in the same sample (keeping only area as one that has most contained)\n",
    "for i, row in areas_only_grouped.iterrows():\n",
    "    if row.max()<row.sum():\n",
    "        max_val_col = areas_only_grouped.loc[i, (row == row.max())].index.tolist()[0]\n",
    "        max_val = row.max()\n",
    "        areas_only_grouped.loc[i] = 0\n",
    "        areas_only_grouped.loc[i][max_val_col] =max_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe of the fractions of each brain area contained within each sample\n",
    "areas_matrix = areas_only_grouped.to_numpy()\n",
    "total_frac = np.sum(areas_matrix, axis=1)\n",
    "frac_matrix = areas_matrix/total_frac[:, np.newaxis]\n",
    "areasFrac = pd.DataFrame(frac_matrix, columns=areas_only_grouped.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d72b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each barcode, create a matrix of BC count for regions in a sample based on amount of each region in LCM (makes assumption of equal BC distribution)\n",
    "bc_matrix = np.zeros(shape=((len(barcodes_across_sample), (len(areas_only_grouped.columns)))))\n",
    "bc_matrix = pd.DataFrame(data= bc_matrix, columns=areas_only_grouped.columns, index=barcodes_across_sample.index)\n",
    "for i, row in barcodes_across_sample.iterrows():\n",
    "    counts = row.to_numpy()\n",
    "    frac_counts = frac_matrix * counts[:, np.newaxis]\n",
    "    sample_counts = pd.DataFrame(frac_counts, columns=areas_only_grouped.columns)\n",
    "    bc_matrix.loc[i] = sample_counts.sum() / areas_only_grouped.sum()\n",
    "#remove any columns that are all zeros\n",
    "for column in bc_matrix.columns:\n",
    "    if bc_matrix[column].sum() == 0:\n",
    "        bc_matrix.drop([column], axis=1, inplace=True)\n",
    "bc_matrix = bc_matrix.loc[~(bc_matrix==0).all(axis=1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7668b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_vs_it = ['Cstr', 'tectum', 'thalamus', 'contra']\n",
    "striatum_proj = bc_matrix[bc_matrix['Cstr']>0]\n",
    "striatum_proj = striatum_proj[pt_vs_it]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73941ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "striatum_proj =striatum_proj.reset_index(drop=True)\n",
    "bc_matrix = bc_matrix.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b8266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform hierarchial clustering of all barcodes across samples\n",
    "#sb.clustermap(bc_matrix, metric='euclidean', standard_scale=0, norm=LogNorm(), cmap=\"Blues\", figsize=(10, 10))\n",
    "\n",
    "sb.clustermap(striatum_proj, metric='canberra', method='average', standard_scale=0, norm=LogNorm(), cmap=\"PuBuGn\", figsize=(3, 5), yticklabels=False, cbar_pos=(1.01, 0.5, 0.02, 0.18))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.clustermap(bc_matrix, metric='canberra', method='average', standard_scale=0, norm=LogNorm(), cmap=\"PuBuGn\", figsize=(3, 5), yticklabels=False, cbar_pos=(1.01, 0.5, 0.02, 0.18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4262afa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#upper = barcodes_across_sample[barcodes_across_sample.idxmax(axis=1).isin([49, 51, 40, 42])]\n",
    "#binary_barcodes = pd.read_pickle(no_barcode_path)\n",
    "upper_index = barcodes_across_sample[barcodes_across_sample.idxmax(axis=1).isin([49, 51, 40, 42])]\n",
    "\n",
    "for i, row in upper_index.iterrows():\n",
    "    col= row.idxmax()\n",
    "    if row[col]/row.drop([col], axis=0).max()<20:\n",
    "        upper_index = upper_index.drop(i)\n",
    "        \n",
    "upper = barcodes_across_sample[barcodes_across_sample.index.isin(upper_index.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f03a0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#for each barcode, create a matrix of BC count for regions in a sample based on amount of each region in LCM (makes assumption of equal BC distribution)\n",
    "bc_matrix = np.zeros(shape=((len(upper), (len(areas_only_grouped.columns)))))\n",
    "bc_matrix = pd.DataFrame(data= bc_matrix, columns=areas_only_grouped.columns, index=upper.index)\n",
    "for i, row in upper.iterrows():\n",
    "    counts = row.to_numpy()\n",
    "    frac_counts = frac_matrix * counts[:, np.newaxis]\n",
    "    sample_counts = pd.DataFrame(frac_counts, columns=areas_only_grouped.columns)\n",
    "    bc_matrix.loc[i] = sample_counts.sum() / areas_only_grouped.sum()\n",
    "#remove any columns that are all zeros\n",
    "for column in bc_matrix.columns:\n",
    "    if bc_matrix[column].sum() == 0:\n",
    "        bc_matrix.drop([column], axis=1, inplace=True)\n",
    "bc_matrix = bc_matrix.loc[~(bc_matrix==0).all(axis=1)]\n",
    "# perform hierarchial clustering of all barcodes across samples\n",
    "sb.clustermap(bc_matrix, metric='euclidean', standard_scale=0, norm=LogNorm(), cmap=\"Blues\", figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d68cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary_barcodes = pd.read_pickle(for_binary_barcode_path)\n",
    "lower_index = barcodes_across_sample[barcodes_across_sample.idxmax(axis=1).isin([50, 52, 41, 43])]\n",
    "for i, row in lower_index.iterrows():\n",
    "    col= row.idxmax()\n",
    "    if row[col]/row.drop([col], axis=0).max()<20:\n",
    "        lower_index = lower_index.drop(i)\n",
    "\n",
    "lower = barcodes_across_sample[barcodes_across_sample.index.isin(lower_index.index)]\n",
    "\n",
    "\n",
    "\n",
    "#for each barcode, create a matrix of BC count for regions in a sample based on amount of each region in LCM (makes assumption of equal BC distribution)\n",
    "bc_matrix = np.zeros(shape=((len(lower), (len(areas_only_grouped.columns)))))\n",
    "bc_matrix = pd.DataFrame(data= bc_matrix, columns=areas_only_grouped.columns, index=lower.index)\n",
    "for i, row in lower.iterrows():\n",
    "    counts = row.to_numpy()\n",
    "    frac_counts = frac_matrix * counts[:, np.newaxis]\n",
    "    sample_counts = pd.DataFrame(frac_counts, columns=areas_only_grouped.columns)\n",
    "    bc_matrix.loc[i] = sample_counts.sum() / areas_only_grouped.sum()\n",
    "#remove any columns that are all zeros\n",
    "for column in bc_matrix.columns:\n",
    "    if bc_matrix[column].sum() == 0:\n",
    "        bc_matrix.drop([column], axis=1, inplace=True)\n",
    "bc_matrix = bc_matrix.loc[~(bc_matrix==0).all(axis=1)]\n",
    "# perform hierarchial clustering of all barcodes across samples\n",
    "sb.clustermap(bc_matrix, metric='euclidean', standard_scale=0, norm=LogNorm(), cmap=\"Blues\", figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bc_matrix[bc_matrix['Cstr']>0])/len(bc_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2154cb9",
   "metadata": {},
   "source": [
    "Look at projection densities across brain in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7179c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the structures that have too much detail\n",
    "group_areas = {\n",
    "    #'SC': ['SCdg', 'SCdw', 'SCig', 'SCiw', 'SCop', 'SCsg', 'SCzo'],\n",
    "    #'IC': ['ICc', 'ICd', 'ICe', 'NB'],\n",
    "    'SSp': ['SSp-bfd', 'SSp-ll', 'SSp-m', 'SSp-n', 'SSp-tr', 'SSp-ul', 'SSp-un'],\n",
    "    'contra': areas.filter(like=\"Contra\").columns,\n",
    "    #'AudC': ['Contra-AUDd', 'Contra-AUDp', 'Contra-AUDv'],\n",
    "    #'VisC': ['Contra-VISa', 'Contra-VISam'],\n",
    "    #'VisIP': ['VISa', 'VISal', 'VISam', 'VISl', 'VISp', 'VISpm', 'VISpor', 'VISrl', 'VISli', 'VISpl'],\n",
    "    #'pons': ['SOCm', 'SOCl', 'POR', 'PRNr', 'PRNc', 'TRN', 'P', 'P-mot', 'PG', 'NLL']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load barcodes, and drop samples that have been qc'd out\n",
    "barcodes_across_sample = pd.read_pickle(normalised_barcode_path)\n",
    "\n",
    "areas = pd.read_csv(lcm_reg_dir/'3d_areas.csv')\n",
    "areas = areas.merge(RTtosample, how='inner', on='sample')\n",
    "areas =areas[areas['RT_primer'].isin(barcodes_across_sample.columns)]\n",
    "\n",
    "regions_to_add = {}\n",
    "regions_to_add['MG'] = [55, 66]\n",
    "regions_to_add['LP'] = [30, 39, 54]\n",
    "regions_to_add['POL'] = [44, 56, 67]\n",
    "regions_to_add['Rstr'] = [8, 13, 19]\n",
    "regions_to_add['CLA/Epc'] = [9, 14, 20, 25]\n",
    "regions_to_add['Cstr'] = [29]\n",
    "regions_to_add['SCs'] = [87, 68, 78, 92]\n",
    "regions_to_add['SCm'] = [69, 79, 93]\n",
    "regions_to_add['IC'] = [86, 89, 90]\n",
    "regions_to_add['pons'] = [72, 80, 88]\n",
    "for k, v in regions_to_add.items():\n",
    "    if k not in areas.columns:\n",
    "        areas[k] = 0\n",
    "    for value in v:\n",
    "        area_of_interest = areas.loc[areas['sample'] == value]\n",
    "        new_val = area_of_interest.sum(axis=1)-(area_of_interest['RT_primer']+area_of_interest['sample'])\n",
    "        to_add = pd.DataFrame(columns=areas.columns)\n",
    "        to_add[k] = new_val\n",
    "        to_add['sample']= value\n",
    "        to_add['RT_primer'] = area_of_interest['RT_primer']\n",
    "        to_add =to_add.fillna(0)\n",
    "        areas = areas.drop(area_of_interest.index)\n",
    "        areas= pd.concat([areas, to_add])\n",
    "areas =areas.set_index('RT_primer').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, columns in group_areas.items():\n",
    "    areas[group] = areas.filter(items=columns).sum(axis=1)\n",
    "    areas = areas.drop(columns, axis=1)\n",
    "areas_only = areas.drop(['sample', 'ar', 'bic', 'bsc', 'ccb', 'ccb', 'ccg', 'cing', 'cpd', 'csc', 'cst', 'ec', 'fa', 'fi',\n",
    "    'fiber tracts', 'fp', 'll', 'mcp', 'ml', 'onl', 'or', 'py', 'root', 'sctv', 'scwm', 'tb', 'CTXsp', 'act', 'alv', 'amc', 'cic', 'VL', 'MRN'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2442fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde4600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_only = areas_only.loc[:, np.sum(areas_only, axis=0)>0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40c65498",
   "metadata": {},
   "source": [
    "Look at barcodes across samples by projection density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe of the fractions of each brain area contained within each sample\n",
    "areas_matrix = areas_only.to_numpy()\n",
    "total_frac = np.sum(areas_matrix, axis=1)\n",
    "frac_matrix = areas_matrix/total_frac[:, np.newaxis]\n",
    "areasFrac = pd.DataFrame(frac_matrix, columns=areas_only.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d725e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each barcode, create a matrix of BC count for regions in a sample based on amount of each region in LCM (makes assumption of equal BC distribution)\n",
    "bc_matrix = np.zeros(shape=((len(barcodes_across_sample), (len(areas_only.columns)))))\n",
    "bc_matrix = pd.DataFrame(data= bc_matrix, columns=areas_only.columns, index=barcodes_across_sample.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01922953",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in barcodes_across_sample.iterrows():\n",
    "    bc_matrix1 = pd.DataFrame(columns=areas_only.columns)\n",
    "    counts = row.to_numpy()\n",
    "    frac_counts = frac_matrix * counts[:, np.newaxis]\n",
    "    sample_counts = pd.DataFrame(frac_counts, columns=areas_only.columns)\n",
    "    bc_matrix.loc[i] = sample_counts.sum() / areas_only.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any columns that are all zeros\n",
    "for column in bc_matrix.columns:\n",
    "    if bc_matrix[column].sum() == 0:\n",
    "        bc_matrix.drop([column], axis=1, inplace=True)\n",
    "bc_matrix = bc_matrix.loc[~(bc_matrix==0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b3551",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_matrix = bc_matrix.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13b08c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# perform hierarchial clustering of all barcodes across samples\n",
    "sb.clustermap(bc_matrix, metric='euclidean', standard_scale=0, norm=LogNorm(), yticklabels=False, cmap=\"PuBuGn\", figsize=(20, 10), cbar_kws={'label': 'projection density', \"shrink\": 0.4}, cbar_pos=(1.01, 0.5, 0.02, 0.18))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7176f1b",
   "metadata": {},
   "source": [
    "Grouping LCM sections according to broad areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc29f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary = bc_matrix.astype(bool)*1\n",
    "sb.clustermap(binary, metric='euclidean', standard_scale=0, norm=LogNorm(), cmap=\"Blues\", figsize=(10, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d73322b",
   "metadata": {},
   "source": [
    "Since subcortical regions are not great quality, and cortical regions are most of interest, see if any patterns in cortical projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c86e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = pd.read_csv(lcm_reg_dir/'3d_areas.csv')\n",
    "areas = areas.merge(RTtosample, how='inner', on='sample')\n",
    "areas.sort_values(\"RT_primer\", inplace=True)\n",
    "areas =areas[areas['RT_primer'].isin(barcodes_across_sample.columns)]\n",
    "cortical_group_areas = {\n",
    "    'SSp': ['SSp-bfd', 'SSp-ll', 'SSp-m', 'SSp-n', 'SSp-tr', 'SSp-ul', 'SSp-un'],\n",
    "    'contra': areas.filter(like=\"Contra\").columns,\n",
    "}\n",
    "for group, columns in cortical_group_areas.items():\n",
    "    areas[group] = areas.filter(items=columns).sum(axis=1)\n",
    "    areas = areas.drop(columns, axis=1)\n",
    "areas = areas.drop(['sample', 'ar', 'bic', 'bsc', 'ccb', 'ccb', 'ccg', 'cing', 'cpd', 'csc', 'cst', 'ec', 'fa', 'fi',\n",
    "    'fiber tracts', 'fp', 'll', 'mcp', 'ml', 'onl', 'or', 'py', 'root', 'sctv', 'scwm', 'tb', 'CTXsp', 'act', 'alv', 'amc', 'cic', 'VL', 'MRN'], axis=1)\n",
    "areas =areas.set_index('RT_primer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe of the fractions of each brain area contained within each sample\n",
    "areas_matrix = areas.to_numpy()\n",
    "total_frac = np.sum(areas_matrix, axis=1)\n",
    "frac_matrix = areas_matrix/total_frac[:, np.newaxis]\n",
    "areasFrac = pd.DataFrame(frac_matrix, columns=areas.columns)\n",
    "\n",
    "#for each barcode, create a matrix of BC count for regions in a sample based on amount of each region in LCM (makes assumption of equal BC distribution)\n",
    "bc_matrix = np.zeros(shape=((len(barcodes_across_sample), (len(areas.columns)))))\n",
    "bc_matrix = pd.DataFrame(data= bc_matrix, columns=areas.columns, index=barcodes_across_sample.index)\n",
    "for i, row in barcodes_across_sample.iterrows():\n",
    "    counts = row.to_numpy()\n",
    "    frac_counts = frac_matrix * counts[:, np.newaxis]\n",
    "    sample_counts = pd.DataFrame(frac_counts, columns=areas.columns)\n",
    "    bc_matrix.loc[i] = sample_counts.sum() / areas.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4678b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cortex = ['ACAd', 'ACAv', 'ECT', 'MOp', 'MOs', 'RSPagl', 'RSPd', 'RSPv', 'SSp', 'SSs', 'VISC', 'VISal',\n",
    "'VISam', 'VISl', 'VISli', 'VISp', 'VISpl','VISpm', 'VISpor', 'VISrl', 'contra', 'TEa', 'AUDp', 'AUDv', 'AUDd']\n",
    "bc_matrix = bc_matrix[cortex]\n",
    "#remove any columns that are all zeros\n",
    "for column in bc_matrix.columns:\n",
    "    if bc_matrix[column].sum() == 0:\n",
    "        bc_matrix.drop([column], axis=1, inplace=True)\n",
    "bc_matrix = bc_matrix.loc[~(bc_matrix==0).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de42b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_matrix = bc_matrix.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96671fab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sb.clustermap(bc_matrix, metric='canberra', standard_scale=0, norm=LogNorm(), yticklabels=False, cmap=\"PuBuGn\", figsize=(10, 10), cbar_kws={'label': 'projection density', \"shrink\": 0.4}, cbar_pos=(1.01, 0.5, 0.02, 0.18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6eb848",
   "metadata": {},
   "outputs": [],
   "source": [
    "areasFrac[(areasFrac['TEa']>0) & (areasFrac['VISpm']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490078b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cortical projections weighted by relationship between area size and counts\n",
    "#areas_only = areas.loc[:, np.sum(areas, axis=0)>0]\n",
    "areas_only = areas_only.loc[:, np.sum(areas_only, axis=0)>0]\n",
    "areas_matrix = areas_only.to_numpy()\n",
    "areas_matrix /= np.sum(areas_matrix, axis=0)\n",
    "barcodes_across_sample.fillna(0,inplace=True)\n",
    "barcodes_matrix = barcodes_across_sample.to_numpy()\n",
    "barcodes_matrix[np.isnan(barcodes_matrix)] = 0\n",
    "total_projection_strength = np.sum(barcodes_matrix, axis=1)\n",
    "barcodes_matrix /= total_projection_strength[:, np.newaxis]\n",
    "barcodes_matrix = barcodes_matrix[total_projection_strength>0, :]\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "mdl = LinearRegression(fit_intercept=False, positive=True)\n",
    "mdl.fit(areas_matrix, barcodes_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mdl.coef_, columns=areas_only.columns)\n",
    "cortex = ['ACAd', 'ACAv', 'ECT', 'MOp', 'MOs', 'RSPagl', 'RSPd', 'RSPv', 'SSp', 'SSs', 'VISal',\n",
    "'VISam', 'VISl', 'VISli', 'VISp', 'VISpl','VISpm', 'VISpor', 'VISrl', 'contra', 'TEa', 'AUDp', 'AUDv', 'AUDd']\n",
    "cortex_df = df[cortex]\n",
    "#cortex_df =cortex_df[cortex_df.sum(axis=1)>0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebdbc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.melt()['value'], bins=30)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3e7f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sb.clustermap(df.T, metric='euclidean', vmax=0.05, dendrogram_ratio=[0.1, 0.1], yticklabels=True, cmap='Blues', figsize=(10, 10))\n",
    "#sb.clustermap(cortex_df.T, metric='euclidean', standard_scale=0, norm=LogNorm(), cmap=\"Blues\", figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba83fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sb.clustermap(cortex_df.T, metric='euclidean', vmax=0.05, cmap='Blues', yticklabels=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64627133",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_across_sample[36]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas[(areas['AUDv']>0) & (areas['AUDp']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ece8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_only[areas_only['contra']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ecf0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas[areas['AUDp']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96598439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe of the fractions of each brain area contained within each sample\n",
    "cortex_areas_matrix = cortical_areas.to_numpy()\n",
    "cortex_total_frac = np.sum(cortex_areas_matrix, axis=1)\n",
    "cortex_frac_matrix = cortex_areas_matrix/cortex_total_frac[:, np.newaxis]\n",
    "cortex_areasFrac = pd.DataFrame(cortex_frac_matrix, columns=cortical_areas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a6ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in barcodes_across_sample.iterrows():\n",
    "    counts = row.to_numpy()\n",
    "    frac_counts = cortex_frac_matrix * counts[:, np.newaxis]\n",
    "    sample_counts = pd.DataFrame(frac_counts, columns=cortical_areas.columns)\n",
    "    cortex_bc_matrix.loc[i] = sample_counts.sum() / cortical_areas.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bdd582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each barcode, create a matrix of BC count for regions in a sample based on amount of each region in LCM (makes assumption of equal BC distribution)\n",
    "bc_matrix = np.zeros(shape=((len(barcodes_across_sample), (len(areas_only_grouped.columns)))))\n",
    "bc_matrix = pd.DataFrame(data= bc_matrix, columns=areas_only_grouped.columns, index=barcodes_across_sample.index)\n",
    "for i, row in barcodes_across_sample.iterrows():\n",
    "    counts = row.to_numpy()\n",
    "    frac_counts = frac_matrix * counts[:, np.newaxis]\n",
    "    sample_counts = pd.DataFrame(frac_counts, columns=areas_only_grouped.columns)\n",
    "    bc_matrix.loc[i] = sample_counts.sum() / areas_only_grouped.sum()\n",
    "#remove any columns that are all zeros\n",
    "for column in bc_matrix.columns:\n",
    "    if bc_matrix[column].sum() == 0:\n",
    "        bc_matrix.drop([column], axis=1, inplace=True)\n",
    "bc_matrix = bc_matrix.loc[~(bc_matrix==0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82efdd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cortex = ['ACAd', 'ACAv', 'AUDd', 'AUDp', 'AUDpo', 'AUDv', 'ECT', 'MOp', 'MOs', 'RSPagl', 'RSPd', 'RSPv', 'SSp', 'SSs', 'TEa', 'VISC', 'VISal',\n",
    "'VISam', 'VISl', 'VISli', 'VISp', 'VISpl','VISpm', 'VISpor', 'VISrl', 'contra']\n",
    "cortical_areas = cortical_areas[cortex]\n",
    "#create a dataframe of the fractions of each brain area contained within each sample\n",
    "cortical_areas_matrix = cortical_areas.to_numpy()\n",
    "total_frac_cortex = np.sum(cortical_areas_matrix, axis=1)\n",
    "cortical_frac_matrix = cortical_areas_matrix/total_frac_cortex[:, np.newaxis]\n",
    "cortical_areasFrac = pd.DataFrame(cortical_frac_matrix, columns=cortical_areas.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf7792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fad69f67",
   "metadata": {},
   "source": [
    "Are there any patterns between visual areas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92047ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_comp = ['VISa', 'VISal', 'VISam', 'VISl', 'VISp', 'VISpm', 'VISpor', 'VISrl', 'VISli', 'VISpl', 'SSs', 'SSp', 'MOp', 'MOs', 'ENTl', 'ECT', 'AUDpo']\n",
    "vis_matrix = bc_matrix[areas_comp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16e9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_matrix = vis_matrix.loc[~(vis_matrix==0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d8064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.clustermap(vis_matrix, metric='euclidean', standard_scale=0, norm=LogNorm(), cmap=\"Blues\", figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4381bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas[['VISpor','ENTl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34357ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "thalamus_and_tect_comp = ['POL', 'LP', 'SCs', 'SCm', 'IC']\n",
    "thalamus_and_tect_matrix = bc_matrix[thalamus_and_tect_comp]\n",
    "thalamus_and_tect_matrix = thalamus_and_tect_matrix.loc[~(thalamus_and_tect_matrix==0).all(axis=1)]\n",
    "sb.clustermap(thalamus_and_tect_matrix, metric='euclidean', standard_scale=0, norm=LogNorm(), cmap=\"Blues\", figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6956e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.clustermap(vis_matrix,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAPseq_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
