{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758e03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "#from matplotlib import rcParam\n",
    "import seaborn as sb\n",
    "import os\n",
    "import sys\n",
    "sys.setrecursionlimit(1000000)\n",
    "from scipy.stats import spearmanr\n",
    "import pathlib\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "mcc = MouseConnectivityCache()\n",
    "from scipy.stats import pearsonr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419c3b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae9e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#barcode_path_junk_test = pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/Sequencing/Processed_data/UpdatedApril/preprocessed_seq/Final_processed_sequences/junk_test/barcodes_across_sample.pkl')\n",
    "barcode_path = pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/Sequencing/Processed_data/UpdatedApril/preprocessed_seq_corrected/Final_processed_sequences/barcodes_across_sample.pkl')\n",
    "#barcode_path = pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/Sequencing/Processed_data/UpdatedApril/preprocessed_seq/Final_processed_sequences/barcodes_across_sample.pkl')\n",
    "barcodes_across_sample = pd.read_pickle(barcode_path)\n",
    "directory = pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/Sequencing/Processed_data/UpdatedApril/preprocessed_seq_corrected/Final_processed_sequences')\n",
    "#junk_test_directory = barcode_path_junk_test = pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/Sequencing/Processed_data/UpdatedApril/preprocessed_seq/Final_processed_sequences/junk_test')\n",
    "#load registration files containing volume of each brain area within each sample and which RT primer corresponds to which sample name\n",
    "lcm_reg_dir = pathlib.PurePath('/nemo/lab/znamenskiyp/home/shared/code/MAPseq_processing/AC_MAPseq/Brain1_FIAA32.6a/LCM_registration')\n",
    "#_3dareas = '/camp/lab/znamenskiyp/home/shared/code/MAPseq_processing/AC_MAPseq/Brain1_FIAA32.6a/LCM_registration/3D_areas_in_sample.csv'\n",
    "areas = pd.read_csv(lcm_reg_dir/'3d_areas.csv')\n",
    "RTtosample = pd.read_csv(lcm_reg_dir/'RTprimer_tosample.csv')\n",
    "areas = areas.merge(RTtosample, how='inner', on='sample')\n",
    "areas.sort_values(\"RT_primer\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be363d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#determine cut-off for total counts for barcode across dataset\n",
    "max_y = 100\n",
    "rcParams['figure.figsize'] = 8, 5\n",
    "interpolate_on_x = len(np.flip(np.sort(barcodes_across_sample.sum(axis=1))))-len(np.flip(np.sort(barcodes_across_sample.sum(axis=1)))[np.flip(np.sort(barcodes_across_sample.sum(axis=1)))<max_y])\n",
    "plt.loglog(np.flip(np.sort(barcodes_across_sample.sum(axis=1))))\n",
    "plt.xlabel('rank')\n",
    "plt.ylabel('total barcode counts')\n",
    "plt.axhline(y =max_y, linestyle='dashed', color = \"Black\", label = \"cut-off\", alpha=0.5)\n",
    "plt.axvline(x =interpolate_on_x, linestyle='dashed', color = \"Black\", label = \"cut-off\", alpha=0.5)\n",
    "plt.title(f'total count per barcode across MAPseq dataset ranked (x={interpolate_on_x})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f03db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove barcodes where total barcode count across dataset is below certain limit (max_y in before)\n",
    "filtered_barcodes =barcodes_across_sample[barcodes_across_sample.sum(axis=1)>=max_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 5, 5\n",
    "cmap = plt.get_cmap(\"tab20c\")\n",
    "\n",
    "negs = filtered_barcodes[[1, 2, 3, 4, 5]].melt(var_name='samples', value_name='barcode_counts')\n",
    "colours_picking = sb.color_palette('tab20c')[0:3]\n",
    "#plt.pie(negs[negs['barcode_counts']>0]['barcode_counts'])\n",
    "plt.pie(negs[negs['barcode_counts']>0]['barcode_counts'].value_counts(), labels=['1', '2'], colors=colours_picking)\n",
    "plt.title(f'barcode umi counts in negative controls \\n n = {len(negs[negs.barcode_counts>0])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8441b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define minimum barcode count per sample based on negative controls\n",
    "filtered_barcodes = filtered_barcodes.replace(1,0)\n",
    "#filtered_barcodes = filtered_barcodes.replace(2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 10, 5\n",
    "av_count_look = filtered_barcodes.copy()\n",
    "av_count_look = av_count_look.replace(0, np.NaN)\n",
    "plt.bar(av_count_look.columns, av_count_look.mean(), yerr=av_count_look.std())\n",
    "plt.yscale('log')\n",
    "plt.axhline(y =2, linestyle='dashed', color = \"Black\", label = \"min barcode count (2)\", alpha=0.5)\n",
    "plt.title('Mean count per barcode per sample')\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('mean umi count')\n",
    "plt.xticks(np.arange(1, 93, 2), rotation=45, fontsize=8)\n",
    "plt.legend(loc ='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601dca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_plot = filtered_barcodes.melt(var_name='samples', value_name='barcode_counts')\n",
    "to_plot = to_plot.drop(to_plot[to_plot.barcode_counts < 1].index)\n",
    "to_plot['log_bc_counts']= np.log10(to_plot['barcode_counts'])\n",
    "\n",
    "rcParams['figure.figsize'] = 18, 5\n",
    "\n",
    "\n",
    "#to_plot = to_plot.drop(to_plot[to_plot.barcode_counts < 2].index)\n",
    "sb.set_style(\"whitegrid\")\n",
    "#ax = sb.barplot(x=\"samples\", y=\"barcode_counts\", data=to_plot)\n",
    "# sb.stripplot(x=\"samples\", y=\"barcode_counts\", data=to_plot, ax=ax, color='black')\n",
    "sb.violinplot(x=\"samples\", y=\"log_bc_counts\", data=to_plot, inner='point', scale=\"width\", palette=\"tab20c\", width=1)\n",
    "#sb.boxplot(x=\"samples\", y=\"log_bc_counts\", data=to_plot)\n",
    "#sb.stripplot(x=\"samples\", y=\"log_bc_counts\", data=to_plot)\n",
    "#plt.yscale('log')\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('log10 per barcode umi count')\n",
    "plt.xticks(rotation=45, fontsize=8)\n",
    "plt.title('UMI count per barcode across samples', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b467d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Look at total reads per sample\n",
    "plt.bar(filtered_barcodes.columns, filtered_barcodes.sum(axis=0))\n",
    "plt.yscale('log')\n",
    "plt.title('Total reads per sample')\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('# reads')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354bee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at total counts for barcode across dataset\n",
    "max_y = 20\n",
    "#interpolate_on_x = len(np.flip(np.sort(barcodes_across_sample.sum(axis=1))))-len(np.flip(np.sort(barcodes_across_sample.sum(axis=1)))[np.flip(np.sort(barcodes_across_sample.sum(axis=1)))<max_y])\n",
    "#plt.loglog(np.flip(np.sort(filtered_barcodes.sum(axis=0))))\n",
    "plt.plot(np.flip(np.sort(filtered_barcodes.sum(axis=0))))\n",
    "plt.xlabel('rank')\n",
    "plt.ylabel('total barcode counts')\n",
    "plt.yscale('log')\n",
    "plt.title(f'total count of barcodes per sample across MAPseq dataset ranked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc8f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a dataframe for barcodes that have been filtered based on total overall expression and min count\n",
    "filtered_barcodes.to_pickle(directory/'filtered_barcode_matrix_for_binary.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b427e0d",
   "metadata": {},
   "source": [
    "Removing dud, low quality samples using Allen atlas and qPCR datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a904dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot relative reads to maximum\n",
    "#load tables\n",
    "ROI_path = pathlib.Path('/nemo/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/LCM_registration/rois')\n",
    "ROI_table = pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/LCM_registration/allenccf/ROI_vol.pkl')\n",
    "allen_converted_path = pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/LCM_registration/allenccf/allen_ccf_coord')\n",
    "download_allen = pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/Allen_Connectivity')\n",
    "reads_path = pathlib.Path(\"/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/Sequencing/Processed_data/UpdatedApril/preprocessed_seq/Final_processed_sequences\")\n",
    "tube_to_RT = pathlib.Path(\"/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/Sequencing/Processed_data/UpdatedApril/tube_to_RT.csv\")\n",
    "finalpix_expt_a = pd.read_pickle('mouse_connectivity/finalpix_expt_a.pkl')\n",
    "finalpix_expt_b = pd.read_pickle('mouse_connectivity/finalpix_expt_b.pkl')\n",
    "finalpix_expt_c = pd.read_pickle('mouse_connectivity/finalpix_expt_c.pkl')\n",
    "#allen anterograde tracing datasets with more than 75% injection site AUDp\n",
    "experiment_id_a = 120491896 # AUDp\n",
    "experiment_id_b =116903230 # AUDp, AUDpo, AUDd, AUDv\n",
    "experiment_id_c =100149109 # AUDp and AUDd\n",
    "#injection volumes to normalise to (mm3)\n",
    "expt_a_inj_vol = 0.097\n",
    "expt_b_inj_vol = 0.114\n",
    "expt_c_inj_vol= 0.073\n",
    "# get projection density for each anterograde tracing expt: values are sum of projecting pixels per voxel.\n",
    "expt_a, pd_a_info = mcc.get_projection_density(experiment_id_a)\n",
    "expt_b, pd_b_info = mcc.get_projection_density(experiment_id_b)\n",
    "expt_c, pd_c_info = mcc.get_projection_density(experiment_id_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a table with total number of projection pixels normalised by injection volume for each expt.\n",
    "all_projection_allen = pd.DataFrame().assign(Tube=finalpix_expt_a['tube'], ExptA = finalpix_expt_a['projection_density_summed']/expt_a_inj_vol, ExptB=finalpix_expt_b['projection_density_summed']/expt_b_inj_vol, ExptC=finalpix_expt_c['projection_density_summed']/expt_c_inj_vol)\n",
    "#all_projection_allen = all_projection_allen.set_index('Tube')\n",
    "projection_comp = pd.DataFrame(all_projection_allen.mean(axis=1), columns=['Allen'])\n",
    "#projection_comp['std_allen'] = all_projection_allen.std(axis=1)\n",
    "projection_comp['Tube'] = all_projection_allen['Tube']\n",
    "RT_convert = pd.read_csv(tube_to_RT)\n",
    "projection_comp.Tube = projection_comp.Tube.astype(str).astype(int)\n",
    "projection_comp = pd.merge(projection_comp, RT_convert, on ='Tube', how ='inner')\n",
    "projection_comp['MAPseq_counts'] = projection_comp.apply(lambda x: filtered_barcodes[x['RT primer']].sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30b13a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop sample 5 that has no registration data\n",
    "projection_comp = projection_comp.drop(projection_comp[projection_comp['RT primer']==5].index)\n",
    "filtered_barcodes = filtered_barcodes.drop(5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c27f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_comp['log_MAPseq_counts']=np.log((projection_comp.MAPseq_counts)+1)\n",
    "projection_comp['log_Allen']=np.log(projection_comp.Allen)\n",
    "#projection_comp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "#projection_comp = projection_comp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c05d3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 8, 5\n",
    "corr, _ = pearsonr(projection_comp['log_Allen'], y=projection_comp['log_MAPseq_counts'])\n",
    "print(f'Pearsons correlation: {corr}')\n",
    "p = sb.regplot(data = projection_comp, x='log_Allen', y='log_MAPseq_counts')\n",
    "#sb.scatterplot(x=projection_comp[projection_comp['fold_dif']<threshold]['log_Allen'], y=projection_comp[projection_comp['fold_dif']<threshold]['log_MAPseq_counts'], hue=projection_comp[projection_comp['fold_dif']<threshold]['fold_dif'])\n",
    "#sb.scatterplot(x=projection_comp[projection_comp['y_dif']>offset_thresh]['log_Allen'], y=projection_comp[projection_comp['y_dif']>offset_thresh]['log_MAPseq_counts'], hue=projection_comp[projection_comp['y_dif']>offset_thresh]['y_dif'])\n",
    "#calculate slope and intercept of regression equation\n",
    "slope, intercept, r, p, sterr = sp.stats.linregress(x=p.get_lines()[0].get_xdata(),\n",
    "                                                       y=p.get_lines()[0].get_ydata())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7886bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.linregress(x=projection_comp['log_Allen'], y=projection_comp['log_MAPseq_counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate residuals from regression plot and plot histogram\n",
    "#plt.rcdefaults()\n",
    "rcParams['figure.figsize'] = 6, 4\n",
    "projection_comp['y_dif'] = (slope*projection_comp['log_Allen']+intercept)-projection_comp['log_MAPseq_counts']\n",
    "plt.hist(projection_comp.y_dif, bins=8)\n",
    "plt.title('Distribution of residuals')\n",
    "plt.xlabel('y difference')\n",
    "plt.ylabel('frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(projection_comp['log_Allen'], projection_comp['y_dif'])\n",
    "plt.ylabel('residuals')\n",
    "plt.xlabel('log_Allen')\n",
    "rcParams['figure.figsize'] = 4, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bcc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_comp['y_bounds'] = (projection_comp['log_Allen']*slope)+intercept-(projection_comp['y_dif'].std() *2)\n",
    "projection_comp['upper_y_bounds'] = (projection_comp['log_Allen']*slope)+intercept+(projection_comp['y_dif'].std() *2)\n",
    "out_bounds_predictions = projection_comp['y_bounds'] >= projection_comp['log_MAPseq_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bounds_predictions = projection_comp['upper_y_bounds'] <= projection_comp['log_MAPseq_counts']\n",
    "projection_comp[upper_bounds_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809feec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    projection_comp[~out_bounds_predictions]['log_Allen'],\n",
    "    projection_comp[~out_bounds_predictions]['log_MAPseq_counts'],\n",
    "    color=\"C0\",\n",
    "    alpha=0.5\n",
    ")\n",
    "plt.scatter(\n",
    "    projection_comp[out_bounds_predictions]['log_Allen'],\n",
    "    projection_comp[out_bounds_predictions]['log_MAPseq_counts'],\n",
    "    color=\"grey\",\n",
    "    marker=\"+\",\n",
    "    label='outside cut-off'\n",
    ")\n",
    "plt.axline((0, intercept), slope=slope, color='C0')\n",
    "plt.axline((0, intercept-(projection_comp['y_dif'].std() *2)), slope=slope, color='grey', label='+ 2 stdev')\n",
    "plt.legend()\n",
    "plt.xlabel('log Allen (AU)')\n",
    "plt.ylabel('log MAPseq counts')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6ba827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now remove samples that are more than 2 stdev outside residuals\n",
    "filtered_barcodes_QC = filtered_barcodes.drop(list(projection_comp[out_bounds_predictions]['RT primer']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f07384",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl =filtered_barcodes_QC.sum(axis=0)\n",
    "#bl = bl[bl>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 5, 5\n",
    "plt.hist(bl[bl<1000], bins=30)\n",
    "#plt.yscale('log')\n",
    "plt.axvline(30, color='Black', linestyle='dashed',  alpha=0.5, label='30 barcode cut-off')\n",
    "plt.xlabel('number of different neuron barcodes')\n",
    "plt.ylabel('number of samples')\n",
    "plt.title('Frequency distribution of # individual barcodes per sample, max visualised to 1000')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1787837",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_barcodes_QC = filtered_barcodes_QC.drop(filtered_barcodes_QC.columns[filtered_barcodes_QC.astype(bool).sum()<30], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed9afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = filtered_barcodes_QC.melt(var_name='samples', value_name='barcode_counts')\n",
    "to_plot = to_plot.drop(to_plot[to_plot.barcode_counts < 1].index)\n",
    "to_plot['log_bc_counts']= np.log10(to_plot['barcode_counts'])\n",
    "\n",
    "rcParams['figure.figsize'] = 18, 5\n",
    "\n",
    "\n",
    "#to_plot = to_plot.drop(to_plot[to_plot.barcode_counts < 2].index)\n",
    "sb.set_style(\"whitegrid\")\n",
    "#ax = sb.barplot(x=\"samples\", y=\"barcode_counts\", data=to_plot)\n",
    "# sb.stripplot(x=\"samples\", y=\"barcode_counts\", data=to_plot, ax=ax, color='black')\n",
    "sb.violinplot(x=\"samples\", y=\"log_bc_counts\", data=to_plot, inner='point', scale=\"width\", palette=\"tab20c\", width=1)\n",
    "#sb.boxplot(x=\"samples\", y=\"log_bc_counts\", data=to_plot)\n",
    "#sb.stripplot(x=\"samples\", y=\"log_bc_counts\", data=to_plot)\n",
    "#plt.yscale('log')\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('log10 per barcode umi count')\n",
    "plt.xticks(rotation=45, fontsize=8)\n",
    "plt.title('UMI count per barcode across samples', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbce6c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_plot = filtered_barcodes_QC.melt(var_name='samples', value_name='barcode_counts')\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "to_plot = to_plot.drop(to_plot[to_plot.barcode_counts < 2].index)\n",
    "sb.set_style(\"whitegrid\")\n",
    "ax = sb.barplot(x=\"samples\", y=\"barcode_counts\", data=to_plot)\n",
    "sb.stripplot(x=\"samples\", y=\"barcode_counts\", data=to_plot, ax=ax, color='black')\n",
    "#sb.stripplot(x=\"samples\", y=\"barcode_counts\", data=to_plot)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('per barcode umi count')\n",
    "plt.xticks(rotation=45, fontsize=8)\n",
    "plt.title('UMI count per barcode across samples after removing putative dud samples', fontsize=18)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7690b6a7",
   "metadata": {},
   "source": [
    "Normalise samples based on spike-in levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b500c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spike-in normalisation, generate table of spike counts per sample\n",
    "spike_counts = pd.DataFrame(columns=[\"sample\", \"spike_count\"])\n",
    "for sample in os.listdir(directory):\n",
    "    if sample.startswith(\"spike_counts\"):\n",
    "        sample_name = sample.split(\"spike_counts_\", 1)\n",
    "        sample_name = sample_name[1][: -len(\".csv\")]\n",
    "        sample_num = float(sample_name[2 :])\n",
    "        sample_reading = pd.read_csv(directory/sample)\n",
    "        sample_reading[\"counts\"] = sample_reading[\"counts\"].astype(\"int\")\n",
    "        sum_counts = sample_reading[\"counts\"].sum()\n",
    "        new_row = pd.DataFrame(\n",
    "            {\"sample\": sample_num, \"spike_count\": sum_counts}, index=[0]\n",
    "        )\n",
    "        spike_counts = pd.concat([spike_counts, new_row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7af2fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot the distribtution of spike-in reads and decide cut-off threshold\n",
    "rcParams['figure.figsize'] = 5, 5\n",
    "plt.hist(spike_counts['spike_count'], bins =20, color='purple')\n",
    "plt.xlabel('total spike umi count')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('distribution of spike counts across samples')\n",
    "plt.axvline(x = 2000, color = 'black', linestyle='dashed', label = 'cut-off', alpha =0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d480c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove spikes that are below certain threshold, then normalise total counts in each sample by relative spike-count\n",
    "\n",
    "spike_cutoff = 2000\n",
    "spike_thresh = list(spike_counts[spike_counts['spike_count']<spike_cutoff]['sample'])\n",
    "filtered_barcodes_QC = filtered_barcodes_QC.drop((spike_thresh), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e30d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_thresholded = spike_counts[spike_counts['spike_count']>spike_cutoff]\n",
    "lowest = min(spikes_thresholded[\"spike_count\"])\n",
    "spikes_thresholded[\"normalisation_factor\"] = spikes_thresholded[\"spike_count\"] / lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434427e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_barcodes_spike_normalised = filtered_barcodes_QC.copy()\n",
    "for i, row in spikes_thresholded.iterrows():\n",
    "    if row['sample'] in filtered_barcodes_spike_normalised.columns:\n",
    "        filtered_barcodes_spike_normalised[row['sample']] = filtered_barcodes_spike_normalised[row['sample']]/row['normalisation_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26376640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set min to 1\n",
    "filtered_barcodes_spike_normalised = filtered_barcodes_spike_normalised/filtered_barcodes_spike_normalised[filtered_barcodes_spike_normalised>0].min().min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70470481",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = filtered_barcodes_spike_normalised.melt(var_name='samples', value_name='barcode_counts')\n",
    "to_plot = to_plot.drop(to_plot[to_plot.barcode_counts ==0].index)\n",
    "to_plot['log_bc_counts']= np.log10(to_plot['barcode_counts'])\n",
    "\n",
    "rcParams['figure.figsize'] = 18, 5\n",
    "\n",
    "\n",
    "#to_plot = to_plot.drop(to_plot[to_plot.barcode_counts < 2].index)\n",
    "sb.set_style(\"whitegrid\")\n",
    "#ax = sb.barplot(x=\"samples\", y=\"barcode_counts\", data=to_plot)\n",
    "# sb.stripplot(x=\"samples\", y=\"barcode_counts\", data=to_plot, ax=ax, color='black')\n",
    "sb.violinplot(x=\"samples\", y=\"log_bc_counts\", data=to_plot, inner='point', scale=\"width\", palette=\"tab20c\", width=1)\n",
    "#sb.boxplot(x=\"samples\", y=\"log_bc_counts\", data=to_plot)\n",
    "#sb.stripplot(x=\"samples\", y=\"log_bc_counts\", data=to_plot)\n",
    "#plt.yscale('log')\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('log10 per barcode umi count')\n",
    "plt.xticks(rotation=45, fontsize=8)\n",
    "plt.title('UMI count per barcode across samples after spike normalisation', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = filtered_barcodes_spike_normalised.melt(var_name='samples', value_name='barcode_counts')\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "post_spike = to_plot[to_plot['barcode_counts']>0]\n",
    "sb.set_style(\"whitegrid\")\n",
    "ax = sb.barplot(x=\"samples\", y=\"barcode_counts\", data=post_spike)\n",
    "sb.stripplot(x=\"samples\", y=\"barcode_counts\", data=post_spike, color='black', ax=ax)\n",
    "#sb.stripplot(x=\"samples\", y=\"barcode_counts\", data=to_plot)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('per barcode umi count')\n",
    "plt.xticks(rotation=45, fontsize=8)\n",
    "\n",
    "plt.title('UMI count per barcode across samples after spike normalisation', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_thresholded['normalisation_factor'].max()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e685735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl =filtered_barcodes_spike_normalised.astype(bool).sum(axis=0)\n",
    "for i in bl:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any barcodes found only in one sample\n",
    "filtered_barcodes_spike_normalised = filtered_barcodes_spike_normalised[filtered_barcodes_spike_normalised.astype(bool).sum(axis=1)>1]\n",
    "\n",
    "#save the qc'd and normalised barcode matrix\n",
    "\n",
    "filtered_barcodes_spike_normalised.to_pickle(directory/'barcode_matrix_normalised.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66413f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_barcodes_spike_normalised.to_pickle(directory/'barcode_matrix_normalised.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a391c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_barcodes_spike_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2842d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the samples that contain zero spike counts may be an artifact of UMI correction, since we know that there are many MAPseq reads. \n",
    "#therefore, let's see if we can correct the artifact and table\n",
    "BC5 = pd.read_csv('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/Sequencing/Processed_data/UpdatedApril/preprocessed_seq_corrected/corrected_BC57.csv',\n",
    "        header=0, \n",
    "        usecols=[\"full_read\", \"neuron_sequence\", \"corrected_sequences_neuron\", \"umi_sequence\", \"corrected_sequences_umi\"])\n",
    "#BC65 = pd.read_csv(directory/'neuron_counts_BC65.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b0a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "BC57[BC57['full_read']=='CCTTACCCCCTAAGTGTTGTTTTTTCCTCTTCTATCTTATCACTATACCCGCTTGCGCCTTA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter ones that contain the spike-in sequence in uncorrected\n",
    "BC57_spike = BC5[BC5['neuron_sequence'].str.contains(\"^.{24}ATCAGTCA\") == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7581f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BC57_spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb2ce47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0910a779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d391eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824eec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop samples that contain spike count less than 1500, as RT likely failed for these samples\n",
    "min_spike = 1500\n",
    "spike_thresholded = spike_counts[spike_counts['spike_count'] >= min_spike]\n",
    "areas_dropped= areas[areas['RT_primer'].isin(spike_thresholded['sample']) == False].RT_primer\n",
    "areas= areas[areas['RT_primer'].isin(spike_thresholded['sample']) == True]\n",
    "barcodes_across_sample = barcodes_across_sample.drop(columns=np.array(areas_dropped))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5aedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#also drop sample 5 that doesn't have reg info\n",
    "areas = areas.drop([4])\n",
    "barcodes_across_sample =barcodes_across_sample.drop(columns=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af9c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now remove any barcodes with a count less than 1, then remove barcodes that don't have a count anywhere.\\\n",
    "barcodes_across_sample = barcodes_across_sample.replace(1,0)\n",
    "barcodes_across_sample.fillna(0,inplace=True)\n",
    "barcodes_across_sample = barcodes_across_sample.loc[~(barcodes_across_sample==0).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b99c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_counts[spike_counts['spike_count'] < min_spike]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = barcodes_across_sample[[1, 2, 3, 4]]\n",
    "bla = bla.loc[~(bla==0).all(axis=1)]\n",
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ae6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90823c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise counts by spike-in counts\n",
    "lowest = min(spike_thresholded[\"spike_count\"])\n",
    "spike_thresholded[\"normalisation_factor\"] = spike_thresholded[\"spike_count\"] / lowest\n",
    "#spike_thresholded= spike_thresholded.sort_values(\"sample\", inplace=True)\n",
    "spike_thresholded =spike_thresholded.set_index('sample')\n",
    "spike_thresholded.sort_index(inplace=True)\n",
    "norm = spike_thresholded['normalisation_factor'].T\n",
    "barcodes_across_sample_changed = barcodes_across_sample.div(norm, axis='columns')\n",
    "\n",
    "barcodes_across_sample_changed.fillna(0,inplace=True)\n",
    "#plt heatmap of barcode matrix after spike normalisation\n",
    "fig, ax = plt.subplots(figsize=(60, 10))\n",
    "sb.heatmap(barcodes_across_sample, cmap='Blues', norm=LogNorm())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c236d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label sample 29 as caudal striatum \n",
    "CStr = areas[areas['RT_primer']==29]\n",
    "CStr_val = CStr.sum(axis=1)-(CStr['RT_primer']+CStr['sample'])\n",
    "to_add = pd.DataFrame(columns=areas.columns)\n",
    "to_add['Cstr'] = CStr_val\n",
    "to_add =to_add.fillna(0)\n",
    "areas['Cstr'] = 0\n",
    "areas.update(to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas['Cstr'] = 0\n",
    "areas.update(to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872ba32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas[areas['RT_primer']==57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f181023",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_areas = {\n",
    "    'tectum': ['SCdg', 'SCdw', 'SCig', 'SCiw', 'SCop', 'SCsg', 'SCzo', 'ICc', 'ICd', 'ICe', 'NB'],\n",
    "    'thalamus': ['PoT', 'TH', 'MGm', 'MGv', 'MGd', 'LGd-co', 'LP', 'POL', 'PO', 'LD', 'VPL', 'PIL', 'Eth'],\n",
    "    'SS': ['SSp-bfd', 'SSp-ll', 'SSp-m', 'SSp-n', 'SSp-tr', 'SSp-ul', 'SSp-un', 'SSs'],\n",
    "    'M': ['MOs', 'MOp'],\n",
    "    'contra': areas.filter(like=\"Contra\").columns,\n",
    "    #'AudC': ['Contra-AUDd', 'Contra-AUDp', 'Contra-AUDv'],\n",
    "    #'VisC': ['Contra-VISa', 'Contra-VISam'],\n",
    "    'VisIP': ['VISa', 'VISal', 'VISam', 'VISl', 'VISp', 'VISpm', 'VISpor', 'VISrl', 'VISli', 'VISpl'],\n",
    "    'RStr': ['CP', 'STR', 'ACB'],\n",
    "    'pons': ['SOCm', 'SOCl', 'POR', 'PRNr', 'PRNc', 'TRN', 'P', 'P-mot', 'PG', 'NLL']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2510a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, columns in group_areas.items():\n",
    "    areas[group] = areas.filter(items=columns).sum(axis=1)\n",
    "    areas = areas.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_only = areas.drop(['sample', 'RT_primer', 'ar', 'bic', 'bsc', 'ccb', 'ccb', 'ccg', 'cing', 'cpd', 'csc', 'cst', 'ec', 'fa', 'fi',\n",
    "    'fiber tracts', 'fp', 'll', 'mcp', 'ml', 'onl', 'or', 'py', 'root', 'sctv', 'scwm', 'tb', 'CTXsp', 'act', 'alv', 'amc', 'cic', 'VL', 'MRN'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1caf16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_only = areas_only.loc[:, np.sum(areas_only, axis=0)>0]\n",
    "areas_matrix = areas_only.to_numpy()\n",
    "areas_matrix /= np.sum(areas_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cb4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_only.iloc[64]['contra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "barcodes_across_sample.fillna(0,inplace=True)\n",
    "barcodes_matrix = barcodes_across_sample.to_numpy()\n",
    "barcodes_matrix[np.isnan(barcodes_matrix)] = 0\n",
    "total_projection_strength = np.sum(barcodes_matrix, axis=1)\n",
    "barcodes_matrix /= total_projection_strength[:, np.newaxis]\n",
    "\n",
    "barcodes_matrix = barcodes_matrix[total_projection_strength>0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70391b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(barcodes_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8371f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "mdl = LinearRegression(fit_intercept=False, positive=True)\n",
    "mdl.fit(areas_matrix, barcodes_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw, not spike normalised, with higher cutoff\n",
    "plt.figure(figsize=(20,70))\n",
    "df = pd.DataFrame(mdl.coef_[:15000,:], columns=areas_only.columns)\n",
    "sb.clustermap(df.T, vmax=0.1, dendrogram_ratio=[0.1, 0.1], yticklabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96723532",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_comp = ['MOB', 'M', 'Cstr', 'RStr', 'tectum', 'thalamus', 'contra', 'VisIP', 'SS']\n",
    "areas_grouped = df[areas_comp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b422e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf901ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_grouped = areas_grouped.loc[~(areas_grouped==0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d5103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw, not spike normalised, with higher cutoff\n",
    "plt.figure(figsize=(10,50))\n",
    "\n",
    "sb.clustermap(areas_grouped.T, cmap=\"Blues\", dendrogram_ratio=(.1, .2), vmax=0.05, cbar_pos=(-0.2, .5, .1, .4), yticklabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538c0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe of the fractions of each brain area contained within each sample\n",
    "areas_matrix = areas_only.to_numpy()\n",
    "total_frac = np.sum(areas_matrix, axis=1)\n",
    "frac_matrix = areas_matrix/total_frac[:, np.newaxis]\n",
    "areasFrac = pd.DataFrame(frac_matrix, columns=areas_only.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40000620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc9c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each barcode, create a matrix of BC count for regions in a sample based on amount of each region in LCM (makes assumption of equal BC distribution)\n",
    "bc_matrix = np.zeros(shape=((len(barcodes_across_sample), (len(areas_only.columns)))))\n",
    "bc_matrix = pd.DataFrame(data= bc_matrix, columns=areas_only.columns, index=barcodes_across_sample.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ea0c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in barcodes_across_sample.iterrows():\n",
    "    bc_matrix1 =pd.DataFrame(columns=areas_only.columns)\n",
    "    for samplename in barcodes_across_sample.columns:\n",
    "        counts = row.to_numpy()\n",
    "        frac_counts =frac_matrix* counts[:, np.newaxis]\n",
    "        sample_counts =pd.DataFrame(frac_counts, columns = areas_only.columns)\n",
    "    for region in sample_counts.columns:\n",
    "        bc_matrix.at[i, region] = sample_counts[region].sum()/areas_only[region].sum()\n",
    "#bc_matrix.to_pickle(lcm_reg_dir/'bc_matrix_lcm_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0082084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f17cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca4d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_comp = ['MOB', 'M', 'Cstr', 'RStr', 'tectum', 'thalamus', 'contra', 'VisIP', 'SS']\n",
    "areas_grouped = bc_matrix[areas_comp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ac41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_grouped = areas_grouped.loc[~(areas_grouped==0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12131cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform hierarchial clustering of all barcodes across samples\n",
    "sb.clustermap(areas_grouped, metric='euclidean', standard_scale=0, norm=LogNorm(), cmap=\"Blues\", figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a7dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_counts = pd.DataFrame(frac_counts, columns = areas_only.columns)\n",
    "for region in sample_counts.columns:\n",
    "    bc_matrix.at[i, region] = sample_counts[region].sum()/areas_only[region].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3c152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in sample_counts.columns:\n",
    "    bc_matrix.at[i, region] = sample_counts[region].sum()/areas_only[region].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699832ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9fec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_counts['thalamus'].sum()/areas_only[region].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8864157",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_only[region].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b3d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_across_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_only.iloc[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd5a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in areas_only[region]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "row =barcodes_across_sample.iloc[2].to_numpy()\n",
    "\n",
    "bl =frac_matrix* row[:, np.newaxis]\n",
    "f =pd.DataFrame(bl, columns = areas_only.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15816c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead8d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.iloc[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db167c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = -1\n",
    "for samplename in barcodes_across_sample.columns:\n",
    "    ind = +1\n",
    "    bl = row.iloc[ind]*areasFrac\n",
    "    print(samplename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e511d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "areasFrac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_across_sample.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in barcodes_across_sample.loc[2]:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234416b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl =row*areasFrac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ba338",
   "metadata": {},
   "outputs": [],
   "source": [
    "areasFrac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e16c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each barcode, create a matrix of BC count for regions in a sample based on amount of each region in LCM (makes assumption of equal BC distribution)\n",
    "bc_matrix = np.zeros(shape=((len(newdf), (len(areas_only.columns)))))\n",
    "bc_matrix = pd.DataFrame(data= bc_matrix, columns=areas_only.columns, index=newdf.index)\n",
    "for i, row in newdf.iterrows():\n",
    "    bc_matrix1 =pd.DataFrame(columns=areas_only.columns)\n",
    "    for samplename in newdf.columns:\n",
    "        ind = areas.index[areas['RT_primer']==samplename].tolist()\n",
    "        fractionC = areasFrac.iloc[ind[0]]*row.loc[samplename]\n",
    "        bc_matrix1 = bc_matrix1.append(fractionC)\n",
    "    for region in bc_matrix1.columns:\n",
    "        bc_matrix.at[i, region] = bc_matrix1[region].sum()/areas_only[region].sum()\n",
    "#bc_matrix.to_pickle(lcm_reg_dir/'bc_matrix_lcm_2.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAPseq_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
