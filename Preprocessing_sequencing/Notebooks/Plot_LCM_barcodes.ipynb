{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import seaborn as sb\n",
    "import os\n",
    "import sys\n",
    "sys.setrecursionlimit(1000000)\n",
    "from scipy.stats import spearmanr\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5c822",
   "metadata": {},
   "source": [
    "Load barcodes and LCM registration files and assign counts to areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = pathlib.PurePath('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/Sequencing/Processed_data/BC_split/temp/increased_cutoff/')\n",
    "barcodes_across_sample = pd.read_pickle(directory/'raw_barcodes_across_sample_higher_cutoff.pkl')\n",
    "#load registration files containing volume of each brain area within each sample and which RT primer corresponds to which sample name\n",
    "lcm_reg_dir = pathlib.PurePath('/nemo/lab/znamenskiyp/home/shared/code/MAPseq_processing/AC_MAPseq/Brain1_FIAA32.6a/LCM_registration')\n",
    "#_3dareas = '/camp/lab/znamenskiyp/home/shared/code/MAPseq_processing/AC_MAPseq/Brain1_FIAA32.6a/LCM_registration/3D_areas_in_sample.csv'\n",
    "areas = pd.read_csv(lcm_reg_dir/'3d_areas.csv')\n",
    "RTtosample = pd.read_csv(lcm_reg_dir/'RTprimer_tosample.csv')\n",
    "areas = areas.merge(RTtosample, how='inner', on='sample')\n",
    "areas.sort_values(\"RT_primer\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3fb5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot heatmap of barcodes against samples\n",
    "fig, ax = plt.subplots(figsize=(60, 10))\n",
    "sb.heatmap(barcodes_across_sample, norm=LogNorm())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c5ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_across_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sum(barcodes_across_sample.to_numpy()>5, axis=1), bins=np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d732952",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(barcodes_across_sample.to_numpy().flatten(), bins=100)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Barcode UMI count per sample')\n",
    "plt.title('Distribution of UMIs per barcode per sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at BC distribution in negative control\n",
    "neg =barcodes_across_sample[[1, 2, 3, 4, 5]].to_numpy().flatten()\n",
    "plt.hist(neg.flatten(), bins=100)\n",
    "#plt.yscale('log')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Barcode UMI count per sample')\n",
    "plt.title('Distribution of UMIs per barcode in negative control')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41249d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg1 = pd.DataFrame(neg).dropna()\n",
    "neg1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab3c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at barcode distribution in sample sites vs neg control\n",
    "neg_sites =[1, 2, 3, 4, 5]\n",
    "fig, ax1 = plt.subplots()\n",
    "sample_sites = barcodes_across_sample.drop(columns=neg_sites) \n",
    "plt.hist(sample_sites.to_numpy().flatten(), bins=100, label ='sample sites')\n",
    "plt.hist(neg.flatten(), bins=np.arange(5000), label = 'negative control')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Barcode UMI count per sample')\n",
    "plt.title('Distribution of UMIs per barcode per sample')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f2d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd43df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots the histogram\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.hist([sample_sites.to_numpy().flatten(),neg.flatten()], histtype='step', linewidth=2, bins=100, label=['sample sites', 'negative control'])\n",
    "#ax1.set_xlim(-10,10)\n",
    "ax1.set_ylabel(\"Frequency\")\n",
    "ax1.set_xlabel(\"UMIs per barcode\")\n",
    "plt.tight_layout()\n",
    "plt.yscale('log')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Distribution of UMIs per barcode per sample')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f040f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67167378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set max barcode to one\n",
    "newbcmatrix = pd.DataFrame(columns = barcodes_across_sample.columns)\n",
    "for i, row in barcodes_across_sample.iterrows():\n",
    "    newrow= pd.DataFrame(barcodes_across_sample.loc[i]/barcodes_across_sample.loc[i].max())\n",
    "    newbcmatrix = pd.concat([newbcmatrix, newrow.T])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(60, 10))\n",
    "sb.heatmap(newbcmatrix, cmap='Blues', norm=LogNorm())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spike-in normalisation, generate table of spike counts per sample\n",
    "spike_counts = pd.DataFrame(columns=[\"sample\", \"spike_count\"])\n",
    "for sample in os.listdir(directory):\n",
    "    if sample.startswith(\"spikecounts\"):\n",
    "        sample_name = sample.split(\"spikecounts_\", 1)\n",
    "        sample_name = sample_name[1][: -len(\".csv\")]\n",
    "        sample_num = float(sample_name[2 :])\n",
    "        sample_reading = pd.read_csv(directory/sample)\n",
    "        sample_reading[\"counts\"] = sample_reading[\"counts\"].astype(\"int\")\n",
    "        sum_counts = sample_reading[\"counts\"].sum()\n",
    "        new_row = pd.DataFrame(\n",
    "            {\"sample\": sample_num, \"spike_count\": sum_counts}, index=[0]\n",
    "        )\n",
    "        spike_counts = pd.concat([spike_counts, new_row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e381ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only look at most abundant barcodes by taking min values for source sites\n",
    "neg =barcodes_across_sample[[40, 41, 42, 43, 49, 50, 51, 52]].to_numpy().flatten()\n",
    "plt.hist(neg.flatten(), bins=50)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Barcode UMI count per sample')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of UMIs per barcode in source sites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0375f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select rows based on min count at source sites\n",
    "source_min = 10\n",
    "barcodes_norm_sub1 = barcodes_across_sample.loc[(barcodes_across_sample[40] >= source_min)]\n",
    "barcodes_norm_sub2 = barcodes_across_sample.loc[(barcodes_across_sample[41] >= source_min)]\n",
    "barcodes_norm_sub3 = barcodes_across_sample.loc[(barcodes_across_sample[42] >= source_min)]\n",
    "barcodes_norm_sub4 = barcodes_across_sample.loc[(barcodes_across_sample[43] >= source_min)]\n",
    "barcodes_norm_sub5 = barcodes_across_sample.loc[(barcodes_across_sample[49] >= source_min)]\n",
    "barcodes_norm_sub6 = barcodes_across_sample.loc[(barcodes_across_sample[50] >= source_min)]\n",
    "barcodes_norm_sub7 = barcodes_across_sample.loc[(barcodes_across_sample[51] >= source_min)]\n",
    "barcodes_norm_sub8 = barcodes_across_sample.loc[(barcodes_across_sample[52] >= source_min)]\n",
    "newdf =pd.concat([barcodes_norm_sub1, barcodes_norm_sub2])\n",
    "newdf =pd.concat([newdf, barcodes_norm_sub3])\n",
    "newdf =pd.concat([newdf, barcodes_norm_sub4])\n",
    "newdf =pd.concat([newdf, barcodes_norm_sub5])\n",
    "newdf =pd.concat([newdf, barcodes_norm_sub6])\n",
    "newdf =pd.concat([newdf, barcodes_norm_sub7])\n",
    "newdf =pd.concat([newdf, barcodes_norm_sub8])\n",
    "newdf = newdf[~newdf.index.duplicated(keep='first')] #remove duplicate barcodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db411a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64231406",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_across_sample = newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab01434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop samples that contain spike count less than 10, as RT likely failed for these samples\n",
    "min_spike = 1500\n",
    "spike_thresholded = spike_counts[spike_counts['spike_count'] >= min_spike]\n",
    "areas_dropped= areas[areas['RT_primer'].isin(spike_thresholded['sample']) == False].RT_primer\n",
    "areas= areas[areas['RT_primer'].isin(spike_thresholded['sample']) == True]\n",
    "barcodes_across_sample = barcodes_across_sample.drop(columns=np.array(areas_dropped))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4718f1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909cf8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#also drop sample 5 that doesn't have reg info\n",
    "areas = areas.drop([4])\n",
    "barcodes_across_sample =barcodes_across_sample.drop(columns=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803fb24a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(spike_counts[\"spike_count\"], bins=30)\n",
    "plt.title('Spike-in Count Distribution', fontsize=12)\n",
    "plt.axvline(x = 1500, color = \"Black\", label = \"cut-off\")\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('# Samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b34865",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beee1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now remove any barcodes with a count of 1, then remove barcodes that don't have a count anywhere.\\\n",
    "barcodes_across_sample = barcodes_across_sample.replace(1,0)\n",
    "barcodes_across_sample.fillna(0,inplace=True)\n",
    "barcodes_across_sample = barcodes_across_sample.loc[~(barcodes_across_sample==0).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525014c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bla = barcodes_across_sample[1][barcodes_across_sample[1]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5445087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_across_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2bfb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas[areas['RT_primer']==56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcfaef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot heatmap of barcodes against samples\n",
    "fig, ax = plt.subplots(figsize=(60, 10))\n",
    "sb.heatmap(barcodes_across_sample, norm=LogNorm())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e91dd67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#normalise counts by spike-in counts\n",
    "lowest = min(spike_thresholded[\"spike_count\"])\n",
    "spike_thresholded[\"normalisation_factor\"] = spike_thresholded[\"spike_count\"] / lowest\n",
    "#spike_thresholded= spike_thresholded.sort_values(\"sample\", inplace=True)\n",
    "spike_thresholded =spike_thresholded.set_index('sample')\n",
    "spike_thresholded.sort_index(inplace=True)\n",
    "norm = spike_thresholded['normalisation_factor'].T\n",
    "barcodes_across_sample = barcodes_across_sample.div(norm, axis='columns')\n",
    "\n",
    "barcodes_across_sample.fillna(0,inplace=True)\n",
    "#plt heatmap of barcode matrix after spike normalisation\n",
    "fig, ax = plt.subplots(figsize=(60, 10))\n",
    "sb.heatmap(barcodes_across_sample, cmap='Blues', norm=LogNorm())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d1f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_across_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc39128",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas.loc[28].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8267e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ROI from registration data, and plot striatum reads against coordinates\n",
    "reg_dir = pathlib.Path('/nemo/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/LCM_registration/allenccf/allen_ccf_coord')\n",
    "ROI = pathlib.Path('/nemo/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/LCM_registration/rois')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dbce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAU_samples = [8, 9, 13, 19, 29]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b8977",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_across_sample[CAU_samples]\n",
    "#plt heatmap of barcode matrix after spike normalisation\n",
    "fig, ax = plt.subplots(figsize=(60, 10))\n",
    "sb.heatmap(barcodes_across_sample[CAU_samples], cmap='Blues', norm=LogNorm())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ae2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set max barcode to one\n",
    "CAU =barcodes_across_sample[CAU_samples]\n",
    "newbcmatrix = pd.DataFrame(columns = CAU.columns)\n",
    "for i, row in CAU.iterrows():\n",
    "    newrow= pd.DataFrame(CAU.loc[i]/CAU.loc[i].max())\n",
    "    newbcmatrix = pd.concat([newbcmatrix, newrow.T])\n",
    "fig, ax = plt.subplots(figsize=(60, 10))\n",
    "sb.heatmap(newbcmatrix, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a638d9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c974160",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 90)\n",
    "pd.set_option('display.max_columns', 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c8da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_sites = [40, 42, 43, 49, 50, 51, 52] #removed 41, as this is already removed\n",
    "#barcodes_across_sample.drop(source_sites, axis=1, inplace=True)\n",
    "#areas.drop(index=[ source - 1 for source in source_sites ], inplace=True)\n",
    "\n",
    "group_areas = {\n",
    "    'SC': ['SCdg', 'SCdw', 'SCig', 'SCiw', 'SCop', 'SCsg', 'SCzo'],\n",
    "    \n",
    "    'IC': ['ICc', 'ICd', 'ICe'],\n",
    "    'SSp': ['SSp-bfd', 'SSp-ll', 'SSp-m', 'SSp-n', 'SSp-tr', 'SSp-ul', 'SSp-un'],\n",
    "    'contra': areas.filter(like=\"Contra\").columns,\n",
    "    'striatum': ['CP', 'STR', 'ACB'],\n",
    "    'pons': ['SOCm', 'SOCl', 'POR', 'PRNr', 'PRNc', 'TRN', 'P', 'P-mot']\n",
    "}\n",
    "for group, columns in group_areas.items():\n",
    "    areas[group] = areas.filter(items=columns).sum(axis=1)\n",
    "    areas = areas.drop(columns, axis=1)\n",
    "    \n",
    "areas_only = areas.drop(['sample', 'RT_primer', 'ar', 'bic', 'bsc', 'ccb', 'ccb', 'ccg', 'cing', 'cpd', 'csc', 'cst', 'ec', 'fa', 'fi',\n",
    "    'fiber tracts', 'fp', 'll', 'mcp', 'ml', 'onl', 'or', 'py', 'root', 'sctv', 'scwm', 'tb', 'CTXsp', 'act', 'alv', 'amc', 'cic', 'TH'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb45602",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a8fd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa74c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_sites = [40, 42, 43, 49, 50, 51, 52] #removed 41, as this is already removed\n",
    "#barcodes_across_sample.drop(source_sites, axis=1, inplace=True)\n",
    "#areas.drop(index=[ source - 1 for source in source_sites ], inplace=True)\n",
    "\n",
    "group_areas = {\n",
    "    'SC': ['SCdg', 'SCdw', 'SCig', 'SCiw', 'SCop', 'SCsg', 'SCzo'],\n",
    "    \n",
    "    'IC': ['ICc', 'ICd', 'ICe'],\n",
    "    'SSp': ['SSp-bfd', 'SSp-ll', 'SSp-m', 'SSp-n', 'SSp-tr', 'SSp-ul', 'SSp-un'],\n",
    "    'contra': areas.filter(like=\"Contra\").columns,\n",
    "    'striatum': ['CP', 'STR', 'ACB'],\n",
    "    'pons': ['SOCm', 'SOCl', 'POR', 'PRNr', 'PRNc', 'TRN', 'P', 'P-mot']\n",
    "}\n",
    "\n",
    "for group, columns in group_areas.items():\n",
    "    areas[group] = areas.filter(items=columns).sum(axis=1)\n",
    "    areas = areas.drop(columns, axis=1)\n",
    "    \n",
    "areas_only = areas.drop(['sample', 'RT_primer', 'ar', 'bic', 'bsc', 'ccb', 'ccb', 'ccg', 'cing', 'cpd', 'csc', 'cst', 'ec', 'fa', 'fi',\n",
    "    'fiber tracts', 'fp', 'll', 'mcp', 'ml', 'onl', 'or', 'py', 'root', 'sctv', 'scwm', 'tb', 'CTXsp', 'act', 'alv', 'amc', 'cic', 'TH'], axis=1)\n",
    "\n",
    "areas_only = areas_only.loc[:, np.sum(areas_only, axis=0)>0]\n",
    "areas_matrix = areas_only.to_numpy()\n",
    "areas_matrix /= np.sum(areas_matrix, axis=0)\n",
    "barcodes_across_sample.fillna(0,inplace=True)\n",
    "barcodes_matrix = barcodes_across_sample.to_numpy()\n",
    "barcodes_matrix[np.isnan(barcodes_matrix)] = 0\n",
    "total_projection_strength = np.sum(barcodes_matrix, axis=1)\n",
    "barcodes_matrix /= total_projection_strength[:, np.newaxis]\n",
    "\n",
    "barcodes_matrix = barcodes_matrix[total_projection_strength>0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "mdl = LinearRegression(fit_intercept=False, positive=True)\n",
    "mdl.fit(areas_matrix, barcodes_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw, not spike normalised, with higher cutoff\n",
    "plt.figure(figsize=(20,70))\n",
    "df = pd.DataFrame(mdl.coef_[:15000,:], columns=areas_only.columns)\n",
    "sb.clustermap(df.T, vmax=0.3, dendrogram_ratio=[0.1, 0.1], yticklabels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd9eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-cutoff with spike normalised\n",
    "plt.figure(figsize=(20,70))\n",
    "df = pd.DataFrame(mdl.coef_[:15000,:], columns=areas_only.columns)\n",
    "sb.clustermap(df.T, vmax=0.2, dendrogram_ratio=[0.1, 0.1], yticklabels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b81107",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "sb.barplot(df)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce0378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove barcodes that are only seen in one sample (NB this is not needed, I initially put in as a QC)\n",
    "barcodes_across_sample['samplesnotin'] =0\n",
    "for index, row in barcodes_across_sample.iterrows():\n",
    "    barcodes_across_sample['samplesnotin'].iloc[index]=(row.isna().sum())\n",
    "barcodes_across_sample = barcodes_across_sample[barcodes_across_sample['samplesnotin']<90]\n",
    "barcodes_across_sample = barcodes_across_sample.drop('samplesnotin', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove NaN\n",
    "barcodes_across_sample = barcodes_across_sample.fillna(0)\n",
    "#set min val to 1\n",
    "barcodes_across_sample= barcodes_across_sample.reset_index(drop=True)\n",
    "for index, row in barcodes_across_sample.iterrows():\n",
    "    bla = np.array(row)\n",
    "    smallest = np.min(bla[np.nonzero(bla)])\n",
    "    barcodes_across_sample.iloc[[index]]=row/smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ab9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select rows based on min count at source sites\n",
    "barcodes_norm_sub1 = barcodes_across_sample.loc[(barcodes_across_sample[40] >= 20)]\n",
    "barcodes_norm_sub2 = barcodes_across_sample.loc[(barcodes_across_sample[41] >= 20)]\n",
    "barcodes_norm_sub3 = barcodes_across_sample.loc[(barcodes_across_sample[42] >= 20)]\n",
    "barcodes_norm_sub4 = barcodes_across_sample.loc[(barcodes_across_sample[43] >= 20)]\n",
    "barcodes_norm_sub5 = barcodes_across_sample.loc[(barcodes_across_sample[49] >= 20)]\n",
    "barcodes_norm_sub6 = barcodes_across_sample.loc[(barcodes_across_sample[50] >= 20)]\n",
    "barcodes_norm_sub7 = barcodes_across_sample.loc[(barcodes_across_sample[51] >= 20)]\n",
    "barcodes_norm_sub8 = barcodes_across_sample.loc[(barcodes_across_sample[52] >= 20)]\n",
    "newdf =pd.concat([barcodes_norm_sub1, barcodes_norm_sub2])\n",
    "newdf =pd.concat([newdf, barcodes_norm_sub3])\n",
    "newdf =pd.concat([newdf, barcodes_norm_sub4])\n",
    "newdf =pd.concat([newdf, barcodes_norm_sub5])\n",
    "newdf =pd.concat([newdf, barcodes_norm_sub6])\n",
    "newdf =pd.concat([newdf, barcodes_norm_sub7])\n",
    "newdf =pd.concat([newdf, barcodes_norm_sub8])\n",
    "newdf = newdf[~newdf.index.duplicated(keep='first')] #remove duplicate barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot heatmap showing barcodes in source site\n",
    "fig, ax = plt.subplots(figsize=(60, 10))\n",
    "sb.heatmap(barcodes_across_sample, norm=LogNorm())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot heatmap showing barcodes in source site with minimum thresholds\n",
    "fig, ax = plt.subplots(figsize=(60, 10))\n",
    "sb.heatmap(newdf, norm=LogNorm())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42932d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now remove columns containing source sites and negative control\n",
    "newdf = newdf.drop([40, 41, 42, 43, 49, 50, 51, 52, 1, 2, 3, 4, 5], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968649f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total['sum'] = areas_only.sum(axis=1)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe of the fractions of each brain area contained within each sample\n",
    "total = pd.DataFrame()\n",
    "total['sum'] = areas_only.sum(axis=1)\n",
    "areasFrac = pd.DataFrame(columns=areas_only.columns)\n",
    "for i, row in areas_only.iterrows():\n",
    "    newrow = row/total['sum'].iloc[i]\n",
    "    areasFrac =areasFrac.append(newrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9704a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas= areas.drop(['ar', 'bic', 'bsc', 'ccb', 'ccb', 'ccg', 'cing', 'cpd', 'csc', 'cst', 'ec', 'fa', 'fi',\n",
    "    'fiber tracts', 'fp', 'll', 'mcp', 'ml', 'onl', 'or', 'py', 'root', 'sctv', 'scwm', 'tb', 'CTXsp', 'act', 'alv', 'amc', 'cic', 'TH'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66754125",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = areas.drop(areas.iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7267386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "areasFrac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085991f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each barcode, create a matrix of BC count for regions in a sample based on amount of each region in LCM (makes assumption of equal BC distribution)\n",
    "bc_matrix = np.zeros(shape=((len(newdf), (len(areas_only.columns)))))\n",
    "bc_matrix = pd.DataFrame(data= bc_matrix, columns=areas_only.columns, index=newdf.index)\n",
    "for i, row in newdf.iterrows():\n",
    "    bc_matrix1 =pd.DataFrame(columns=areas_only.columns)\n",
    "    for samplename in newdf.columns:\n",
    "        ind = areas.index[areas['RT_primer']==samplename].tolist()\n",
    "        fractionC = areasFrac.iloc[ind[0]]*row.loc[samplename]\n",
    "        bc_matrix1 = bc_matrix1.append(fractionC)\n",
    "    for region in bc_matrix1.columns:\n",
    "        bc_matrix.at[i, region] = bc_matrix1[region].sum()/areas_only[region].sum()\n",
    "#bc_matrix.to_pickle(lcm_reg_dir/'bc_matrix_lcm_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f6df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load bc_matrix (containing counts in each region for each barcode) if don't want to repeat above  \n",
    "bc_matrix = pd.read_pickle(lcm_reg_dir/'bc_matrix_lcm_2.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748be93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns that are all zeros, and rows that are all zeros\n",
    "for column in bc_matrix.columns:\n",
    "    if bc_matrix[column].sum() == 0:\n",
    "        bc_matrix.drop([column], axis=1, inplace=True)\n",
    "bc_matrix = bc_matrix.loc[~(bc_matrix==0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a3c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform hierarchial clustering of all barcodes across samples\n",
    "sb.clustermap(bc_matrix, metric='euclidean', standard_scale=0, cmap=\"Blues\", figsize=(60, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308bfcd6",
   "metadata": {},
   "source": [
    "Potentially may want to threshold to minimum barcode counts? I haven't but might be useful set a minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a63526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#threshold minimum value of counts/cm3 to zero\n",
    "threshold = 0.0000001\n",
    "bc_matrix_thresholded = pd.DataFrame(np.where(bc_matrix > threshold, 0, bc_matrix))\n",
    "#remove columns that are all zeros, and rows that are all zeros\n",
    "for column in bc_matrix_thresholded.columns:\n",
    "    if bc_matrix_thresholded[column].sum() == 0:\n",
    "        bc_matrix_thresholded.drop([column], axis=1, inplace=True)\n",
    "bc_matrix_thresholded = bc_matrix_thresholded.loc[~(bc_matrix==0).all(axis=1)]\n",
    "#plot heatmap showing barcodes in source site with minimum thresholds\n",
    "fig, ax = plt.subplots(figsize=(60, 10))\n",
    "sb.heatmap(bc_matrix_thresholded, norm=LogNorm())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7662d1bf",
   "metadata": {},
   "source": [
    "Looking at barcode distribution across visual areas only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before selecting subset of areas, set max row projection strength to 1, so preserve relative projection strengths of bc\n",
    "newbcmatrix = pd.DataFrame(columns = bc_matrix.columns)\n",
    "for i, row in bc_matrix.iterrows():\n",
    "    newrow= pd.DataFrame(bc_matrix.loc[i]/bc_matrix.loc[i].max())\n",
    "    newbcmatrix = pd.concat([newbcmatrix, newrow.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c7b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now take only the regions that contain visual areas\n",
    "visareas= [col for col in newbcmatrix if col.startswith('VIS') and col.startswith('VISC') == False] +  [col for col in newbcmatrix if col.startswith('Contra-VIS')and col.startswith('Contra-VISC') == False]\n",
    "reg = newbcmatrix.loc[:,visareas]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows and columns containing only zeros\n",
    "for column in reg.columns:\n",
    "    if reg[column].sum() == 0:\n",
    "        reg.drop([column], axis=1, inplace=True)\n",
    "reg = reg.loc[~(reg==0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform hierarchial clustering of visual areas only\n",
    "sb.clustermap(reg, metric='euclidean', cmap=\"Blues\", figsize=(30, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b80451",
   "metadata": {},
   "source": [
    "(can ignore) looking at qPCR as potential QC check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ea67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = pd.read_csv(lcm_reg_dir/'3d_areas.csv')\n",
    "RTtosample = pd.read_csv(lcm_reg_dir/'RTprimer_tosample.csv')\n",
    "areas = areas.merge(RTtosample, how='inner', on='sample')\n",
    "areas.sort_values(\"RT_primer\", inplace=True)\n",
    "areas.drop('RT_primer', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddf4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot of qPCR beta actin values against volume for potentially using as QC against sample quality\n",
    "qPCR = pd.read_csv('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/qPCR/qPCR_FIAA326a.csv') \n",
    "qPCR['B-act_amount'] = np.power(1.585,(-(qPCR['B-actin Ct'])))\n",
    "qPCR['vol'] = 0\n",
    "qPCR['vol'] = areas.sum(axis=1)    \n",
    "#for i, row in qPCR.iterrows():\n",
    " #   ind = areas.index[areas['RT_primer']==qPCR.loc[i, 'RT primer']].tolist()\n",
    "  #  qPCR.at[i, 'vol'] = total.iloc[ind[0]]\n",
    "#qPCR = qPCR.drop([4]) #remove row with no volume\n",
    "qPCR['logVol'] = np.log(qPCR['vol'])\n",
    "qPCR['logBetaAct'] = np.log(qPCR['B-act_amount'])\n",
    "sb.lmplot(data= qPCR, x='logVol', y='logBetaAct')\n",
    "corr, _ = spearmanr(qPCR[\"vol\"], qPCR[\"B-act_amount\"])\n",
    "print('Spearmans correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12886903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_ci_manual(t, s_err, n, x, x2, y2, ax=None):\n",
    "    \"\"\"Return an axes of confidence bands using a simple approach.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    .. math:: \\left| \\: \\hat{\\mu}_{y|x0} - \\mu_{y|x0} \\: \\right| \\; \\leq \\; T_{n-2}^{.975} \\; \\hat{\\sigma} \\; \\sqrt{\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n{(x_i-\\bar{x})^2}}}\n",
    "    .. math:: \\hat{\\sigma} = \\sqrt{\\sum_{i=1}^n{\\frac{(y_i-\\hat{y})^2}{n-2}}}\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Duarte.  \"Curve fitting,\" Jupyter Notebook.\n",
    "       http://nbviewer.ipython.org/github/demotu/BMC/blob/master/notebooks/CurveFitting.ipynb\n",
    "    \n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    ci = t * s_err * np.sqrt(1/n + (x2 - np.mean(x))**2 / np.sum((x - np.mean(x))**2))\n",
    "    ax.fill_between(x2, y2 + ci, y2 - ci, color=\"#b9cfe7\", edgecolor=\"none\")\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_ci_bootstrap(xs, ys, resid, nboot=500, ax=None):\n",
    "    \"\"\"Return an axes of confidence bands using a bootstrap approach.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The bootstrap approach iteratively resampling residuals.\n",
    "    It plots `nboot` number of straight lines and outlines the shape of a band.\n",
    "    The density of overlapping lines indicates improved confidence.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ax : axes\n",
    "        - Cluster of lines\n",
    "        - Upper and Lower bounds (high and low) (optional)  Note: sensitive to outliers\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] J. Stults. \"Visualizing Confidence Intervals\", Various Consequences.\n",
    "       http://www.variousconsequences.com/2010/02/visualizing-confidence-intervals.html\n",
    "\n",
    "    \"\"\" \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    bootindex = sp.random.randint\n",
    "\n",
    "    for _ in range(nboot):\n",
    "        resamp_resid = resid[bootindex(0, len(resid) - 1, len(resid))]\n",
    "        # Make coeffs of for polys\n",
    "        pc = sp.polyfit(xs, ys + resamp_resid, 1)                   \n",
    "        # Plot bootstrap cluster\n",
    "        ax.plot(xs, sp.polyval(pc, xs), \"b-\", linewidth=2, alpha=3.0 / float(nboot))\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f5d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equation(a, b):\n",
    "    \"\"\"Return a 1D polynomial.\"\"\"\n",
    "    return np.polyval(a, b) \n",
    "\n",
    "\n",
    "x = qPCR['logVol']\n",
    "y = qPCR['logBetaAct']\n",
    "p, cov = np.polyfit(x, y, 1, cov=True)                     # parameters and covariance from of the fit of 1-D polynom.\n",
    "y_model = equation(p, x)                                   # model using the fit parameters; NOTE: parameters here are coefficients\n",
    "\n",
    "# Statistics\n",
    "n = qPCR['logBetaAct'].size                                           # number of observations\n",
    "m = p.size                                                 # number of parameters\n",
    "dof = n - m                                                # degrees of freedom\n",
    "t = stats.t.ppf(0.975, n - m)                              # t-statistic; used for CI and PI bands\n",
    "\n",
    "# Estimates of Error in Data/Model\n",
    "resid = y - y_model                                        # residuals; diff. actual data from predicted values\n",
    "chi2 = np.sum((resid / y_model)**2)                        # chi-squared; estimates error in data\n",
    "chi2_red = chi2 / dof                                      # reduced chi-squared; measures goodness of fit\n",
    "s_err = np.sqrt(np.sum(resid**2) / dof)                    # standard deviation of the error\n",
    "\n",
    "# Plotting --------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Data\n",
    "ax.plot(\n",
    "    x, y, \"o\", color=\"#b9cfe7\", markersize=5, \n",
    "    markeredgewidth=0.1, markeredgecolor=\"#0047AB\", markerfacecolor=\"#0047AB\"\n",
    ")\n",
    "\n",
    "# Fit\n",
    "ax.plot(x, y_model, \"-\", color=\"0.1\", linewidth=1.5, alpha=0.5, label=\"Fit\")  \n",
    "\n",
    "x2 = np.linspace(np.min(x), np.max(x), 100)\n",
    "y2 = equation(p, x2)\n",
    "\n",
    "# Confidence Interval (select one)\n",
    "plot_ci_manual(t, s_err, n, x, x2, y2, ax=ax)\n",
    "#plot_ci_bootstrap(x, y, resid, ax=ax)\n",
    "   \n",
    "# Prediction Interval\n",
    "pi = t * s_err * np.sqrt(1 + 1/n + (x2 - np.mean(x))**2 / np.sum((x - np.mean(x))**2))   \n",
    "ax.fill_between(x2, y2 + pi, y2 - pi, color=\"None\", linestyle=\"--\")\n",
    "ax.plot(x2, y2 - pi, \"--\", color=\"0.5\", label=\"95% Prediction Limits\")\n",
    "ax.plot(x2, y2 + pi, \"--\", color=\"0.5\")\n",
    "plt.xlabel('log vol')\n",
    "plt.ylabel('log b-actin')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a85c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove samples that are outside 95% prediction limit of b-act/vol regression fit\n",
    "low_bact_corr = [67, 39, 25, 5, 44] #43 already removed in spike-in\n",
    "barcodes_across_sample.drop(low_bact_corr, axis=1, inplace=True)\n",
    "areas = areas[~areas['RT_primer'].isin(low_bact_corr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b1b0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a6642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2defc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-MAPseq_processing] *",
   "language": "python",
   "name": "conda-env-.conda-MAPseq_processing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
