{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB need to use environment with python3.9 or above for ccf_streamlines to run\n",
    "import nrrd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ccf_streamlines.projection as ccfproj\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib.colors import LogNorm\n",
    "import copy\n",
    "import cv2\n",
    "import seaborn as sb\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_dir = pathlib.Path('/nemo/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/LCM_registration/allenccf/allen_ccf_coord')\n",
    "ROI_path = pathlib.Path('/nemo/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/LCM_registration/rois')\n",
    "ROI_table = pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/LCM_registration/allenccf/ROI_vol.pkl')\n",
    "allen_converted_path = pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/LCM_registration/allenccf/allen_ccf_coord')\n",
    "convert_to_flat_path = allen_converted_path.parents[1]\n",
    "lcm_reg_dir = pathlib.PurePath('/nemo/lab/znamenskiyp/home/shared/code/MAPseq_processing/AC_MAPseq/Brain1_FIAA32.6a/LCM_registration')\n",
    "reads_path = pathlib.Path(\"/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/FIAA32.6a/Sequencing/Source_target_together\")\n",
    "RTtosample = pd.read_csv(allen_converted_path.parents[2]/ 'Sequencing/Processed_data/UpdatedApril/tube_to_RT.csv')\n",
    "\n",
    "areas = pd.read_csv(lcm_reg_dir/'3d_areas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_barcode_path= pathlib.Path('/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/FIAA32.6a/Sequencing/Source_target_together/barcode_matrix_normalised_no_source_cut.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_barcodes_spike_normalised = pd.read_pickle(normalised_barcode_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-organise sample names in barcode table so that they match tube names for registraton\n",
    "new_columns= {}\n",
    "for i, r in RTtosample.iterrows():\n",
    "    new_columns[r['RT primer']]= r['Tube'] #create a dictionary to rename columns in the barcode matrix with tube names rather than RT sample names\n",
    "filtered_barcodes_spike_normalised = filtered_barcodes_spike_normalised.rename(columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_barcodes_spike_normalised =filtered_barcodes_spike_normalised[filtered_barcodes_spike_normalised.astype(bool).sum(axis=1)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogram distribution of 1st/2nd abundant ratios\n",
    "known_source = [36, 65]\n",
    "known_source_filtered_barcodes_spike_normalised = filtered_barcodes_spike_normalised[filtered_barcodes_spike_normalised.idxmax(axis=1).isin(known_source)]\n",
    "without_known_source_filtered_barcodes_spike_normalised = filtered_barcodes_spike_normalised[~filtered_barcodes_spike_normalised.idxmax(axis=1).isin(known_source)]\n",
    "find_source_not_known = pd.DataFrame()\n",
    "find_source_not_known['highest'] = filtered_barcodes_spike_normalised.max(axis=1) +1\n",
    "find_source_not_known['second'] = filtered_barcodes_spike_normalised.apply(lambda row: row.nlargest(2).values[-1],axis=1) +1\n",
    "find_source_not_known['relative_to_max'] = np.log10(find_source_not_known['highest']/find_source_not_known['second'])\n",
    "plt.hist(find_source_not_known['relative_to_max'], bins=150, alpha=0.5,  density=True, label='all samples')\n",
    "find_source = pd.DataFrame()\n",
    "find_source['highest'] = known_source_filtered_barcodes_spike_normalised.max(axis=1) +1\n",
    "find_source['second'] = known_source_filtered_barcodes_spike_normalised.apply(lambda row: row.nlargest(2).values[-1],axis=1) +1\n",
    "find_source['relative_to_max'] = np.log10(find_source['highest']/find_source['second'])\n",
    "plt.hist(find_source['relative_to_max'], bins=150, alpha = 0.5, density=True, label ='barcodes with max in samples 36 and 65')\n",
    "no_source = pd.DataFrame()\n",
    "no_source['highest'] = without_known_source_filtered_barcodes_spike_normalised.max(axis=1) +1\n",
    "no_source['second'] = without_known_source_filtered_barcodes_spike_normalised.apply(lambda row: row.nlargest(2).values[-1],axis=1) +1\n",
    "no_source['relative_to_max'] = np.log10(no_source['highest']/no_source['second'])\n",
    "plt.hist(no_source['relative_to_max'], bins=150, alpha = 0.5, density=True, label ='barcodes without max in samples 36 and 65')\n",
    "plt.title('Distribution of 1st/2nd abundance')\n",
    "plt.xlabel('log 10 1st/2nd barcode counts')\n",
    "plt.axvline(x =1.64, linestyle='dashed', color = \"Black\", label = \"cut-off\", alpha=0.5)\n",
    "plt.ylabel('density')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(find_source_not_known[find_source_not_known['sample']==36])/len(find_source_not_known) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since \n",
    "find_source_not_known['sample'] = filtered_barcodes_spike_normalised.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.stripplot(data=find_source_not_known, x='sample', y='highest')\n",
    "plt.yscale('log')\n",
    "plt.title('Max count for max barcode across samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.stripplot(data=find_source_not_known, x='sample', y='relative_to_max')\n",
    "plt.title('1st/2nd most abundant sample count ratio across samples with containing max barcode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.violinplot(data=find_source_not_known, x='sample', y='relative_to_max', inner='point', scale=\"width\", palette=\"tab20c\", width=1)\n",
    "plt.title('1st/2nd most abundant sample count ratio across samples with containing max barcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.stripplot(data=thresholded_bc, x='sample', y='relative_to_max')\n",
    "plt.title('1st/2nd most abundant sample count ratio across samples with containing max barcode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_barcodes_spike_normalised_3samples =filtered_barcodes_spike_normalised[filtered_barcodes_spike_normalised.astype(bool).sum(axis=1)>2]\n",
    "find_source_not_known_3 = pd.DataFrame()\n",
    "find_source_not_known_3['highest'] = filtered_barcodes_spike_normalised_3samples.max(axis=1)\n",
    "find_source_not_known_3['second_max'] = filtered_barcodes_spike_normalised_3samples.apply(lambda row: row.nlargest(3).values[-2],axis=1)\n",
    "find_source_not_known_3['third_max'] = filtered_barcodes_spike_normalised_3samples.apply(lambda row: row.nlargest(3).values[-1],axis=1)\n",
    "find_source_not_known_3['relative_to_max'] = np.log10(find_source_not_known_3['second_max']/find_source_not_known_3['third_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_source_not_known_3['sample'] = filtered_barcodes_spike_normalised_3samples.idxmax(axis=1)\n",
    "find_source_not_known_3['2larg'] = filtered_barcodes_spike_normalised_3samples.mask(filtered_barcodes_spike_normalised_3samples.eq(filtered_barcodes_spike_normalised_3samples.max(axis=1), axis=0)).idxmax(axis=1)\n",
    "rcParams['figure.figsize'] = 18, 5\n",
    "sb.stripplot(data=find_source_not_known_3, x='2larg', y='relative_to_max')\n",
    "plt.title('2nd/3rd most abundant sample count ratio across samples with containing max barcode')\n",
    "plt.axhline(y =1.64, linestyle='dashed', color = \"Black\", label = \"cut-off\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold =find_source_not_known_3['relative_to_max'].std()*4 + find_source_not_known_3['relative_to_max'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(find_source_not_known['relative_to_max'], bins=150, alpha=0.5,  density=True, label='all samples 1st/2nd max')\n",
    "\n",
    "plt.hist(find_source_not_known_3['relative_to_max'], bins=150, alpha = 0.5, density=True, label ='all samples 2nd/3rd max')\n",
    "plt.title('Distribution of relative abundance between samples')\n",
    "plt.xlabel('log 10 1st/2nd barcode counts')\n",
    "plt.axvline(x =1.64, linestyle='dashed', color = \"Black\", label = \"cut-off\", alpha=0.5)\n",
    "plt.ylabel('density')\n",
    "plt.legend(loc='upper right', fontsize=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_barcodes = pd.DataFrame()\n",
    "for col in filtered_barcodes_spike_normalised.columns:\n",
    "    density_barcodes[col] = filtered_barcodes_spike_normalised[col]/(areas.loc[col].sum())\n",
    "thresholded_bc['max_density'] = ''\n",
    "for indexes in thresholded_bc.index:\n",
    "    thresholded_bc.loc[indexes, 'max_density'] = density_barcodes.loc[indexes, thresholded_bc.loc[indexes, 'sample']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_bc['vol'] = ''\n",
    "for indexes in thresholded_bc.index:\n",
    "    thresholded_bc.loc[indexes, 'vol'] = areas.loc[thresholded_bc.loc[indexes, 'sample']].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.scatterplot(x=thresholded_bc['vol'], y = thresholded_bc['max_density'])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.clustermap(filtered_barcodes_spike_normalised[filtered_barcodes_spike_normalised.idxmax(axis=1)==57],metric='canberra', standard_scale=0, norm=LogNorm(), cmap=\"Greys\", figsize=(20, 10), yticklabels=False, xticklabels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.stripplot(data=thresholded_bc, x='sample', y='max_density')\n",
    "plt.title('max density in max count sample for each barcode according to sample ')\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_boundary_finder = ccfproj.BoundaryFinder(\n",
    "    projected_atlas_file=convert_to_flat_path/\"flatmap_butterfly.nrrd\",\n",
    "    labels_file=convert_to_flat_path/\"labelDescription_ITKSNAPColor.txt\",\n",
    ")\n",
    "\n",
    "# We get the left hemisphere region boundaries with the default arguments\n",
    "bf_left_boundaries = bf_boundary_finder.region_boundaries()\n",
    "\n",
    "# And we can get the right hemisphere boundaries that match up with\n",
    "# our projection if we specify the same configuration\n",
    "bf_right_boundaries = bf_boundary_finder.region_boundaries(\n",
    "    # we want the right hemisphere boundaries, but located in the right place\n",
    "    # to plot both hemispheres at the same time\n",
    "    hemisphere='right_for_both',\n",
    "\n",
    "    # we also want the hemispheres to be adjacent\n",
    "    view_space_for_other_hemisphere='flatmap_butterfly',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_top = ccfproj.Isocortex2dProjector(\n",
    "    # Specify our view lookup file\n",
    "    convert_to_flat_path/\"flatmap_butterfly.h5\",\n",
    "\n",
    "    # Specify our streamline file\n",
    "    convert_to_flat_path/\"surface_paths_10_v3.h5\",\n",
    "\n",
    "    # Specify that we want to project both hemispheres\n",
    "    hemisphere=\"both\",\n",
    "\n",
    "    # The top view contains space for the right hemisphere, but is empty.\n",
    "    # Therefore, we tell the projector to put both hemispheres side-by-side\n",
    "    view_space_for_other_hemisphere='flatmap_butterfly',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide = 'ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_flatmap = np.load(convert_to_flat_path/'ROI_cortical_3D.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove tubes in ROI flatmap that aren't in normalised barcode path\n",
    "tubes = np.arange(1, 93, 1)\n",
    "tubes_not_in = [i for i in tubes if i not in filtered_barcodes_spike_normalised.columns.to_list()]\n",
    "for x in tubes_not_in:\n",
    "    ROI_flatmap[ROI_flatmap == x] = 0\n",
    "ROI_projection_max = proj_top.project_volume(ROI_flatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_thresholded = filtered_barcodes_spike_normalised[find_source_not_known['relative_to_max']>threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take sum of 'neurons' with max barcode count in each sample to see distribution of where the soma is\n",
    "source_thresholded_soma_only = pd.DataFrame(columns= source_thresholded.columns)\n",
    "for i, r in source_thresholded.iterrows():\n",
    "    soma_sample = r.idxmax()\n",
    "    row_data = [0] * len(source_thresholded.columns)\n",
    "    barcode_row = pd.DataFrame([row_data], columns=source_thresholded.columns)\n",
    "    barcode_row[r.idxmax()] = 1\n",
    "    source_thresholded_soma_only = pd.concat([source_thresholded_soma_only, barcode_row])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_matrix = np.zeros((len(source_thresholded_soma_only), max(source_thresholded_soma_only.columns.to_list())+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in source_thresholded_soma_only:\n",
    "    barcode_matrix[:, column] = source_thresholded_soma_only[column].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_counts = np.sum(barcode_matrix, axis=0)\n",
    "#now set zero values to -1\n",
    "total_counts[0] = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take sum of 'neurons' with max barcode count in each sample to see distribution of where the soma is\n",
    "# source_thresholded_soma_only_actual_val = pd.DataFrame(columns= source_thresholded.columns)\n",
    "# for i, r in source_thresholded.iterrows():\n",
    "#     soma_sample = r.idxmax()\n",
    "#     row_data = [0] * len(source_thresholded.columns)\n",
    "#     barcode_row = pd.DataFrame([row_data], columns=source_thresholded.columns)\n",
    "#     barcode_row[r.idxmax()] = r[r.idxmax()]\n",
    "#     source_thresholded_soma_only_actual_val = pd.concat([source_thresholded_soma_only_actual_val, barcode_row])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mat = np.log10(1 + total_counts[ROI_projection_max.astype(int)]).T\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"magma\").copy()\n",
    "\n",
    "cmap.set_bad(color=[0.3 , 0.3 , 0.3 , 1 ])  # Set NaN values as grey\n",
    "\n",
    "plt.imshow(new_mat, cmap=cmap)\n",
    "plt.axis('off')\n",
    "plt.colorbar(label='log 10 barcode counts', fraction=0.03, pad=0.04)\n",
    "for k, boundary_coords in bf_left_boundaries.items():\n",
    "    plt.plot(*boundary_coords.T, c=\"white\", lw=0.5)\n",
    "for k, boundary_coords in bf_right_boundaries.items():\n",
    "    plt.plot(*boundary_coords.T, c=\"white\", lw=0.5)\n",
    "plt.title(f'threshold = log 10 (max/2ndmax) > {threshold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = areas.set_index('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_areas = areas.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_areas['fraction_AUDp']= source_areas['AUDp']/source_areas.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_areas = source_areas[source_areas['fraction_AUDp']>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_areas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now look only at the barcodes with max barcode count in area containing at least 10% A1\n",
    "source_thresholded = source_thresholded[source_thresholded.idxmax(axis=1).isin(source_areas.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_thresholded.to_pickle(normalised_barcode_path.parents[0]/'source_filtered_thresholded.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_barcode_path.parents[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAPseq_processing_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
