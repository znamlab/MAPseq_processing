{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import nrrd\n",
    "import bg_space as bg\n",
    "from pprint import pprint\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import seaborn as sb\n",
    "import pathlib\n",
    "from bg_atlasapi import BrainGlobeAtlas\n",
    "from lcm_registration import LCM_registration_functions as lrf\n",
    "from lcm_registration import visualign_functions as vis\n",
    "from znamutils import slurm_it\n",
    "from PIL import Image\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Before using QuickNII, you can run the below code to make LCM section images conform to requirements for lcm registration pipeline (convert images to jpg and making sure they start with '_s0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"/nemo/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/FIAA45.6d/LCM/sections_same_orientation/\"\n",
    "output_folder = \"/nemo/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/FIAA45.6d/LCM/sections_QuickNII/\"\n",
    "\n",
    "lrf.convert_tif_to_jpg(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove mouse name from section images filename.\n",
    "mouse_name = \"FIAA45.6D\"\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.startswith(f\"{mouse_name}_\") and filename.endswith(\".TIF\"):\n",
    "        # Construct the new filename by removing \"FIAA45_\"\n",
    "        new_filename = filename.replace(f\"{mouse_name}_\", \"\")\n",
    "\n",
    "        # Rename the file\n",
    "        os.rename(\n",
    "            os.path.join(input_folder, filename),\n",
    "            os.path.join(input_folder, new_filename),\n",
    "        )\n",
    "        print(f\"Renamed {filename} to {new_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing registration using QuickNII and Visualign softwhare, you can now calculate z distance between sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_path = (\n",
    "    \"/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/FIAA45.6a/Sequencing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convert each registered section image to numpy file containing 2D allen ccf coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_job = lrf.convert_images(\n",
    "    parameters_path=parameters_path,\n",
    "    use_slurm=True,\n",
    "    slurm_folder=\"/camp/home/turnerb/slurm_logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now find find the pixels in the previous section with closest Euclidean distance, in order to calculate z-distance between the two sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf.get_euclidean_distance(\n",
    "    parameters_path=parameters_path,\n",
    "    use_slurm=True,\n",
    "    job_dependency=convert_job,\n",
    "    slurm_folder=\"/camp/home/turnerb/slurm_logs\",\n",
    ")\n",
    "# lcm_dir = '/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/FIAA45.6a/LCM'\n",
    "# lrf.get_euclidean_distance(lcm_dir, use_slurm=False, slurm_folder='/camp/home/turnerb/slurm_logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) check how the z distance between sections looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters =lrf.load_parameters(directory=parameters_path)\n",
    "lcm_dir = pathlib.Path(parameters[\"lcm_directory\"])\n",
    "%matplotlib inline\n",
    "section = 44\n",
    "euclid_dist = np.load(f'{lcm_dir}/allenccf/z_calc/euclid_distance_S0{section}.npy')\n",
    "z_dist = np.load(f'{lcm_dir}/allenccf/z_calc/z_add_S0{section}.npy')\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "sb.heatmap(euclid_dist, ax=axs[0, 0])\n",
    "axs[0, 0].set_title('Nearest Euclidian distance')\n",
    "sb.heatmap(z_dist, ax=axs[0, 1])\n",
    "axs[0, 1].set_title('Z distance')\n",
    "if os.path.isfile(f'{lcm_dir}/sections_same_orientation/S0{section}.TIF'):\n",
    "    image_to_look= f'{lcm_dir}/sections_same_orientation/S0{section}.TIF'\n",
    "elif os.path.isfile(f'{lcm_dir}/sections_same_orientation/S0{section}.tif'):\n",
    "    image_to_look= f'{lcm_dir}/sections_same_orientation/S0{section}.tif'\n",
    "img1 = plt.imread(image_to_look)\n",
    "axs[1, 0].imshow(img1)\n",
    "axs[1, 0].axis('off')\n",
    "axs[1, 0].set_title('Section looked at')\n",
    "if os.path.isfile(f'{lcm_dir}/sections_same_orientation/S0{section+1}.TIF'):\n",
    "    image_to_look_2= f'{lcm_dir}/sections_same_orientation/S0{section+1}.TIF'\n",
    "elif os.path.isfile(f'{lcm_dir}/sections_same_orientation/S0{section+1}.tif'):\n",
    "    image_to_look_2= f'{lcm_dir}/sections_same_orientation/S0{section+1}.tif'\n",
    "img2 = plt.imread(image_to_look_2)\n",
    "\n",
    "axs[1, 1].imshow(img2)\n",
    "axs[1, 1].axis('off')\n",
    "axs[1, 1].set_title('Section before')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now send job to create 3D atlas containing all LCM ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf.get_roi_vol(\n",
    "    parameters_path=parameters_path,\n",
    "    use_slurm=True,\n",
    "    slurm_folder=\"/camp/home/turnerb/slurm_logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calculate volumes and generate brain region annotations for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ROI_coordinates(\n",
    "    parameters_path=parameters_path,\n",
    "    use_slurm=True,\n",
    "    slurm_folder=\"/camp/home/turnerb/slurm_logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = lrf.load_parameters(directory=parameters_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in parameters[\"rois_to_combine\"]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load ROI's to visualise\n",
    "ROI_path = pathlib.Path(lcm_dir) / \"rois\"\n",
    "pixcoord = []\n",
    "for i, axis in enumerate([allencoord_roixa, allencoord_roiya, allencoord_roiza]):\n",
    "    pixel = np.array(np.round(axis / 10), dtype=int)\n",
    "    pixel[pixel < 0] = 0\n",
    "    pixel[pixel >= empty_frame.shape[i]] = 0\n",
    "    pixcoord.append(pixel)\n",
    "new_coord = np.zeros(pixcoord[0].shape)\n",
    "z_add = 0\n",
    "for stack in range(int(np.round(z_to_add / 10))):\n",
    "    for i in range(pixcoord[0].shape[0]):\n",
    "        for j in range(pixcoord[0].shape[1]):\n",
    "            if pixcoord[0][i, j] != 0:\n",
    "                new_coord[i, j] = (pixcoord[0][i, j]) - z_add\n",
    "    z_add = z_add + 1\n",
    "    for k in range(pixcoord[0].shape[0]):\n",
    "        for l in range(pixcoord[0].shape[1]):\n",
    "            x = new_coord[k, l]\n",
    "            y = pixcoord[1][k, l]\n",
    "            z = pixcoord[2][k, l]\n",
    "            if x != 0 and y != 0 and z != 0:\n",
    "                empty_frame[int(x), int(y), int(z)] = int(tube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get e.g. of ROI\n",
    "for ROI_to_look in os.listdir(ROI_path):\n",
    "    # region = ROI_path/'s015_TUBE6.png'\n",
    "    region = ROI_path / ROI_to_look\n",
    "    if ROI_to_look.startswith(\"s0\") or ROI_to_look.startswith(\"S0\"):\n",
    "        slicename = region.stem[1:4]\n",
    "        tube = region.stem[5 : len(region.stem)].split(\"TUBE\", 1)[1]\n",
    "        # if int(tube) in cortical_samples_table['Tube'].to_list():\n",
    "        [xa, ya, za, one] = np.load(reg_dir / f\"allen_ccf_converted_s{slicename}.npy\")\n",
    "        roi = plt.imread(ROI_path / f\"{region}\")\n",
    "        allencoord_roiya = roi * ya\n",
    "        allencoord_roiza = roi * za\n",
    "        allencoord_roixa = roi * xa\n",
    "        z_dist = (\n",
    "            np.load(f\"{lcm_dir}/allenccf/allen_ccf_coord/z_add_s{slicename}.npy\") / 10\n",
    "        )  # convert to 10um pixels\n",
    "\n",
    "        add_z.loc[add_z[\"slice\"] == f\"s{slicename}\", \"amountz\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_dir = pathlib.Path(f\"{lcm_dir}/allenccf/allen_ccf_coord/\")\n",
    "z_averages = []\n",
    "for file in reg_dir.glob(\"z_add_s*.npy\"):\n",
    "    z_file = np.load(file)\n",
    "    z_av = np.mean(z_file)\n",
    "    z_averages.append(z_av)\n",
    "average_z = np.mean(z_averages)\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "\n",
    "mcc = MouseConnectivityCache(resolution=10)\n",
    "avg_temp, meta = mcc.get_template_volume()\n",
    "empty_frame = np.zeros((avg_temp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get e.g. of ROI\n",
    "for ROI_to_look in os.listdir(ROI_path):\n",
    "    # region = ROI_path/'s015_TUBE6.png'\n",
    "    region = ROI_path / ROI_to_look\n",
    "    if ROI_to_look.startswith(\"s0\") or ROI_to_look.startswith(\"S0\"):\n",
    "        slicename = region.stem[1:4]\n",
    "        tube = region.stem[5 : len(region.stem)].split(\"TUBE\", 1)[1]\n",
    "        # if int(tube) in cortical_samples_table['Tube'].to_list():\n",
    "        [xa, ya, za, one] = np.load(reg_dir / f\"allen_ccf_converted_s{slicename}.npy\")\n",
    "        roi = plt.imread(ROI_path / f\"{region}\")\n",
    "        allencoord_roiya = roi * ya\n",
    "        allencoord_roiza = roi * za\n",
    "        allencoord_roixa = roi * xa\n",
    "        z_file = reg_dir / f\"z_add_s{slicename}.npy\"\n",
    "        if z_file.is_file():\n",
    "            z_dist = np.load(z_file)\n",
    "\n",
    "            z_dist_pix = np.round(z_dist / 10)\n",
    "            # convert the x, y, z coordinates to pixel\n",
    "\n",
    "            pixcoord = []\n",
    "            for i, axis in enumerate(\n",
    "                [allencoord_roixa, allencoord_roiya, allencoord_roiza]\n",
    "            ):\n",
    "                pixel = np.array(np.round(axis / 10), dtype=int)\n",
    "                pixel[pixel < 0] = 0\n",
    "                pixel[pixel >= empty_frame.shape[i]] = 0\n",
    "                pixcoord.append(pixel)\n",
    "            for i in range(pixcoord[0].shape[0]):\n",
    "                for j in range(pixcoord[0].shape[1]):\n",
    "                    if pixcoord[0][i, j] != 0:\n",
    "                        for z_add in range(int(z_dist_pix[i, j])):\n",
    "                            x = pixcoord[0][i, j] - z_add\n",
    "                            y = pixcoord[1][i, j]\n",
    "                            z = pixcoord[2][i, j]\n",
    "                            if x != 0 and y != 0 and z != 0:\n",
    "                                empty_frame[int(x), int(y), int(z)] = int(tube)\n",
    "        elif z_file.is_file() == False:\n",
    "            average_z_pix = np.round(average_z / 10)\n",
    "            for i in range(pixcoord[0].shape[0]):\n",
    "                for j in range(pixcoord[0].shape[1]):\n",
    "                    if pixcoord[0][i, j] != 0:\n",
    "                        for z_add in range(int(average_z_pix)):\n",
    "                            x = pixcoord[0][i, j] - z_add\n",
    "                            y = pixcoord[1][i, j]\n",
    "                            z = pixcoord[2][i, j]\n",
    "                            if x != 0 and y != 0 and z != 0:\n",
    "                                empty_frame[int(x), int(y), int(z)] = int(tube)\n",
    "                # new_coord[i,j] = (pixcoord[0][i, j])-z_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{lcm_dir}/ROI_flatmap.npy\", empty_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAPseq_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
