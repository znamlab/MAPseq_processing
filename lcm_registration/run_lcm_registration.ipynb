{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import nrrd\n",
    "import bg_space as bg\n",
    "from pprint import pprint\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import seaborn as sb\n",
    "import pathlib\n",
    "from bg_atlasapi import BrainGlobeAtlas\n",
    "from lcm_registration import lcm_registration_functions as lrf\n",
    "from lcm_registration import visualign_functions as vis\n",
    "from znamutils import slurm_it\n",
    "from PIL import Image\n",
    "import os\n",
    "import yaml\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Before using QuickNII, you can run the below code to make LCM section images conform to requirements for lcm registration pipeline (convert images to jpg and making sure they start with '_s0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"/nemo/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/FIAA45.6d/LCM/sections_same_orientation/\"\n",
    "output_folder = \"/nemo/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/FIAA45.6d/LCM/sections_QuickNII/\"\n",
    "\n",
    "lrf.convert_tif_to_jpg(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove mouse name from section images filename.\n",
    "mouse_name = \"FIAA45.6D\"\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.startswith(f\"{mouse_name}_\") and filename.endswith(\".TIF\"):\n",
    "        new_filename = filename.replace(f\"{mouse_name}_\", \"\")\n",
    "        os.rename(\n",
    "            os.path.join(input_folder, filename),\n",
    "            os.path.join(input_folder, new_filename),\n",
    "        )\n",
    "        print(f\"Renamed {filename} to {new_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing registration using QuickNII and Visualign softwhare, you can now calculate z distance between sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = 'FIAA55.4d'\n",
    "parameters_path = (\n",
    "    f\"/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/{mouse}/Sequencing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convert each registered section image to numpy file containing 2D allen ccf coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_job = lrf.convert_images(\n",
    "    parameters_path=parameters_path,\n",
    "    use_slurm=True,\n",
    "    slurm_folder=\"/camp/home/turnerb/slurm_logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now find find the pixels in the previous section with closest Euclidean distance, in order to calculate z-distance between the two sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf.get_euclidean_distance(\n",
    "    parameters_path=parameters_path,\n",
    "    use_slurm=True,\n",
    "    job_dependency=convert_job,\n",
    "    slurm_folder=\"/camp/home/turnerb/slurm_logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) check how the z distance between sections looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters =lrf.load_parameters(directory=parameters_path)\n",
    "section = 44\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "lrf.check_z_dist(lcm_dir=pathlib.Path(parameters[\"lcm_directory\"]), section=section, fig=fig, axs=axs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now send job to create 3D atlas containing all LCM ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf.get_roi_vol(\n",
    "    parameters_path=parameters_path,\n",
    "    use_slurm=True,\n",
    "    slurm_folder=\"/camp/home/turnerb/slurm_logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calculate volumes and generate brain region annotations for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf.group_ROI_coordinates(\n",
    "    parameters_path=parameters_path,\n",
    "    use_slurm=True,\n",
    "    slurm_folder=\"/camp/home/turnerb/slurm_logs\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAPseq_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
