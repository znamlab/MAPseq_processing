{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB need to use environment with python3.9 or above for ccf_streamlines to run\n",
    "import nrrd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ccf_streamlines.projection as ccfproj\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib.colors import LogNorm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcm_directory = pathlib.Path(\n",
    "    \"/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/FIAA45.6a/LCM\"\n",
    ")\n",
    "# load datasets\n",
    "barcodes_across_sample = pd.read_pickle(\n",
    "    \"/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/FIAA45.6a/Sequencing/barcode_matrix_soma_thresholded.pkl\"\n",
    ")\n",
    "ROI_3D = np.load(lcm_directory / \"ROI_3D_10.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the path to where the ccf streamlines downloads is (so don't change when looking a different mice)\n",
    "convert_to_flat_path = pathlib.Path(\n",
    "    \"/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/FIAA32.6a/LCM_registration\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore barcodes that are only found in one sample\n",
    "barcodes_across_sample = barcodes_across_sample[\n",
    "    barcodes_across_sample.astype(bool).sum(axis=1) > 1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cortical_samples = [\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10,\n",
    "    11,\n",
    "    13,\n",
    "    14,\n",
    "    15,\n",
    "    16,\n",
    "    17,\n",
    "    18,\n",
    "    19,\n",
    "    20,\n",
    "    25,\n",
    "    26,\n",
    "    27,\n",
    "    28,\n",
    "    29,\n",
    "    30,\n",
    "    31,\n",
    "    32,\n",
    "    33,\n",
    "    37,\n",
    "    38,\n",
    "    39,\n",
    "    40,\n",
    "    41,\n",
    "    42,\n",
    "    43,\n",
    "    44,\n",
    "    45,\n",
    "    46,\n",
    "    51,\n",
    "    52,\n",
    "    53,\n",
    "    54,\n",
    "    55,\n",
    "    56,\n",
    "    57,\n",
    "    58,\n",
    "    59,\n",
    "    60,\n",
    "    61,\n",
    "    62,\n",
    "    63,\n",
    "    66,\n",
    "    70,\n",
    "    71,\n",
    "    72,\n",
    "    73,\n",
    "    74,\n",
    "    75,\n",
    "    76,\n",
    "    77,\n",
    "    78,\n",
    "    79,\n",
    "    80,\n",
    "    81,\n",
    "    82,\n",
    "    83,\n",
    "    84,\n",
    "    85,\n",
    "    86,\n",
    "    87,\n",
    "    88,\n",
    "    93,\n",
    "    94,\n",
    "    95,\n",
    "    96,\n",
    "    97,\n",
    "    98,\n",
    "    99,\n",
    "    100,\n",
    "    101,\n",
    "    102,\n",
    "    103,\n",
    "    104,\n",
    "    105,\n",
    "    106,\n",
    "    107,\n",
    "    108,\n",
    "    109,\n",
    "    110,\n",
    "    111,\n",
    "    112,\n",
    "    113,\n",
    "    117,\n",
    "    118,\n",
    "    119,\n",
    "    120,\n",
    "    121,\n",
    "    122,\n",
    "    123,\n",
    "    124,\n",
    "    125,\n",
    "    126,\n",
    "    127,\n",
    "    128,\n",
    "    132,\n",
    "    133,\n",
    "    134,\n",
    "    135,\n",
    "    136,\n",
    "    137,\n",
    "    138,\n",
    "    139,\n",
    "    140,\n",
    "    141,\n",
    "    142,\n",
    "    143,\n",
    "    147,\n",
    "    148,\n",
    "    149,\n",
    "    150,\n",
    "    151,\n",
    "    153,\n",
    "    154,\n",
    "    155,\n",
    "    156,\n",
    "    157,\n",
    "    158,\n",
    "    159,\n",
    "    161,\n",
    "    162,\n",
    "    163,\n",
    "    164,\n",
    "    165,\n",
    "    167,\n",
    "    168,\n",
    "    169,\n",
    "    170,\n",
    "    172,\n",
    "    173,\n",
    "    174,\n",
    "    175,\n",
    "    177,\n",
    "    178,\n",
    "    179,\n",
    "    180,\n",
    "    181,\n",
    "    182,\n",
    "    183,\n",
    "    184,\n",
    "    185,\n",
    "    186,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cortical_samples = [\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    8,\n",
    "    9,\n",
    "    10,\n",
    "    11,\n",
    "    12,\n",
    "    14,\n",
    "    15,\n",
    "    16,\n",
    "    17,\n",
    "    18,\n",
    "    19,\n",
    "    20,\n",
    "    21,\n",
    "    22,\n",
    "    23,\n",
    "    27,\n",
    "    28,\n",
    "    29,\n",
    "    30,\n",
    "    31,\n",
    "    32,\n",
    "    33,\n",
    "    34,\n",
    "    39,\n",
    "    40,\n",
    "    41,\n",
    "    42,\n",
    "    43,\n",
    "    44,\n",
    "    45,\n",
    "    46,\n",
    "    47,\n",
    "    48,\n",
    "    49,\n",
    "    50,\n",
    "    54,\n",
    "    57,\n",
    "    58,\n",
    "    59,\n",
    "    60,\n",
    "    61,\n",
    "    62,\n",
    "    63,\n",
    "    64,\n",
    "    65,\n",
    "    66,\n",
    "    67,\n",
    "    72,\n",
    "    73,\n",
    "    74,\n",
    "    76,\n",
    "    77,\n",
    "    78,\n",
    "    79,\n",
    "    80,\n",
    "    81,\n",
    "    82,\n",
    "    83,\n",
    "    84,\n",
    "    85,\n",
    "    86,\n",
    "    87,\n",
    "    88,\n",
    "    89,\n",
    "    90,\n",
    "    91,\n",
    "    92,\n",
    "    93,\n",
    "    94,\n",
    "    95,\n",
    "    96,\n",
    "    97,\n",
    "    98,\n",
    "    99,\n",
    "    100,\n",
    "    101,\n",
    "    102,\n",
    "    103,\n",
    "    104,\n",
    "    105,\n",
    "    109,\n",
    "    110,\n",
    "    111,\n",
    "    112,\n",
    "    113,\n",
    "    114,\n",
    "    115,\n",
    "    116,\n",
    "    117,\n",
    "    118,\n",
    "    119,\n",
    "    120,\n",
    "    126,\n",
    "    127,\n",
    "    128,\n",
    "    129,\n",
    "    131,\n",
    "    132,\n",
    "    133,\n",
    "    134,\n",
    "    135,\n",
    "    136,\n",
    "    139,\n",
    "    144,\n",
    "    145,\n",
    "    146,\n",
    "    147,\n",
    "    148,\n",
    "    151,\n",
    "    152,\n",
    "    153,\n",
    "    154,\n",
    "    155,\n",
    "    156,\n",
    "    157,\n",
    "    159,\n",
    "    160,\n",
    "    161,\n",
    "    162,\n",
    "    163,\n",
    "    164,\n",
    "    166,\n",
    "    167,\n",
    "    168,\n",
    "    169,\n",
    "    171,\n",
    "    172,\n",
    "    173,\n",
    "    174,\n",
    "    175,\n",
    "    176,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any samples from 3D array that aren't cortical for flatmap visualisation\n",
    "mask = np.isin(ROI_3D, cortical_samples)\n",
    "ROI_3D[~mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_boundary_finder = ccfproj.BoundaryFinder(\n",
    "    projected_atlas_file=convert_to_flat_path / \"flatmap_butterfly.nrrd\",\n",
    "    labels_file=convert_to_flat_path / \"labelDescription_ITKSNAPColor.txt\",\n",
    ")\n",
    "\n",
    "# We get the left hemisphere region boundaries with the default arguments\n",
    "bf_left_boundaries = bf_boundary_finder.region_boundaries()\n",
    "\n",
    "# And we can get the right hemisphere boundaries that match up with\n",
    "# our projection if we specify the same configuration\n",
    "bf_right_boundaries = bf_boundary_finder.region_boundaries(\n",
    "    # we want the right hemisphere boundaries, but located in the right place\n",
    "    # to plot both hemispheres at the same time\n",
    "    hemisphere=\"right_for_both\",\n",
    "    # we also want the hemispheres to be adjacent\n",
    "    view_space_for_other_hemisphere=\"flatmap_butterfly\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_top = ccfproj.Isocortex2dProjector(\n",
    "    # Specify our view lookup file\n",
    "    convert_to_flat_path / \"flatmap_butterfly.h5\",\n",
    "    # Specify our streamline file\n",
    "    convert_to_flat_path / \"surface_paths_10_v3.h5\",\n",
    "    # Specify that we want to project both hemispheres\n",
    "    hemisphere=\"both\",\n",
    "    # The top view contains space for the right hemisphere, but is empty.\n",
    "    # Therefore, we tell the projector to put both hemispheres side-by-side\n",
    "    view_space_for_other_hemisphere=\"flatmap_butterfly\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tubes in ROI flatmap that aren't in normalised barcode path\n",
    "tubes = np.arange(\n",
    "    np.min(barcodes_across_sample.columns), np.max(barcodes_across_sample.columns), 1\n",
    ")\n",
    "tubes_not_in = [i for i in tubes if i not in barcodes_across_sample.columns.to_list()]\n",
    "for x in tubes_not_in:\n",
    "    ROI_3D[ROI_3D == x] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_projection_max = proj_top.project_volume(ROI_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_matrix = np.zeros(\n",
    "    (\n",
    "        len(barcodes_across_sample),\n",
    "        max(barcodes_across_sample.columns.to_list()) + 1,\n",
    "    )\n",
    ")\n",
    "for column in barcodes_across_sample:\n",
    "    barcode_matrix[:, column] = barcodes_across_sample[column].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = np.sum(barcode_matrix, axis=0)\n",
    "# now set zero values to -1\n",
    "total_counts[0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mat = np.log10(1 + total_counts[ROI_projection_max.astype(int)]).T\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"magma\").copy()\n",
    "\n",
    "cmap.set_bad(color=[0.3, 0.3, 0.3, 1])  # Set NaN values as grey\n",
    "\n",
    "plt.imshow(new_mat, cmap=cmap)\n",
    "plt.axis(\"off\")\n",
    "plt.colorbar(label=\"log 10 barcode counts\", fraction=0.03, pad=0.04)\n",
    "for k, boundary_coords in bf_left_boundaries.items():\n",
    "    plt.plot(*boundary_coords.T, c=\"white\", lw=0.5)\n",
    "for k, boundary_coords in bf_right_boundaries.items():\n",
    "    plt.plot(*boundary_coords.T, c=\"white\", lw=0.5)\n",
    "plt.title(f\"Distribution of total MAPseq counts FIAA45.6a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_strength = np.zeros(total_counts.shape)\n",
    "for i in np.unique(ROI_3D):\n",
    "    if int(i) > 0:\n",
    "        vol = len(ROI_3D[ROI_3D==i])*25\n",
    "        proj_strength[int(i)] = total_counts[int(i)]/vol\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_strength[int(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_strength[0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mat = np.log10(1 + proj_strength[ROI_projection_max.astype(int)]).T\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"magma\").copy()\n",
    "\n",
    "cmap.set_bad(color=[0.3, 0.3, 0.3, 1])  # Set NaN values as grey\n",
    "\n",
    "plt.imshow(new_mat, cmap=cmap)\n",
    "plt.axis(\"off\")\n",
    "plt.colorbar(label=\"log 10 barcode counts/$um^{3}$\", fraction=0.03, pad=0.04)\n",
    "for k, boundary_coords in bf_left_boundaries.items():\n",
    "    plt.plot(*boundary_coords.T, c=\"white\", lw=0.5)\n",
    "for k, boundary_coords in bf_right_boundaries.items():\n",
    "    plt.plot(*boundary_coords.T, c=\"white\", lw=0.5)\n",
    "plt.title(f\"Distribution of MAPseq counts/volume FIAA45.6a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now look at where soma locations are\n",
    "# take sum of 'neurons' with max barcode count in each sample to see distribution of where the soma is\n",
    "source_thresholded_soma_only_actual_val = pd.DataFrame(\n",
    "    columns=barcodes_across_sample.columns\n",
    ")\n",
    "for i, r in barcodes_across_sample.iterrows():\n",
    "    soma_sample = r.idxmax()\n",
    "    row_data = [0] * len(barcodes_across_sample.columns)\n",
    "    barcode_row = pd.DataFrame([row_data], columns=barcodes_across_sample.columns)\n",
    "    barcode_row[r.idxmax()] = 1\n",
    "    source_thresholded_soma_only_actual_val = pd.concat(\n",
    "        [source_thresholded_soma_only_actual_val, barcode_row]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_matrix = np.zeros(\n",
    "    (\n",
    "        len(barcodes_across_sample),\n",
    "        max(barcodes_across_sample.columns.to_list()) + 1,\n",
    "    )\n",
    ")\n",
    "for column in source_thresholded_soma_only_actual_val:\n",
    "    soma_matrix[:, column] = source_thresholded_soma_only_actual_val[column].to_numpy()\n",
    "soma_counts = np.sum(soma_matrix, axis=0)\n",
    "\n",
    "\n",
    "# now set zero values to -1\n",
    "soma_counts[0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_mat = log_soma[ROI_projection_max.astype(int)].T\n",
    "new_mat = np.log10(1 + soma_counts[ROI_projection_max.astype(int)]).T\n",
    "cmap = plt.cm.get_cmap(\"magma\").copy()\n",
    "\n",
    "cmap.set_bad(color=[0.3, 0.3, 0.3, 1])  # Set NaN values as grey\n",
    "\n",
    "plt.imshow(new_mat, cmap=cmap)\n",
    "plt.axis(\"off\")\n",
    "plt.colorbar(label=\"log 10 neuron counts\", fraction=0.03, pad=0.04)\n",
    "for k, boundary_coords in bf_left_boundaries.items():\n",
    "    plt.plot(*boundary_coords.T, c=\"white\", lw=0.5)\n",
    "for k, boundary_coords in bf_right_boundaries.items():\n",
    "    plt.plot(*boundary_coords.T, c=\"white\", lw=0.5)\n",
    "plt.title(f\"Location of barcode cell bodies FIAA45.6a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_thresholded_soma_only_actual_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_across_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_counts.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAPseq_processing_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
