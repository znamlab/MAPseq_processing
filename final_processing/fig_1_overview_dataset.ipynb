{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import ast\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sb\n",
    "from preprocessing_sequencing import preprocess_sequences as ps\n",
    "from matplotlib import rcParams\n",
    "from final_processing import final_processing_functions as fpf\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "from decimal import Decimal\n",
    "from matplotlib.colors import LogNorm\n",
    "import itertools\n",
    "from flexiznam.config import PARAMETERS\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice = [\"FIAA45.6a\", \"FIAA45.6d\", \"FIAA55.4d\"]\n",
    "processed_path = Path(PARAMETERS[\"data_root\"][\"processed\"])\n",
    "proj_path = processed_path / \"turnerb_A1_MAPseq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen_comp_dict = {}\n",
    "to_plot = pd.DataFrame()\n",
    "\n",
    "for mouse in mice:\n",
    "    parameters_path = proj_path / mouse / \"Sequencing\"\n",
    "    barcodes = pd.read_pickle(\n",
    "        parameters_path / \"A1_barcodes_thresholded_with_source.pkl\"\n",
    "    )\n",
    "    # select only cortical samples\n",
    "    parameters = fpf.load_parameters(directory=parameters_path)\n",
    "    cortical_samples = parameters[\"cortical_samples\"]\n",
    "    cortical_samples = [\n",
    "        sample for sample in cortical_samples if sample in barcodes.columns\n",
    "    ]\n",
    "    barcodes = barcodes[cortical_samples]\n",
    "    failed_RT = barcodes.loc[:, (barcodes == 0).all()].columns\n",
    "    barcodes.drop(columns=failed_RT, inplace=True)\n",
    "    allen_comp_dict[mouse] = fpf.compare_to_allen(\n",
    "        barcode_table=barcodes, parameters_path=str(parameters_path)\n",
    "    )\n",
    "    temp_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Allen\": np.log10(allen_comp_dict[mouse][\"Mean_Allen\"] + 1e-3),\n",
    "            \"MAPseq\": np.log10(allen_comp_dict[mouse][\"MAPseq_counts\"] + 1e-3),\n",
    "            \"Mouse\": mouse,\n",
    "            \"Allen_expt_A\": np.log10(allen_comp_dict[mouse][\"Allen_expt_a\"] + 1e-3),\n",
    "            \"Allen_expt_B\": np.log10(allen_comp_dict[mouse][\"Allen_expt_b\"] + 1e-3),\n",
    "            \"Allen_expt_C\": np.log10(allen_comp_dict[mouse][\"Allen_expt_c\"] + 1e-3),\n",
    "        }\n",
    "    )\n",
    "    temp_df[\"Allen_Z_core\"] = (temp_df[\"Allen\"] - temp_df[\"Allen\"].mean()) / temp_df[\n",
    "        \"Allen\"\n",
    "    ].std()\n",
    "    temp_df[\"MAPseq_Z_score\"] = (\n",
    "        temp_df[\"MAPseq\"] - temp_df[\"MAPseq\"].mean()\n",
    "    ) / temp_df[\"MAPseq\"].std()\n",
    "    temp_df[\"Allen_expt_A_Z_score\"] = (\n",
    "        temp_df[\"Allen_expt_A\"] - temp_df[\"Allen_expt_A\"].mean()\n",
    "    ) / temp_df[\"Allen_expt_A\"].std()\n",
    "    temp_df[\"Allen_expt_B_Z_score\"] = (\n",
    "        temp_df[\"Allen_expt_B\"] - temp_df[\"Allen_expt_B\"].mean()\n",
    "    ) / temp_df[\"Allen_expt_B\"].std()\n",
    "    temp_df[\"Allen_expt_C_Z_score\"] = (\n",
    "        temp_df[\"Allen_expt_C\"] - temp_df[\"Allen_expt_C\"].mean()\n",
    "    ) / temp_df[\"Allen_expt_C\"].std()\n",
    "    to_plot = pd.concat([to_plot, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.set(style=\"white\")\n",
    "sb.set_palette([\"#3498DB\", \"#21618C\", \"#A9CCE3\"])\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "sb.scatterplot(data=to_plot, x=\"Allen_Z_core\", y=\"MAPseq_Z_score\", hue=\"Mouse\", s=20)\n",
    "sb.regplot(\n",
    "    data=to_plot, x=\"Allen_Z_core\", y=\"MAPseq_Z_score\", scatter=False, color=\"grey\"\n",
    ")\n",
    "# corr, p = pearsonr(\n",
    "#     to_plot[\"Allen_Z_core\"], y=to_plot[\"MAPseq_Z_score\"]\n",
    "# )\n",
    "corr, p = pearsonr(to_plot[\"Allen_Z_core\"], to_plot[\"MAPseq_Z_score\"])\n",
    "# plt.title(\n",
    "#     f\"r = {np.round(corr, 3)}, p = {Decimal(p):.2E}\"\n",
    "# )\n",
    "plt.xlabel(\"Projection Strength \\n Bulk GFP (Z score)\", size=18)\n",
    "plt.ylabel(\"Projection Strength \\n MAPseq (Z score)\", size=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=\"medium\", bbox_to_anchor=(0.01, 0.93))\n",
    "plt.text(\n",
    "    0.02,\n",
    "    0.98,\n",
    "    f\"r = {np.round(corr, 3)}, p = {Decimal(p):.2E}\",\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=14,\n",
    "    verticalalignment=\"top\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "which_expt = [\"Allen_expt_A_Z_score\", \"Allen_expt_B_Z_score\", \"Allen_expt_C_Z_score\"]\n",
    "expt_name = [\"Expt A\", \"Expt B\", \"Expt C\"]\n",
    "legend_entries = [\"Mean\"]\n",
    "\n",
    "for A, B in itertools.combinations([0, 1, 2], 2):\n",
    "    sb.scatterplot(data=to_plot, x=which_expt[A], y=which_expt[B], marker=\"X\")\n",
    "    corr, p = pearsonr(to_plot[which_expt[A]], to_plot[which_expt[B]])\n",
    "    legend_entries.append(f\"{expt_name[A]} vs {expt_name[B]} (r={np.round(corr, 2)})\")\n",
    "sb.regplot(\n",
    "    data=to_plot, x=\"Allen_Z_core\", y=\"Allen_Z_core\", scatter=False, color=\"grey\"\n",
    ")\n",
    "plt.legend(legend_entries, loc=\"lower right\", fontsize=\"medium\")\n",
    "plt.xlabel(\"Projection Strength \\n Expt. X Bulk GFP (Z score)\", size=18)\n",
    "plt.ylabel(\"Projection Strength \\n Expt. Y Bulk GFP (Z score)\", size=18)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_broad_regions(dataframe, regions_to_add):\n",
    "    summed_data = {}\n",
    "    for area, tubes in regions_to_add.items():\n",
    "        valid_tubes = [tube for tube in tubes if tube in dataframe.columns]\n",
    "        summed_data[area] = dataframe[valid_tubes].sum(axis=1)\n",
    "\n",
    "    df_result = pd.DataFrame(summed_data)\n",
    "    df_result = df_result.loc[(df_result != 0).any(axis=1)]\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_to_combine = {}\n",
    "mean_umi_tab = pd.DataFrame()\n",
    "mice = [\"FIAA45.6a\", \"FIAA45.6d\", \"FIAA55.4d\"]\n",
    "for i, mouse in enumerate(mice):\n",
    "    which_samples = {}\n",
    "    parameters_path = proj_path / mouse / \"Sequencing\"\n",
    "    # Load the barcode data for the current mouse\n",
    "    barcodes = pd.read_pickle(parameters_path / \"A1_barcodes_thresholded.pkl\")\n",
    "    failed_RT = barcodes.loc[:, (barcodes == 0).all()].columns\n",
    "    barcodes.drop(columns=failed_RT, inplace=True)\n",
    "    parameters = ps.load_parameters(directory=parameters_path)\n",
    "    # which_samples['Pons'] = parameters['pons_samples']\n",
    "    which_samples[\"Ipsi Cortex\"] = [\n",
    "        sample\n",
    "        for sample in parameters[\"cortical_samples\"]\n",
    "        if sample not in parameters[\"contra\"]\n",
    "    ]\n",
    "    which_samples[\"Contra Cortex\"] = parameters[\"contra\"]\n",
    "    which_samples[\"Striatum\"] = parameters[\"striatum_samples\"]\n",
    "    which_samples[\"Tectum\"] = parameters[\"tectum_samples\"]\n",
    "    which_samples[\"Thalamus\"] = parameters[\"thalamus_samples\"]\n",
    "    which_samples[\"IC\"] = parameters[\"IC_samples\"]\n",
    "    which_samples[\"SC\"] = parameters[\"SC_samples\"]\n",
    "    table_to_look = combine_broad_regions(\n",
    "        dataframe=barcodes, regions_to_add=which_samples\n",
    "    )\n",
    "    mean_umi_dict = {}\n",
    "    for key in which_samples.keys():\n",
    "        samples = [\n",
    "            sample for sample in which_samples[key] if sample in barcodes.columns\n",
    "        ]\n",
    "        selection = barcodes[barcodes[samples].astype(bool).sum(axis=1) > 0][\n",
    "            samples\n",
    "        ].melt()\n",
    "        values = [val for val in selection[\"value\"] if val > 0]\n",
    "        mean_umi_dict[key] = np.mean(values)\n",
    "    mean_umi_dict[\"mouse\"] = mouse\n",
    "    mean_umi_tab = mean_umi_tab.append(mean_umi_dict, ignore_index=True)\n",
    "    if i == 0:\n",
    "        combined_table = table_to_look\n",
    "    else:\n",
    "        combined_table = pd.concat([combined_table, table_to_look])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "striatum_projecting = combined_table[combined_table[\"Striatum\"] > 0]\n",
    "PT_num = len(\n",
    "    striatum_projecting[\n",
    "        striatum_projecting[[\"Tectum\", \"Thalamus\"]].astype(bool).astype(int).sum(axis=1)\n",
    "        > 0\n",
    "    ]\n",
    ")\n",
    "contra_num = len(\n",
    "    striatum_projecting[\n",
    "        striatum_projecting[[\"Contra Cortex\"]].astype(bool).astype(int).sum(axis=1) > 0\n",
    "    ]\n",
    ")\n",
    "overlapping_num = len(\n",
    "    striatum_projecting[\n",
    "        (\n",
    "            striatum_projecting[[\"Tectum\", \"Thalamus\"]]\n",
    "            .astype(bool)\n",
    "            .astype(int)\n",
    "            .sum(axis=1)\n",
    "            > 0\n",
    "        )\n",
    "        & (striatum_projecting[\"Contra Cortex\"].astype(bool).astype(int) > 0)\n",
    "    ]\n",
    ")\n",
    "wrong_thal = len(\n",
    "    striatum_projecting[\n",
    "        (striatum_projecting[\"Thalamus\"].astype(bool).astype(int) > 0)\n",
    "        & (striatum_projecting[\"Tectum\"].astype(bool).astype(int) == 0)\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    f\"number PT = {PT_num}, number contra IT = {contra_num}, number overlapping = {overlapping_num}, thal_not_tect= {wrong_thal}, tot_striatum = {len(striatum_projecting)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.set(font_scale=1, style=\"white\")\n",
    "areas_to_look = [\n",
    "    \"Ipsi Cortex\",\n",
    "    \"Contra Cortex\",\n",
    "    \"Striatum\",\n",
    "    \"IC\",\n",
    "    \"SC\",\n",
    "    \"Thalamus\",\n",
    "]\n",
    "combined_table_to_look = combined_table[areas_to_look]\n",
    "cluster = sb.clustermap(\n",
    "    combined_table_to_look.T,\n",
    "    metric=\"canberra\",\n",
    "    row_cluster=True,\n",
    "    standard_scale=0,\n",
    "    norm=LogNorm(),\n",
    "    cmap=\"Blues\",\n",
    "    figsize=(6, 4),\n",
    "    xticklabels=False,\n",
    "    yticklabels=True,\n",
    "    cbar_pos=(0.8, 0.12, 0.02, 0.65),\n",
    "    cbar_kws={\"label\": \"Normalised \\n projection strength\"},\n",
    ")\n",
    "\n",
    "cluster.ax_row_dendrogram.set_visible(False)\n",
    "cluster.ax_col_dendrogram.set_visible(False)\n",
    "cluster.ax_heatmap.yaxis.set_ticks_position(\"left\")\n",
    "cluster.ax_heatmap.yaxis.set_label_position(\"left\")\n",
    "cluster.ax_heatmap.set_xlabel(\"\")  # Set empty string to remove x-axis label\n",
    "\n",
    "for spine in cluster.ax_heatmap.spines.values():\n",
    "    spine.set_visible(True)  # Make the spines visible\n",
    "    spine.set_linewidth(2)  # Set border width\n",
    "    spine.set_color(\"black\")  # Set border color\n",
    "for spine in cluster.cax.spines.values():\n",
    "    spine.set_visible(True)\n",
    "    spine.set_linewidth(2)  # Set border width\n",
    "    spine.set_color(\"black\")\n",
    "cluster.cax.set_ylabel(\"Projection strength\", fontsize=16)\n",
    "num_barcodes = len(combined_table)\n",
    "tick_positions = range(0, num_barcodes, 1000)\n",
    "tick_labels = [str(pos) for pos in tick_positions]\n",
    "cluster.ax_heatmap.set_xticks(tick_positions)  # Set the position of the ticks\n",
    "cluster.ax_heatmap.set_xticklabels(tick_labels, rotation=0)  # Set the tick labels\n",
    "cluster.ax_heatmap.tick_params(\n",
    "    axis=\"x\", which=\"both\", length=5, color=\"black\"\n",
    ")  # Ensure tick marks are visible\n",
    "cluster.ax_heatmap.tick_params(axis=\"y\", which=\"major\", labelsize=16)\n",
    "cluster.ax_heatmap.tick_params(axis=\"x\", which=\"major\", labelsize=16)\n",
    "cluster.ax_heatmap.xaxis.set_ticks_position(\"top\")  # Move ticks to the top\n",
    "cluster.ax_heatmap.xaxis.set_label_position(\"top\")\n",
    "cluster.ax_heatmap.set_xlabel(\"Neurons\", fontsize=16, labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "IT = {}\n",
    "PT = {}\n",
    "CT = {}\n",
    "layers = [\"upper\", \"lower\"]\n",
    "for num, mouse in enumerate(mice):\n",
    "    new_dict = {}\n",
    "    parameters_path = proj_path / mouse / \"Sequencing\"\n",
    "    barcodes = pd.read_pickle(\n",
    "        parameters_path / \"A1_barcodes_thresholded_with_source.pkl\"\n",
    "    )\n",
    "    parameters = ps.load_parameters(directory=parameters_path)\n",
    "    sample_vol_and_regions = pd.read_pickle(\n",
    "        processed_path\n",
    "        / (\"turnerb_\" + parameters[\"lcm_directory\"].split(\"turnerb_\")[1])\n",
    "        / \"sample_vol_and_regions.pkl\"\n",
    "    )\n",
    "    sample_vol_and_regions[\"fractions\"] = sample_vol_and_regions[\"breakdown\"].apply(\n",
    "        ast.literal_eval\n",
    "    )\n",
    "    sample_vol_and_regions[\"regions\"] = sample_vol_and_regions[\"regions\"].apply(\n",
    "        ast.literal_eval\n",
    "    )\n",
    "    AUDp_containing = sample_vol_and_regions[sample_vol_and_regions[\"main\"] == \"AUDp\"][\n",
    "        \"ROI Number\"\n",
    "    ].to_list()\n",
    "    AUDp_containing = [\n",
    "        sample for sample in AUDp_containing if sample in barcodes.columns\n",
    "    ]\n",
    "    for layer in layers:\n",
    "        if num == 0:\n",
    "            IT[layer] = []\n",
    "            CT[layer] = []\n",
    "            PT[layer] = []\n",
    "        new_dict[f\"{layer}_layer\"] = barcodes[\n",
    "            barcodes.idxmax(axis=1).isin(parameters[f\"{layer}_layer\"])\n",
    "        ].drop(columns=AUDp_containing)\n",
    "        IT[layer].append(\n",
    "            len(\n",
    "                new_dict[f\"{layer}_layer\"][\n",
    "                    (\n",
    "                        new_dict[f\"{layer}_layer\"][\n",
    "                            [\n",
    "                                f\n",
    "                                for f in parameters[\"cortical_samples\"]\n",
    "                                if f in new_dict[f\"{layer}_layer\"].columns\n",
    "                            ]\n",
    "                        ]\n",
    "                        .astype(bool)\n",
    "                        .sum(axis=1)\n",
    "                        > 0\n",
    "                    )\n",
    "                    & (\n",
    "                        new_dict[f\"{layer}_layer\"][\n",
    "                            [\n",
    "                                s\n",
    "                                for s in parameters[\"tectum_samples\"]\n",
    "                                if s in new_dict[f\"{layer}_layer\"].columns\n",
    "                            ]\n",
    "                        ]\n",
    "                        .astype(bool)\n",
    "                        .sum(axis=1)\n",
    "                        == 0\n",
    "                    )\n",
    "                    & (\n",
    "                        new_dict[f\"{layer}_layer\"][\n",
    "                            [\n",
    "                                s\n",
    "                                for s in parameters[\"thalamus_samples\"]\n",
    "                                if s in new_dict[f\"{layer}_layer\"].columns\n",
    "                            ]\n",
    "                        ]\n",
    "                        .astype(bool)\n",
    "                        .sum(axis=1)\n",
    "                        == 0\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        PT[layer].append(\n",
    "            len(\n",
    "                new_dict[f\"{layer}_layer\"][\n",
    "                    new_dict[f\"{layer}_layer\"][\n",
    "                        [\n",
    "                            f\n",
    "                            for f in parameters[\"tectum_samples\"]\n",
    "                            if f in new_dict[f\"{layer}_layer\"].columns\n",
    "                        ]\n",
    "                    ]\n",
    "                    .astype(bool)\n",
    "                    .sum(axis=1)\n",
    "                    > 0\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        CT[layer].append(\n",
    "            len(\n",
    "                new_dict[f\"{layer}_layer\"][\n",
    "                    (\n",
    "                        new_dict[f\"{layer}_layer\"][\n",
    "                            [\n",
    "                                s\n",
    "                                for s in parameters[\"tectum_samples\"]\n",
    "                                if s in new_dict[f\"{layer}_layer\"].columns\n",
    "                            ]\n",
    "                        ]\n",
    "                        .astype(bool)\n",
    "                        .sum(axis=1)\n",
    "                        == 0\n",
    "                    )\n",
    "                    & (\n",
    "                        new_dict[f\"{layer}_layer\"][\n",
    "                            [\n",
    "                                s\n",
    "                                for s in parameters[\"thalamus_samples\"]\n",
    "                                if s in new_dict[f\"{layer}_layer\"].columns\n",
    "                            ]\n",
    "                        ]\n",
    "                        .astype(bool)\n",
    "                        .sum(axis=1)\n",
    "                        > 0\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "tot_IT_upper = np.sum(IT[\"upper\"])\n",
    "tot_IT_lower = np.sum(IT[\"lower\"])\n",
    "tot_PT_upper = np.sum(PT[\"upper\"])\n",
    "tot_CT_upper = np.sum(CT[\"upper\"])\n",
    "tot_PT_lower = np.sum(PT[\"lower\"])\n",
    "tot_CT_lower = np.sum(CT[\"lower\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\"Upper Layer\", \"Deep Layer\"]\n",
    "IT_neurons = [tot_IT_upper, tot_IT_lower]\n",
    "PT_neurons = [tot_PT_upper, tot_PT_lower]\n",
    "CT_neurons = [tot_CT_upper, tot_CT_lower]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "bar_width = 0.6\n",
    "ax.bar(layers, IT_neurons, label=\"IT Neurons\", color=\"steelblue\", width=bar_width)\n",
    "ax.bar(\n",
    "    layers,\n",
    "    PT_neurons,\n",
    "    bottom=IT_neurons,\n",
    "    label=\"PT Neurons\",\n",
    "    color=\"skyblue\",\n",
    "    width=bar_width,\n",
    ")\n",
    "ax.bar(\n",
    "    layers,\n",
    "    CT_neurons,\n",
    "    bottom=[i + j for i, j in zip(IT_neurons, PT_neurons)],\n",
    "    label=\"CT Neurons\",\n",
    "    color=\"orchid\",\n",
    "    width=bar_width,\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Number of Neurons\")\n",
    "# ax.set_title('CT, IT, and PT Neurons in Upper and Deep Layers')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_upper = tot_IT_upper + tot_PT_upper + tot_CT_upper\n",
    "total_lower = tot_IT_lower + tot_PT_lower + tot_CT_lower\n",
    "\n",
    "IT_neurons = [tot_IT_upper / total_upper, tot_IT_lower / total_lower]\n",
    "PT_neurons = [tot_PT_upper / total_upper, tot_PT_lower / total_lower]\n",
    "CT_neurons = [tot_CT_upper / total_upper, tot_CT_lower / total_lower]\n",
    "\n",
    "layers = [\"Upper\\nLayer\", \"Deep\\nLayer\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1.5, 3))\n",
    "\n",
    "bar_width = 0.6\n",
    "ax.bar(layers, IT_neurons, label=\"IT Neurons\", color=\"forestgreen\", width=bar_width)\n",
    "ax.bar(\n",
    "    layers,\n",
    "    PT_neurons,\n",
    "    bottom=IT_neurons,\n",
    "    label=\"PT Neurons\",\n",
    "    color=\"darkturquoise\",\n",
    "    width=bar_width,\n",
    ")\n",
    "ax.bar(\n",
    "    layers,\n",
    "    CT_neurons,\n",
    "    bottom=[i + j for i, j in zip(IT_neurons, PT_neurons)],\n",
    "    label=\"CT Neurons\",\n",
    "    color=\"orchid\",\n",
    "    width=bar_width,\n",
    ")\n",
    "\n",
    "ax.tick_params(axis=\"x\", labelsize=15)\n",
    "ax.tick_params(axis=\"y\", labelsize=16)\n",
    "ax.set_ylabel(\"Proportion of Neurons\", size=18)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.8), frameon=False, fontsize=16)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot correlations between mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice = [\"FIAA45.6a\", \"FIAA45.6d\", \"FIAA55.4d\"]\n",
    "combined_mice_dict = {}\n",
    "for mouse in mice:\n",
    "    new_dict = {}\n",
    "    parameters_path = proj_path / mouse / \"Sequencing\"\n",
    "    barcodes = pd.read_pickle(parameters_path / \"A1_barcodes_thresholded.pkl\")\n",
    "    failed_RT = barcodes.loc[:, (barcodes == 0).all()].columns\n",
    "    barcodes.drop(columns=failed_RT, inplace=True)\n",
    "    # normalise barcodes to total sum\n",
    "    parameters = ps.load_parameters(directory=parameters_path)\n",
    "    processed_path = Path(PARAMETERS[\"data_root\"][\"processed\"])\n",
    "    lcm_directory = processed_path / (\n",
    "        \"turnerb_\" + parameters[\"lcm_directory\"].split(\"turnerb_\")[1]\n",
    "    )\n",
    "    new_dict[\"homog_across_cubelet\"] = fpf.homog_across_cubelet(\n",
    "        parameters_path=parameters_path,\n",
    "        barcode_matrix=barcodes,\n",
    "        cortical=True,\n",
    "        shuffled=False,\n",
    "    )\n",
    "    new_dict[\"area_is_main\"] = fpf.area_is_main(\n",
    "        parameters_path=parameters_path,\n",
    "        barcode_matrix=barcodes,\n",
    "        cortical=True,\n",
    "        shuffled=False,\n",
    "    )\n",
    "    new_dict[\"homog_across_area\"] = fpf.homog_across_area(\n",
    "        parameters_path=parameters_path,\n",
    "        barcode_matrix=barcodes,\n",
    "        cortical=True,\n",
    "        shuffled=False,\n",
    "    )\n",
    "    new_dict[\"all_areas\"] = fpf.get_area_volumes(\n",
    "        barcode_table_cols=barcodes.columns, lcm_directory=lcm_directory\n",
    "    )\n",
    "\n",
    "    combined_mice_dict[mouse] = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_list = [\"homog_across_cubelet\", \"homog_across_area\", \"area_is_main\"]\n",
    "corr_dict = {}\n",
    "mcc = MouseConnectivityCache()\n",
    "structure_tree = mcc.get_structure_tree()\n",
    "rsp = mcc.get_reference_space()\n",
    "for key in analysis_list:\n",
    "    correlation_matrix = pd.DataFrame(columns=mice, index=mice)\n",
    "    for mouse_1 in mice:\n",
    "        for mouse_2 in mice:\n",
    "            if mouse_1 == mouse_2:\n",
    "                correlation_matrix.loc[mouse_1, mouse_2] = np.nan\n",
    "            else:\n",
    "                common_columns = set(\n",
    "                    combined_mice_dict[mouse_1][key].columns\n",
    "                ).intersection(combined_mice_dict[mouse_2][key].columns)\n",
    "                common_cols_cortex = []\n",
    "                for col in common_columns:\n",
    "                    if col != \"Contra\":\n",
    "                        structure = structure_tree.get_structures_by_acronym([col])\n",
    "                        if 315 in structure[0][\"structure_id_path\"]:\n",
    "                            common_cols_cortex.append(col)\n",
    "                    if col == \"Contra\":\n",
    "                        common_cols_cortex.append(col)\n",
    "                mean_A = np.log10(\n",
    "                    combined_mice_dict[mouse_1][key][common_cols_cortex].mean(axis=0)\n",
    "                    + 1e-10\n",
    "                )\n",
    "                mean_B = np.log10(\n",
    "                    combined_mice_dict[mouse_2][key][common_cols_cortex].mean(axis=0)\n",
    "                    + 1e-10\n",
    "                )\n",
    "                corr, p = pearsonr(mean_A, mean_B)\n",
    "                correlation_matrix.loc[mouse_1, mouse_2] = corr\n",
    "                correlation_matrix = correlation_matrix.apply(\n",
    "                    pd.to_numeric, errors=\"coerce\"\n",
    "                )\n",
    "\n",
    "    corr_dict[key] = correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "analysis_list = [\"homog_across_cubelet\", \"homog_across_area\", \"area_is_main\"]\n",
    "corr_dict = {}\n",
    "mcc = MouseConnectivityCache()\n",
    "structure_tree = mcc.get_structure_tree()\n",
    "rsp = mcc.get_reference_space()\n",
    "color_list = [\"forestgreen\", \"steelblue\", \"orchid\"]\n",
    "titles = [\"Homogeneous across cubelet\", \"Homogeneous across area\", \"Area is main\"]\n",
    "for i, key in enumerate(analysis_list):\n",
    "    # correlation_matrix = pd.DataFrame(columns=mice, index=mice)\n",
    "    ax = axes[i]\n",
    "    x = 0\n",
    "    for mouse_1, mouse_2 in itertools.combinations(mice, 2):\n",
    "        common_columns = set(combined_mice_dict[mouse_1][key].columns).intersection(\n",
    "            combined_mice_dict[mouse_2][key].columns\n",
    "        )\n",
    "        common_cols_cortex = []\n",
    "        for col in common_columns:\n",
    "            if col != \"Contra\":\n",
    "                structure = structure_tree.get_structures_by_acronym([col])\n",
    "                if 315 in structure[0][\"structure_id_path\"]:\n",
    "                    common_cols_cortex.append(col)\n",
    "            if col == \"Contra\":\n",
    "                common_cols_cortex.append(col)\n",
    "        mean_A = np.log10(\n",
    "            combined_mice_dict[mouse_1][key][common_cols_cortex].mean(axis=0) + 1e-10\n",
    "        )\n",
    "        mean_B = np.log10(\n",
    "            combined_mice_dict[mouse_2][key][common_cols_cortex].mean(axis=0) + 1e-10\n",
    "        )\n",
    "        corr, p = pearsonr(mean_A, mean_B)\n",
    "        # sb.scatterplot(x=mean_A, y=mean_B, ax=ax, s=20, color='#3498DB', label='Data points')\n",
    "        # sb.regplot(x=mean_A, y=mean_B, ax=ax, scatter=True, label=f'{mouse_1} vs {mouse_2} \\n r = {corr}')\n",
    "        sb.regplot(\n",
    "            x=mean_A,\n",
    "            y=mean_B,\n",
    "            ax=ax,\n",
    "            scatter=True,\n",
    "            label=f\"{mouse_1} vs {mouse_2} \\n r = {np.round(corr, 2)}\",\n",
    "            scatter_kws={\"color\": color_list[x]},\n",
    "            line_kws={\"color\": color_list[x]},\n",
    "        )\n",
    "        x = x + 1\n",
    "    ax.set_xlabel(\"log10(Projection Strength) \\n (Mouse 1)\", size=16)\n",
    "    ax.set_ylabel(\"log10(Projection Strength) \\n (Mouse 2)\", size=16)\n",
    "    ax.tick_params(axis=\"x\", labelsize=16)\n",
    "    ax.tick_params(axis=\"y\", labelsize=16)\n",
    "    # Add a legend\n",
    "    ax.legend(loc=\"upper left\", fontsize=14)\n",
    "    ax.set_title(titles[i], size=16)\n",
    "    # Add a black border around the plot for visibility\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor(\"black\")\n",
    "        spine.set_linewidth(1)\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.subplots_adjust(left=0.05, right=0.9, wspace=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot correlation to bulk tracing in areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MouseConnectivityCache()\n",
    "#     download_allen = pathlib.Path(\n",
    "#     \"/camp/lab/znamenskiyp/home/shared/projects/turnerb_MAPseq/A1_MAPseq/Allen_Connectivity\"\n",
    "# )\n",
    "\n",
    "# these expts have already been downloaded. If not you'll have to re-download\n",
    "# finalpix_expt_a = pd.read_pickle(\"mouse_connectivity/finalpix_expt_a.pkl\")\n",
    "# finalpix_expt_b = pd.read_pickle(\"mouse_connectivity/finalpix_expt_b.pkl\")\n",
    "# finalpix_expt_c = pd.read_pickle(\"mouse_connectivity/finalpix_expt_c.pkl\")\n",
    "# allen anterograde tracing datasets with more than 75% injection site AUDp\n",
    "experiment_id_a = 120491896  # AUDp\n",
    "experiment_id_b = 116903230  # AUDp, AUDpo, AUDd, AUDv\n",
    "experiment_id_c = 100149109  # AUDp and AUDd\n",
    "# injection volumes to normalise to (mm3)\n",
    "expt_a_inj_vol = 0.097\n",
    "expt_b_inj_vol = 0.114\n",
    "expt_c_inj_vol = 0.073\n",
    "# get projection density for each anterograde tracing expt: values are sum of projecting pixels per voxel.\n",
    "expt_a, pd_a_info = mcc.get_projection_density(experiment_id_a)\n",
    "expt_b, pd_b_info = mcc.get_projection_density(experiment_id_b)\n",
    "expt_c, pd_c_info = mcc.get_projection_density(experiment_id_c)\n",
    "# create an average of three experiments normalised by injection volume\n",
    "expt_a_normalised = expt_a / expt_a_inj_vol\n",
    "expt_b_normalised = expt_b / expt_b_inj_vol\n",
    "expt_c_normalised = expt_c / expt_c_inj_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"homog_across_cubelet\"\n",
    "common_columns = (\n",
    "    set(combined_mice_dict[\"FIAA45.6a\"][key].columns)\n",
    "    .intersection(set(combined_mice_dict[\"FIAA45.6d\"][key].columns))\n",
    "    .intersection(set(combined_mice_dict[\"FIAA55.4d\"][key].columns))\n",
    ")\n",
    "structure_tree = mcc.get_structure_tree()\n",
    "rsp = mcc.get_reference_space()\n",
    "expts = [expt_a, expt_b, expt_c]\n",
    "# mean_vis_df = pd.DataFrame(columns = vis_regions, index=[0, 1, 2])\n",
    "shape_template = (528, 320, 456)\n",
    "x_midpoint = shape_template[2] // 2\n",
    "contra_mask = np.zeros(shape_template, dtype=bool)\n",
    "contra_mask[:, :, x_midpoint:] = 1\n",
    "expt_dict = {}\n",
    "for i, experiment in enumerate(expts):\n",
    "    expt_dict[i] = experiment * contra_mask\n",
    "all_area = [area for area in common_columns]\n",
    "mean_all_areas_df = pd.DataFrame(columns=all_area, index=[0, 1, 2])\n",
    "columns_to_keep = []\n",
    "for acronym in all_area:\n",
    "    try:\n",
    "        structure = structure_tree.get_structures_by_acronym([acronym])\n",
    "    except KeyError:\n",
    "        print(f\"{acronym} does not exist - need to check naming\")\n",
    "        continue\n",
    "    if 315 in structure[0][\"structure_id_path\"]:\n",
    "        structure_id = structure[0][\"id\"]\n",
    "        mask = rsp.make_structure_mask([structure_id], direct_only=False)\n",
    "        for i, expt_loaded in enumerate(expt_dict.keys()):\n",
    "            projection_density_to_look = expt_dict[expt_loaded][np.where(mask == 1)]\n",
    "            mean_projection_density = np.mean(projection_density_to_look)\n",
    "            mean_all_areas_df.loc[i, acronym] = mean_projection_density\n",
    "        columns_to_keep.append(acronym)\n",
    "mean_all_areas_df = mean_all_areas_df[columns_to_keep]\n",
    "\n",
    "combined_df = pd.concat(\n",
    "    [\n",
    "        combined_mice_dict[\"FIAA45.6d\"][key][columns_to_keep],\n",
    "        combined_mice_dict[\"FIAA45.6a\"][key][columns_to_keep],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_all_cortical = np.log10(mean_all_areas_df.astype(float))\n",
    "allen_z_normalized = (\n",
    "    logged_all_cortical.T - logged_all_cortical.mean(axis=1)\n",
    ") / logged_all_cortical.std(axis=1)\n",
    "allen_z_normalized = allen_z_normalized.T\n",
    "mean_all_MAPseq = pd.DataFrame()\n",
    "mean_all_MAPseq = pd.concat(\n",
    "    [\n",
    "        combined_mice_dict[\"FIAA45.6d\"][\"homog_across_cubelet\"][columns_to_keep].mean(),\n",
    "        combined_mice_dict[\"FIAA45.6a\"][\"homog_across_cubelet\"][columns_to_keep].mean(),\n",
    "        combined_mice_dict[\"FIAA55.4d\"][\"homog_across_cubelet\"][columns_to_keep].mean(),\n",
    "    ],\n",
    "    axis=1,\n",
    "    ignore_index=True,\n",
    ")\n",
    "logged_all_MAPseq = np.log10(mean_all_MAPseq.T)\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "\n",
    "plt.errorbar(\n",
    "    x=allen_z_normalized.mean(),\n",
    "    y=logged_all_MAPseq.mean(),\n",
    "    xerr=allen_z_normalized.std(),\n",
    "    yerr=logged_all_MAPseq.std(),\n",
    "    fmt=\"none\",\n",
    "    color=\"gray\",\n",
    "    alpha=0.6,\n",
    "    label=None,\n",
    ")\n",
    "# plt.errorbar(x=allen_z_normalized.mean(), y=logged_all_MAPseq.mean(), xerr=allen_z_normalized.std(), yerr=logged_all_MAPseq.std(), fmt='none', color='gray', alpha=0.6, label='Error Bars')\n",
    "# sb.regplot(x=allen_z_normalized.mean(), y=logged_all_MAPseq.mean(), scatter=False)\n",
    "scatter = sb.scatterplot(\n",
    "    x=allen_z_normalized.mean(), y=logged_all_MAPseq.mean(), color=\"steelblue\", alpha=1\n",
    ")\n",
    "slope, intercept = np.polyfit(\n",
    "    allen_z_normalized.mean(), logged_all_MAPseq.mean(), 1\n",
    ")  # 1 for a linear fit\n",
    "\n",
    "\n",
    "x_fit = np.linspace(min(allen_z_normalized.mean()), max(allen_z_normalized.mean()), 100)\n",
    "y_fit = slope * x_fit + intercept\n",
    "\n",
    "# Plot the best-fit line\n",
    "plt.plot(x_fit, y_fit, color=\"black\", label=\"Best Fit Line\")\n",
    "# corr, p = pearsonr(\n",
    "#     to_plot[\"Allen_Z_core\"], y=to_plot[\"MAPseq_Z_score\"]\n",
    "# )\n",
    "corr, p = pearsonr(allen_z_normalized.mean(), logged_all_MAPseq.mean())\n",
    "# plt.title(\n",
    "#     f\"r = {np.round(corr, 3)}, p = {Decimal(p):.2E}\"\n",
    "# )\n",
    "plt.xlabel(\"Mean Bulk GFP \\n (Z score)\", size=16)\n",
    "plt.ylabel(\"Mean MAPseq \\n Log10(Projection Strength)\", size=16)\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "# handles, labels = scatter.get_legend_handles_labels()\n",
    "# plt.legend(handles=[handles[1], handles[2]], labels=['Visual cortex areas', 'Other cortical areas'], loc='lower right', fontsize=10)\n",
    "plt.text(\n",
    "    0.02,\n",
    "    0.98,\n",
    "    f\"r = {np.round(corr, 3)}, p = {Decimal(p):.2E}\",\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=14,\n",
    "    verticalalignment=\"top\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make venn diagram of shared barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3\n",
    "\n",
    "mice = [\"FIAA45.6a\", \"FIAA45.6d\", \"FIAA55.4d\"]\n",
    "dfs = {}\n",
    "for i, mouse in enumerate(mice):\n",
    "    parameters_path = str(proj_path) + \"/\" + mouse + \"/Sequencing\"\n",
    "    barcodes = pd.read_pickle(f\"{parameters_path}/A1_barcodes_thresholded.pkl\")\n",
    "    indices = set(barcodes.index)\n",
    "    dfs[i] = indices\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "venn = venn3([dfs[0], dfs[1], dfs[2]], (f\"{mice[0]}\", f\"{mice[1]}\", f\"{mice[2]}\"))\n",
    "\n",
    "colors = [\"orchid\", \"steelblue\", \"forestgreen\"]\n",
    "\n",
    "alpha_value = 0.8\n",
    "\n",
    "\n",
    "venn.get_patch_by_id(\"100\").set_facecolor(colors[0])\n",
    "venn.get_patch_by_id(\"100\").set_alpha(alpha_value)\n",
    "venn.get_patch_by_id(\"010\").set_facecolor(colors[1])\n",
    "venn.get_patch_by_id(\"010\").set_alpha(alpha_value)\n",
    "venn.get_patch_by_id(\"001\").set_facecolor(colors[2])\n",
    "venn.get_patch_by_id(\"001\").set_alpha(alpha_value)\n",
    "\n",
    "\n",
    "for patch in venn.patches:\n",
    "    if patch is not None:\n",
    "        patch.set_edgecolor(\"black\")\n",
    "        patch.set_linewidth(2),\n",
    "        patch.set_linestyle(\"--\")\n",
    "for label in venn.subset_labels:\n",
    "    if label is not None:\n",
    "        label.set_fontsize(14)\n",
    "        label.set_color(\"yellow\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an overview of projecting only within and outside the auditory cortex and A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice = [\"FIAA45.6a\", \"FIAA45.6d\", \"FIAA55.4d\"]\n",
    "count_df = pd.DataFrame(\n",
    "    index=mice,\n",
    "    columns=[\n",
    "        \"Total\",\n",
    "        \"A1 Only\",\n",
    "        \"Only Within Auditory Cortex\",\n",
    "        \"Out of Auditory Cortex\",\n",
    "    ],\n",
    ")\n",
    "combined_dict = {}\n",
    "for num, mouse in enumerate(mice):\n",
    "    new_dict = {}\n",
    "    parameters_path = proj_path / mouse / \"Sequencing\"\n",
    "    barcodes = pd.read_pickle(\n",
    "        parameters_path / \"A1_barcodes_thresholded_with_source.pkl\"\n",
    "    )\n",
    "    bc_no_source = pd.read_pickle(f\"{parameters_path}/A1_barcodes_thresholded.pkl\")\n",
    "    bc_no_source = bc_no_source[bc_no_source.sum(axis=1) > 0]\n",
    "    tot_bc = len(barcodes)\n",
    "    count_df.loc[mouse, \"Total\"] = tot_bc\n",
    "    parameters = fpf.load_parameters(directory=parameters_path)\n",
    "    lcm_directory = processed_path / (\n",
    "        \"turnerb_\" + parameters[\"lcm_directory\"].split(\"turnerb_\")[1]\n",
    "    )\n",
    "    sample_vol_path = lcm_directory / \"sample_vol_and_regions.pkl\"\n",
    "    sample_vol_and_regions = pd.read_pickle(\n",
    "        lcm_directory / \"sample_vol_and_regions.pkl\"\n",
    "    )\n",
    "    count_df.loc[mouse, \"A1 Only\"] = tot_bc - len(bc_no_source)\n",
    "    any_aud_containing = sample_vol_and_regions[\n",
    "        (sample_vol_and_regions[\"main\"] == \"AUDp\")\n",
    "        | (sample_vol_and_regions[\"main\"] == \"AUDv\")\n",
    "        | (sample_vol_and_regions[\"main\"] == \"AUDd\")\n",
    "        | (sample_vol_and_regions[\"main\"] == \"AUDpo\")\n",
    "    ]\n",
    "    with_aud = any_aud_containing[\"ROI Number\"].to_list()\n",
    "    with_aud = [sample for sample in with_aud if sample in barcodes.columns]\n",
    "    no_A1_mat = barcodes.drop(columns=with_aud)\n",
    "    no_A1_mat = no_A1_mat[no_A1_mat.sum(axis=1) > 0]\n",
    "    count_df.loc[mouse, \"Only Within Auditory Cortex\"] = tot_bc - len(no_A1_mat)\n",
    "    count_df.loc[mouse, \"Out of Auditory Cortex\"] = len(no_A1_mat)\n",
    "    # combined_dict[mouse] = fpf.homog_across_cubelet(parameters_path=parameters_path, barcode_matrix = barcodes, cortical=False, shuffled=False, binary=False, IT_only=False,)\n",
    "\n",
    "    # common_columns = set(combined_dict['FIAA45.6a'][key].columns).intersection(combined_dict['FIAA45.6d'][key].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice = [\"FIAA45.6a\", \"FIAA45.6d\", \"FIAA55.4d\"]\n",
    "count_df = pd.DataFrame(\n",
    "    index=mice,\n",
    "    columns=[\n",
    "        \"Total\",\n",
    "        \"A1 Only\",\n",
    "        \"Only Within Auditory Cortex\",\n",
    "        \"Out of Auditory Cortex\",\n",
    "    ],\n",
    ")\n",
    "combined_dict = {}\n",
    "for num, mouse in enumerate(mice):\n",
    "    new_dict = {}\n",
    "    parameters_path = proj_path / mouse / \"Sequencing\"\n",
    "    barcodes = pd.read_pickle(\n",
    "        parameters_path / \"A1_barcodes_thresholded_with_source.pkl\"\n",
    "    )\n",
    "    bc_no_source = pd.read_pickle(parameters_path / \"A1_barcodes_thresholded.pkl\")\n",
    "    bc_no_source = bc_no_source[bc_no_source.sum(axis=1) > 0]\n",
    "    tot_bc = len(barcodes)\n",
    "    count_df.loc[mouse, \"Total\"] = tot_bc\n",
    "    parameters = fpf.load_parameters(directory=parameters_path)\n",
    "    lcm_directory = processed_path / (\n",
    "        \"turnerb_\" + parameters[\"lcm_directory\"].split(\"turnerb_\")[1]\n",
    "    )\n",
    "    areas_only_grouped = fpf.get_area_volumes(\n",
    "        barcode_table_cols=barcodes.columns,\n",
    "        lcm_directory=lcm_directory,\n",
    "        area_threshold=0.1,\n",
    "    )\n",
    "    A1_only_list = areas_only_grouped[areas_only_grouped[\"AUDp\"] > 0].index.to_list()\n",
    "    A1_only_list = [sample for sample in A1_only_list if sample in barcodes.columns]\n",
    "    no_A1_mat = barcodes.drop(columns=A1_only_list)\n",
    "    no_A1_mat = no_A1_mat[no_A1_mat.sum(axis=1) > 0]\n",
    "    count_df.loc[mouse, \"A1 Only\"] = tot_bc - len(no_A1_mat)\n",
    "    any_aud_containing = sample_vol_and_regions[\n",
    "        (sample_vol_and_regions[\"main\"] == \"AUDp\")\n",
    "        | (sample_vol_and_regions[\"main\"] == \"AUDv\")\n",
    "        | (sample_vol_and_regions[\"main\"] == \"AUDd\")\n",
    "        | (sample_vol_and_regions[\"main\"] == \"AUDpo\")\n",
    "    ]\n",
    "    with_aud = areas_only_grouped[\n",
    "        (areas_only_grouped[[\"AUDp\", \"AUDv\", \"AUDd\", \"AUDpo\"]] > 0).any(axis=1)\n",
    "    ].index.to_list()\n",
    "    with_aud = [sample for sample in with_aud if sample in barcodes.columns]\n",
    "    no_AUD_mat = barcodes.drop(columns=with_aud)\n",
    "    no_AUD_mat = no_AUD_mat[no_AUD_mat.sum(axis=1) > 0]\n",
    "    count_df.loc[mouse, \"Only Within Auditory Cortex\"] = tot_bc - len(no_AUD_mat)\n",
    "    count_df.loc[mouse, \"Out of Auditory Cortex\"] = len(no_AUD_mat)\n",
    "    # combined_dict[mouse] = fpf.homog_across_cubelet(parameters_path=parameters_path, barcode_matrix = barcodes, cortical=False, shuffled=False, binary=False, IT_only=False,)\n",
    "\n",
    "    # common_columns = set(combined_dict['FIAA45.6a'][key].columns).intersection(combined_dict['FIAA45.6d'][key].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_columns = [\"A1 Only\", \"Only Within Auditory Cortex\", \"Out of Auditory Cortex\"]\n",
    "frequencies = count_df[freq_columns].div(count_df[\"Total\"], axis=0) * 100\n",
    "\n",
    "mean_frequencies = frequencies.mean()\n",
    "fig, ax = plt.subplots(figsize=(2, 3))\n",
    "x = np.arange(len(freq_columns))\n",
    "bar_width = 0.6\n",
    "ax.bar(\n",
    "    x,\n",
    "    mean_frequencies,\n",
    "    width=bar_width,\n",
    "    label=\"Mean Frequency\",\n",
    "    color=\"black\",\n",
    "    zorder=1,\n",
    ")\n",
    "for i, column in enumerate(freq_columns):\n",
    "    y = frequencies[column]\n",
    "    ax.scatter(\n",
    "        [x[i]] * len(y),\n",
    "        y,\n",
    "        label=f\"{column} Replicates\" if i == 0 else \"\",\n",
    "        color=\"grey\",\n",
    "        zorder=2,\n",
    "    )\n",
    "\n",
    "wrapped_labels = [\"A1\\nOnly\", \"Only\\nAUD\", \"Out of\\nAUD\"]\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(wrapped_labels, fontsize=14)\n",
    "\n",
    "ax.set_ylabel(\"Frequency (%)\", fontsize=16)\n",
    "plt.yticks(size=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies.drop(columns=[\"A1 Only\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_columns = [\"Only Within Auditory Cortex\", \"Out of Auditory Cortex\"]\n",
    "mean_frequencies = frequencies.mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1.5, 3))\n",
    "\n",
    "x = np.arange(len(freq_columns))\n",
    "bar_width = 0.6\n",
    "ax.bar(\n",
    "    x,\n",
    "    mean_frequencies,\n",
    "    width=bar_width,\n",
    "    label=\"Mean Frequency\",\n",
    "    color=\"black\",\n",
    "    zorder=1,\n",
    ")\n",
    "\n",
    "for i, column in enumerate(freq_columns):\n",
    "    y = frequencies[column]\n",
    "    ax.scatter(\n",
    "        [x[i]] * len(y),\n",
    "        y,\n",
    "        label=f\"{column} Replicates\" if i == 0 else \"\",\n",
    "        color=\"grey\",\n",
    "        zorder=2,\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "\n",
    "wrapped_labels = [\"Only\\nAUD\", \"Out of\\nAUD\"]\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(wrapped_labels, fontsize=14)\n",
    "\n",
    "ax.set_ylabel(\"Frequency (%)\", fontsize=16)\n",
    "plt.yticks(size=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at frequency across areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice = [\"FIAA45.6a\", \"FIAA45.6d\", \"FIAA55.4d\"]\n",
    "count_df = pd.DataFrame(\n",
    "    index=mice,\n",
    "    columns=[\n",
    "        \"Total\",\n",
    "        \"A1 Only\",\n",
    "        \"Only Within Auditory Cortex\",\n",
    "        \"Out of Auditory Cortex\",\n",
    "    ],\n",
    ")\n",
    "combined_dict = {}\n",
    "for num, mouse in enumerate(mice):\n",
    "    new_dict = {}\n",
    "    parameters_path = proj_path / mouse / \"Sequencing\"\n",
    "    barcodes = pd.read_pickle(parameters_path / \"A1_barcodes_thresholded.pkl\")\n",
    "    combined_dict[mouse] = fpf.homog_across_cubelet(\n",
    "        parameters_path=parameters_path,\n",
    "        barcode_matrix=barcodes,\n",
    "        binary=False,\n",
    "        cortical=True,\n",
    "        IT_only=True,\n",
    "        shuffled=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MouseConnectivityCache()\n",
    "structure_tree = mcc.get_structure_tree()\n",
    "common_columns_cubelet = set(combined_dict[mice[0]].columns)\n",
    "for mouse in mice[1:]:\n",
    "    common_columns_cubelet = common_columns_cubelet.intersection(\n",
    "        combined_dict[mouse].columns\n",
    "    )\n",
    "\n",
    "common_columns_cubelet = list(common_columns_cubelet)\n",
    "common_cols_cortex = []\n",
    "for col in common_columns_cubelet:\n",
    "    if col not in [\"Contra\", \"OB\"]:\n",
    "        structure = structure_tree.get_structures_by_acronym([col])\n",
    "        if 315 in structure[0][\"structure_id_path\"]:\n",
    "            common_cols_cortex.append(col)\n",
    "matrix = pd.concat(\n",
    "    [combined_dict[mouse][common_cols_cortex] for mouse in mice],\n",
    "    ignore_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict = {\n",
    "    \"VISp\": \"V1\",\n",
    "    \"VISpor\": \"POR\",\n",
    "    \"VISli\": \"LI\",\n",
    "    \"VISal\": \"AL\",\n",
    "    \"VISl\": \"LM\",\n",
    "    \"VISpl\": \"P\",\n",
    "    \"VISpm\": \"PM\",\n",
    "    \"VISrl\": \"RL\",\n",
    "    \"VISam\": \"AM\",\n",
    "    \"VISa\": \"A\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_groups = {\n",
    "    \"AUDITORY CORTEX\": [\"AUDd\", \"AUDv\", \"AUDpo\"],\n",
    "    \"LATERAL CORTEX\": [\"TEa\", \"PERI\", \"ECT\"],\n",
    "    \"VISUAL CORTEX\": [\n",
    "        \"VISal\",\n",
    "        \"VISp\",\n",
    "        \"VISpl\",\n",
    "        \"VISpm\",\n",
    "        \"VISrl\",\n",
    "        \"VISpor\",\n",
    "        \"VISam\",\n",
    "        \"VISl\",\n",
    "        \"VISa\",\n",
    "        \"VISli\",\n",
    "    ],\n",
    "    \"SOMATOMOTOR CORTICAL AREAS\": [\"MOp\", \"MOs\", \"SSp\", \"SSs\"],\n",
    "    \"CINGULATE CORTEX\": [\"RSPv\", \"RSPd\", \"RSPagl\", \"ACAd\", \"ACAv\"],\n",
    "}\n",
    "freq_df = pd.DataFrame(index=mice, columns=common_cols_cortex)\n",
    "tot_freq = pd.DataFrame(index=mice, columns=area_groups.keys())\n",
    "for mouse in mice:\n",
    "    df_to_look = combined_dict[mouse].astype(bool).astype(int)\n",
    "    for area in common_cols_cortex:\n",
    "        freq_df.loc[mouse, area] = df_to_look[area].mean()\n",
    "    for grouped_area in tot_freq.columns:\n",
    "        frequency = len(\n",
    "            df_to_look[df_to_look[area_groups[grouped_area]].sum(axis=1) > 0]\n",
    "        ) / len(df_to_look)\n",
    "        tot_freq.loc[mouse, grouped_area] = frequency\n",
    "\n",
    "plot_data = []\n",
    "group_positions = []\n",
    "x_labels = []  #\n",
    "\n",
    "x_pos = 0\n",
    "\n",
    "for group, columns in area_groups.items():\n",
    "\n",
    "    group_mean = tot_freq[group]\n",
    "    plot_data.append(group_mean)\n",
    "    x_labels.append(f\"Total\")\n",
    "    group_positions.append(x_pos - 0.5)\n",
    "    x_pos += 1\n",
    "    group_positions.append(x_pos - 0.5)\n",
    "\n",
    "    for area in sorted_columns:\n",
    "        plot_data.append(freq_df[area])\n",
    "        x_labels.append(area)\n",
    "        x_pos += 1\n",
    "\n",
    "x_labels = [\n",
    "    item if item not in convert_dict.keys() else convert_dict[item] for item in x_labels\n",
    "]\n",
    "plot_df = pd.concat(plot_data, axis=1).T\n",
    "plot_df.columns = freq_df.index\n",
    "plot_df.index = x_labels\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    "\n",
    "for i, (label, row) in enumerate(plot_df.iterrows()):\n",
    "    ax.scatter(\n",
    "        [i] * len(row),\n",
    "        row,\n",
    "        color=\"grey\",\n",
    "        edgecolor=\"black\",\n",
    "        zorder=2,\n",
    "        label=\"Individual Points\" if i == 0 else \"\",\n",
    "    )\n",
    "    ax.bar(\n",
    "        i,\n",
    "        row.mean(),\n",
    "        color=\"black\",\n",
    "        edgecolor=\"black\",\n",
    "        zorder=1,\n",
    "        width=0.5,\n",
    "        label=\"Mean\" if i == 0 else \"\",\n",
    "    )\n",
    "for pos in group_positions:\n",
    "    ax.axvline(x=pos, color=\"k\", linestyle=\"--\", linewidth=1, zorder=0)\n",
    "\n",
    "ax.set_xticks(range(len(plot_df.index)))\n",
    "ax.set_xticklabels(plot_df.index, rotation=45, ha=\"right\", fontsize=16)\n",
    "ax.set_ylabel(\"Frequency\", fontsize=16)\n",
    "ax.set_xticklabels(plot_df.index, rotation=45, ha=\"right\", fontsize=14)\n",
    "ax.tick_params(axis=\"y\", labelsize=16, length=8, width=2)\n",
    "# for idx, group in enumerate(area_groups.keys()):\n",
    "#     group_start = group_positions[2 * idx] + 0.5  # Start position of the group\n",
    "#     group_end = group_positions[2 * idx + 1] + 0.5  # End position of the group\n",
    "#     group_mid = (group_start + group_end) / 2  # Midpoint of the group\n",
    "#     ax.text(\n",
    "#         group_start, ax.get_ylim()[1] * 1.05, group, ha='center', va='center', fontsize=12, fontweight='bold'\n",
    "#    )\n",
    "\n",
    "# Adjust layout and display plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapseq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
