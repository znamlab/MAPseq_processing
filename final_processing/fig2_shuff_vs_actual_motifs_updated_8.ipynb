{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainglobe_atlasapi import BrainGlobeAtlas\n",
    "import pandas as pd\n",
    "from final_processing import final_processing_functions as fpf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "import itertools\n",
    "from scipy.stats import norm\n",
    "from matplotlib import rcParams\n",
    "import figure_formatting as ff\n",
    "import yaml\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.stats import mannwhitneyu\n",
    "import statsmodels.api as sm\n",
    "import textwrap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"general_analysis_parameters.yaml\", \"r\") as file:\n",
    "    gen_parameters = yaml.safe_load(file)\n",
    "rcParams['font.sans-serif'] = gen_parameters['font']\n",
    "rcParams['font.family'] = gen_parameters['font']\n",
    "rcParams['font.size'] = gen_parameters['font_size']\n",
    "font_size = gen_parameters['font_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't done yet, generate a shuffle population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first get shuffled population\n",
    "# mice = ['FIAA45.6a', 'FIAA45.6d', 'FIAA55.4d']\n",
    "fpf.generate_shuffle_population(mice=gen_parameters['MICE'], proj_folder= str(gen_parameters['proj_path']), total_number_shuffles= gen_parameters['number_shuffles'], mice_sep=False, use_slurm=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any shuffle jobs have failed, run this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this if you have jobs that have failed\n",
    "# #fpf.collate_all_shuffles(temp_shuffle_folder='/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/temp_shuffles', mice_sep=False, mice=['FIAA45.6a', 'FIAA45.6d', 'FIAA55.4d'], overwrite=False, use_slurm=False, )\n",
    "temp_shuffle_folder=gen_parameters['proj_path'] + '/temp_shuffles'\n",
    "mice_sep=False\n",
    "total=int(gen_parameters['number_shuffles']/200)\n",
    "fpf.check_and_run_missing_scripts(total= total, mice = gen_parameters['MICE'], temp_shuffle_folder=str(temp_shuffle_folder), mice_sep=mice_sep, use_slurm=False)\n",
    "                                                                                                                                                                                                                                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run scripts to generate figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = gen_parameters['fig_saving_path']\n",
    "mice = gen_parameters['MICE']\n",
    "proj_path = gen_parameters['proj_path']\n",
    "mcc = MouseConnectivityCache()\n",
    "structure_tree = mcc.get_structure_tree()\n",
    "combined_dict = {}\n",
    "for num, mouse in enumerate(mice):\n",
    "    new_dict = {}\n",
    "    parameters_path = (\n",
    "    f\"{proj_path}/{mouse}/Sequencing\")\n",
    "    barcodes = pd.read_pickle(f\"{parameters_path}/A1_barcodes_thresholded.pkl\")\n",
    "    new_dict['homogenous_across_cubelet'] = fpf.homog_across_cubelet(parameters_path=parameters_path, barcode_matrix = barcodes, cortical=True, shuffled=False, binary=True, IT_only=True, area_threshold=0.1)\n",
    "    new_dict['homogenous_across_area'] = fpf.homog_across_area(parameters_path=parameters_path, barcode_matrix = barcodes, cortical=True, shuffled=False, binary=False, IT_only=True)\n",
    "    new_dict['area_is_main'] = fpf.area_is_main(parameters_path=parameters_path, barcode_matrix = barcodes, cortical=False, shuffled=False, binary=True,  IT_only=True)\n",
    "    new_dict['shuff_cubelet']= fpf.homog_across_cubelet(parameters_path=parameters_path, barcode_matrix = barcodes, cortical=True, shuffled=True, binary=True, IT_only=True)\n",
    "    new_dict['shuff_area']=fpf.homog_across_area(parameters_path=parameters_path, barcode_matrix = barcodes, cortical=True, shuffled=True, binary=False,  IT_only=True)\n",
    "    new_dict['shuff_main'] = fpf.area_is_main(parameters_path=parameters_path, barcode_matrix = barcodes, cortical=True, shuffled=True, binary=True,  IT_only=True)\n",
    "    combined_dict[mouse] = new_dict\n",
    "analysis_names =['homogenous_across_cubelet', 'homogenous_across_area', 'area_is_main', 'shuff_cubelet', 'shuff_area', 'shuff_main']\n",
    "all_combined = {}\n",
    "for i, key in enumerate(analysis_names):\n",
    "    common_cols_cortex = fpf.get_common_columns(mice=mice, combined_dict=combined_dict, key=key, cortex=True)\n",
    "    combined_matrix = pd.concat([\n",
    "    combined_dict[k][key][common_cols_cortex]\n",
    "    for k in mice\n",
    "])\n",
    "    all_combined[key] = combined_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_probability_dict = {}\n",
    "p_val_dict = {}\n",
    "analysis_names =['homogenous_across_cubelet', 'shuff_cubelet']\n",
    "for key in analysis_names:\n",
    "    cols = ['VISl', 'VISli', 'VISpor', 'VISpl', 'VISp', 'VISal', 'VISam', 'VISa', 'VISpm', 'VISrl']\n",
    "    matrix = all_combined[key].copy()\n",
    "    all_cols = matrix.columns\n",
    "    cols_reordered = [item for item in cols if item in all_cols] + [item for item in all_cols if item not in cols]\n",
    "    cols_reordered = [item for item in cols_reordered if item != 'AUDp']\n",
    "    cols = [col for col in cols if col in all_cols]\n",
    "    if 'shuff' in key:\n",
    "        which = key.split('shuff_')[-1]\n",
    "        #conditional_prob = pd.DataFrame(data=np.zeros((len(cols), len(cols_reordered))), columns= cols_reordered, index=cols_reordered)\n",
    "        if which in ('cubelet', 'area'):\n",
    "            matrix_to_comp = all_combined[f'homogenous_across_{which}']\n",
    "        elif which == 'main':\n",
    "            matrix_to_comp= all_combined['area_is_main']\n",
    "        conditional_prob = fpf.get_cond_prob(matrix=matrix_to_comp[cols_reordered], columns=cols_reordered, index=cols_reordered)\n",
    "        #matrix = all_combined[f'homogenous_across_{which}'][cols_reordered]\n",
    "        shuffled_cond_prob = pd.read_pickle(f'{proj_path}/collated_shuffles/shuffled_{which}_conditional_prob__collated.pkl')\n",
    "        mean_val_matrix = pd.DataFrame(data=np.zeros((len(cols_reordered), len(cols_reordered))), columns= cols_reordered, index=cols_reordered)\n",
    "        p_val_matrix = pd.DataFrame(data=np.zeros((len(cols_reordered), len(cols_reordered))), columns= cols_reordered, index=cols_reordered)\n",
    "        for column_name in shuffled_cond_prob.columns:\n",
    "            separated_words = column_name.split(', ')\n",
    "            mean_corr = shuffled_cond_prob[column_name].mean()\n",
    "            if separated_words[0] in cols_reordered and separated_words[1] in cols_reordered:\n",
    "                mean_val_matrix.loc[separated_words[0], separated_words[1]] = mean_corr\n",
    "                # if separated_words[1] in cols:\n",
    "                #     mean_val_matrix.loc[separated_words[1], separated_words[0]] = mean_corr\n",
    "                val_to_comp = conditional_prob.loc[separated_words[0], separated_words[1]]\n",
    "                # if val_to_comp >= mean_corr:\n",
    "                #     p_val = (sum(1 for value in shuffled_cond_prob[column_name] if value > val_to_comp)/len(shuffled_cond_prob))*2\n",
    "                # elif val_to_comp < mean_corr:\n",
    "                #     p_val = (sum(1 for value in shuffled_cond_prob[column_name] if value < val_to_comp)/len(shuffled_cond_prob))*2    \n",
    "                mu, std = norm.fit(shuffled_cond_prob[column_name].values)\n",
    "                if val_to_comp >= mean_corr:\n",
    "                    p_val = norm.sf(val_to_comp, loc=mu, scale=std) * 2  # two-sided\n",
    "                else:\n",
    "                    p_val = norm.cdf(val_to_comp, loc=mu, scale=std) * 2\n",
    "                #p_val = scipy.stats.norm.sf(abs(z_value))*2\n",
    "                p_val_matrix.loc[separated_words[0], separated_words[1]] = p_val\n",
    "                # if separated_words[1] in cols_reordered:\n",
    "                #     p_val_matrix.loc[separated_words[1], separated_words[0]] = p_val\n",
    "        np.fill_diagonal(mean_val_matrix.values, np.nan)\n",
    "        np.fill_diagonal(p_val_matrix.values, np.nan)\n",
    "        number_tests = len(cols)* (len(cols_reordered)-1)\n",
    "        all_col_test_num = len(cols_reordered)* (len(cols_reordered)-1)\n",
    "        p_val_matrix_corrected = p_val_matrix*number_tests #bonferroni correction\n",
    "        p_val_dict[key] =p_val_matrix_corrected\n",
    "        p_val_dict['all_columns'] =  p_val_matrix*all_col_test_num\n",
    "        conditional_probability_dict[key] =mean_val_matrix\n",
    "    else:\n",
    "       conditional_probability_dict[key] = fpf.get_cond_prob(matrix=all_combined[key][cols_reordered], columns=cols_reordered, index=cols_reordered) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check normality by plotting random selection qq plots\n",
    "selected_columns = np.random.choice(shuffled_cond_prob.columns, 20, replace=False)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(4, 5, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(selected_columns):\n",
    "    stats.probplot(shuffled_cond_prob[col], dist=\"norm\", plot=axes[i])\n",
    "    axes[i].set_title(f'Q-Q Plot of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(3, 6.5), constrained_layout=True)\n",
    "heatmap_titles = ['Actual Data', 'Mean Shuffled']\n",
    "\n",
    "analysis_type = 'cubelet'\n",
    "\n",
    "if analysis_type != 'main':\n",
    "    actual_data = conditional_probability_dict[f'homogenous_across_{analysis_type}']\n",
    "else:\n",
    "    actual_data = conditional_probability_dict['area_is_main']\n",
    "\n",
    "combined_dif = actual_data - conditional_probability_dict[f'shuff_{analysis_type}']\n",
    "\n",
    "dfs = [actual_data, conditional_probability_dict[f'shuff_{analysis_type}']]\n",
    "\n",
    "cols = ['VISal', 'VISl', 'VISli', 'VISpor', 'VISpl', 'VISp', 'VISam', 'VISa', 'VISpm', 'VISrl']\n",
    "all_cols = actual_data.columns\n",
    "cols = [col for col in cols if col in all_cols]\n",
    "\n",
    "for number, title in enumerate(heatmap_titles):\n",
    "    data_to_use = dfs[number].copy(deep=True)\n",
    "    shortened_data = data_to_use.loc[all_cols]\n",
    "\n",
    "    sb.heatmap(\n",
    "        ax=axs[number],\n",
    "        data=fpf.convert_matrix_names(shortened_data),\n",
    "        cmap='Purples',\n",
    "        xticklabels=True,\n",
    "        yticklabels=True, cbar_kws=dict(\n",
    "            location='right',  \n",
    "            pad=-0.48,          \n",
    "                                \n",
    "            fraction=0.045,     \n",
    "            shrink=1.0,         \n",
    "            use_gridspec=True   \n",
    "        )\n",
    "    )\n",
    "\n",
    "    axs[number].set_title(f'{heatmap_titles[number]}', size=font_size*1.1)\n",
    "    axs[number].tick_params(axis='y', which='major', labelsize=font_size, rotation=0)\n",
    "\n",
    "    for _, spine in axs[number].spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(1)\n",
    "\n",
    "    axs[number].set_ylabel('Cortical area', size=font_size)\n",
    "    axs[number].set_xlabel('Co-projection target', size=font_size)\n",
    "\n",
    "    cbar = axs[number].collections[0].colorbar\n",
    "    \n",
    "    cbar.outline.set_visible(True)\n",
    "    cbar.outline.set_edgecolor('black')\n",
    "    cbar.outline.set_linewidth(1)\n",
    "    cbar.set_label(\n",
    "    r'$\\mathrm{Conditional\\ probability}$' + '\\n' +\n",
    "    r'$\\mathit{P(target \\mid Cortical\\ area)}$',\n",
    "    fontsize=font_size\n",
    ")\n",
    "\n",
    "    #cbar.set_label(r'Conditional probability' '\\n' r'$\\mathit{P(target \\mid Cortical\\ area)}$', fontsize=font_size)\n",
    "bubble_data = fpf.convert_matrix_names(combined_dif.loc[all_cols])\n",
    "pval_df = fpf.convert_matrix_names(p_val_dict[f'all_columns'].loc[all_cols])\n",
    "\n",
    "df_plot = bubble_data.stack().reset_index()\n",
    "df_plot.columns = [\"y_label\", \"x_label\", \"conditional_prob\"]\n",
    "df_plot[\"p_value\"] = pval_df.stack().reset_index(drop=True)\n",
    "x_categories = bubble_data.columns\n",
    "y_categories = bubble_data.index\n",
    "\n",
    "df_plot[\"x\"] = pd.Categorical(df_plot[\"x_label\"], categories=x_categories, ordered=True).codes\n",
    "df_plot[\"y\"] = pd.Categorical(df_plot[\"y_label\"], categories=y_categories, ordered=True).codes\n",
    "\n",
    "size_scale = 60\n",
    "df_plot[\"bubble_size\"] = df_plot[\"conditional_prob\"].abs() * size_scale\n",
    "#df_plot[\"color_value\"] = -np.log10(df_plot[\"p_value\"].clip(lower=1e-50))\n",
    "df_plot[\"color_value\"] = (\n",
    "        np.sign(df_plot[\"conditional_prob\"]) *\n",
    "        -np.log10(df_plot[\"p_value\"].clip(lower=1e-50))\n",
    "    )\n",
    "norm = TwoSlopeNorm(vmin=df_plot[\"color_value\"].min(),\n",
    "                    vcenter=0,\n",
    "                    vmax=df_plot[\"color_value\"].max())\n",
    "\n",
    "sc = axs[2].scatter(\n",
    "    x=df_plot[\"x\"],\n",
    "    y=df_plot[\"y\"],\n",
    "    s=df_plot[\"bubble_size\"],\n",
    "    c=df_plot[\"color_value\"],\n",
    "    cmap='coolwarm', norm=norm,\n",
    "    edgecolors=\"none\"\n",
    ")\n",
    "significant_mask = df_plot[\"p_value\"] < 0.05\n",
    "axs[2].scatter(\n",
    "    x=df_plot.loc[significant_mask, \"x\"],\n",
    "    y=df_plot.loc[significant_mask, \"y\"],\n",
    "    s=df_plot.loc[significant_mask, \"bubble_size\"],\n",
    "    facecolors=\"none\",\n",
    "    edgecolors=\"black\",\n",
    "    linewidths=1\n",
    ")\n",
    "axs[2].set_xticks(range(len(x_categories)))\n",
    "axs[2].set_yticks(range(len(y_categories)))\n",
    "axs[2].set_xticklabels(x_categories, rotation=90, fontsize=font_size*0.9)\n",
    "axs[2].set_yticklabels(y_categories, fontsize=font_size*0.9)\n",
    "\n",
    "axs[2].invert_yaxis()\n",
    "axs[2].set_title('Actual Minus Mean Shuffled', size=font_size*1.1)\n",
    "axs[2].set_xlabel(\"Co-Projection Target\", fontsize=font_size*0.9)\n",
    "axs[2].set_ylabel(\"Cortical Area\", fontsize=font_size*0.9)\n",
    "legend_values = [0.1, 0.2, 0.4]\n",
    "legend_handles = [\n",
    "    axs[2].scatter([], [], s=val * size_scale, c=\"gray\", alpha=0.5,\n",
    "                   label=f'{val:.1f}') for val in legend_values\n",
    "]\n",
    "\n",
    "axs[2].legend(\n",
    "    handles=legend_handles,\n",
    "    title=\"Conditional Probability\",\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    frameon=True,\n",
    "    fontsize=font_size,\n",
    "    title_fontsize=font_size,\n",
    ")\n",
    "cax = inset_axes(\n",
    "    axs[2],                  \n",
    "    width=\"4%\",            \n",
    "    height=\"50%\",             \n",
    "    bbox_to_anchor=(1.22,    \n",
    "                    -0.4,   \n",
    "                    1, 1),\n",
    "    bbox_transform=axs[2].transAxes,\n",
    "    loc=\"upper left\",\n",
    "    borderpad=0,\n",
    ")\n",
    "\n",
    "cbar = plt.colorbar(sc, cax=cax, orientation=\"vertical\")\n",
    "cbar.set_label(\"-log10(p-value)\", fontsize=font_size)\n",
    "cbar.ax.tick_params(labelsize=font_size)\n",
    "tick_locs = cbar.get_ticks()\n",
    "cbar.set_ticks(tick_locs)\n",
    "cbar.set_ticklabels([f\"{int(abs(tick))}\" for tick in tick_locs])\n",
    "fig.savefig(f\"{saving_path}/supplementary/extended_fig_3d.svg\", format=\"svg\", bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analysis_type = 'cubelet'\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "if analysis_type != 'main':\n",
    "    actual_data = conditional_probability_dict[f'homogenous_across_{analysis_type}']\n",
    "elif analysis_type == 'main':\n",
    "    actual_data = conditional_probability_dict['area_is_main']\n",
    "\n",
    "cols = [ 'VISl', 'VISli', 'VISpor', 'VISpl', 'VISal', 'VISp', 'VISam', 'VISa', 'VISpm', 'VISrl']\n",
    "#all_cols = actual_data.columns\n",
    "pairwise_distances = actual_data.corr() \n",
    "linkage_matrix = linkage(pairwise_distances, method='ward')\n",
    "dendro = dendrogram(linkage_matrix, labels=actual_data.columns, no_plot=True)\n",
    "column_order = dendro['ivl']\n",
    "all_cols = column_order\n",
    "cols = [col for col in cols if col in all_cols]\n",
    "not_in = [col for col in all_cols if col not in cols]\n",
    "combined = cols + not_in\n",
    "shortened_data = actual_data.loc[cols][combined]\n",
    "shortened_data_names_the_same = actual_data.loc[cols][combined].copy(deep=True)\n",
    "fig = plt.figure(figsize=(15/2.54, 4/2.54))\n",
    "\n",
    "ax1 = fig.add_axes([0.1, 0.25, 0.35, 0.6])\n",
    "cbax1 = fig.add_axes([0.47, 0.5, 0.01, 0.35])\n",
    "\n",
    "plt.sca(ax1)\n",
    "tick_vals= [0.0, 1]\n",
    "sb.heatmap(\n",
    "    data=fpf.convert_matrix_names(shortened_data), \n",
    "    cmap='Purples',\n",
    "    xticklabels=False,  \n",
    "    yticklabels=True, \n",
    "    cbar_kws={'ticks': tick_vals},\n",
    "    ax=ax1,\n",
    "    cbar_ax=cbax1,\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "ax1.tick_params(axis='y', which='major', labelsize=font_size, rotation=0)\n",
    "tick_positions = np.arange(len(x_categories)) + 0.5\n",
    "ax1.set_xticks(tick_positions)\n",
    "ax1.set_xticklabels(x_categories, rotation=90, fontsize=font_size)\n",
    "\n",
    "for _, spine in ax1.spines.items():\n",
    "    spine.set_visible(True)\n",
    "    spine.set_color('black')\n",
    "    spine.set_linewidth(1)\n",
    "\n",
    "cbar = ax1.collections[0].colorbar\n",
    "cbar.outline.set_visible(True)\n",
    "cbar.outline.set_edgecolor('black')\n",
    "cbar.outline.set_linewidth(1)\n",
    "cbar.ax.tick_params(labelsize=font_size)\n",
    "cbax1.set_title(\n",
    "    'P(target|VC area)',\n",
    "    fontsize=font_size,\n",
    ")\n",
    "\n",
    "ax1.set_ylabel('VC area', size=font_size)\n",
    "ax1.set_xlabel(\"Coprojection target\", fontsize=font_size)\n",
    "\n",
    "ax2 = fig.add_axes([0.55, 0.25, 0.35, 0.6])\n",
    "cbax2 = fig.add_axes([.92, 0.5, 0.01, 0.35])\n",
    "\n",
    "plt.sca(ax2)  \n",
    "\n",
    "converted_actual = fpf.convert_matrix_names(actual_data.loc[cols][combined])\n",
    "p_val_converted = fpf.convert_matrix_names(p_val_dict['shuff_cubelet'].loc[cols][combined])\n",
    "\n",
    "df_plot = converted_actual.stack().reset_index()\n",
    "df_plot.columns = [\"y_label\", \"x_label\", \"conditional_prob\"]\n",
    "df_plot[\"p_value\"] = p_val_converted.stack().reset_index(drop=True)\n",
    "\n",
    "x_categories = converted_actual.columns\n",
    "y_categories = converted_actual.index\n",
    "df_plot[\"x\"] = (\n",
    "    pd.Categorical(df_plot[\"x_label\"], categories=x_categories, ordered=True).codes + 0.5\n",
    ")\n",
    "\n",
    "df_plot[\"y\"] = pd.Categorical(df_plot[\"y_label\"], categories=y_categories, ordered=True).codes\n",
    "combined_dif = np.log10(actual_data / conditional_probability_dict[f'shuff_{analysis_type}'])\n",
    "combined_dif_converted = fpf.convert_matrix_names(combined_dif.loc[cols][combined])\n",
    "combined_dif_converted_df_plot = combined_dif_converted.stack().reset_index()\n",
    "combined_dif_converted_df_plot.columns = [\"y_label\", \"x_label\", \"subtracted_conditional_prob\"]\n",
    "df_plot['subtracted_conditional_prob'] = combined_dif_converted_df_plot['subtracted_conditional_prob']\n",
    "size_scale = 100\n",
    "df_plot[\"bubble_size\"] = df_plot[\"subtracted_conditional_prob\"].abs() * size_scale\n",
    "#df_plot[\"color_value\"] = -np.log10(df_plot[\"p_value\"].clip(lower=1e-50))\n",
    "df_plot[\"color_value\"] = (\n",
    "        np.sign(df_plot[\"subtracted_conditional_prob\"]) *\n",
    "        -np.log10(df_plot[\"p_value\"].clip(lower=1e-50))\n",
    "    )\n",
    "norm = TwoSlopeNorm(vmin=-5,\n",
    "                    vcenter=0,\n",
    "                    vmax=5)\n",
    "sc = ax2.scatter(\n",
    "    x=df_plot[\"x\"],\n",
    "    y=df_plot[\"y\"],\n",
    "    s=df_plot[\"bubble_size\"],\n",
    "    c=df_plot[\"color_value\"],\n",
    "    cmap='coolwarm', \n",
    "    norm=norm,\n",
    "    edgecolors=\"none\"\n",
    ")\n",
    "\n",
    "df_signif = df_plot[df_plot[\"p_value\"] < 0.05]\n",
    "ax2.scatter(\n",
    "    x=df_signif[\"x\"],\n",
    "    y=df_signif[\"y\"],\n",
    "    s=df_signif[\"bubble_size\"],\n",
    "    facecolors=\"none\",\n",
    "    edgecolors=\"black\",\n",
    "    linewidths=0.5\n",
    ")\n",
    "\n",
    "cbar = fig.colorbar(sc, ax=ax2, cax=cbax2)\n",
    "cbar.ax.tick_params(labelsize=font_size)\n",
    "cbar.ax.set_title(\"Signed\\n$log_{10}$ p-value\", fontsize=font_size)\n",
    "cbar.ax.yaxis.set_label_coords(7.5, 0.4)\n",
    "legend_values = [0.1, 0.2, 0.4]\n",
    "legend_handles = [\n",
    "    ax2.scatter([], [], s=val * size_scale, c=\"gray\", alpha=0.5, \n",
    "                label=val, linewidths=0)  \n",
    "    for val in legend_values\n",
    "]\n",
    "\n",
    "legend = ax2.legend(\n",
    "    handles=legend_handles,\n",
    "    title=\"Effect size\\n$|\\log_{10}\\\\frac{\\mathrm{observed}}{\\mathrm{shuffled}}|$\",\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1.0, 0.3),\n",
    "    borderaxespad=0.,\n",
    "    frameon=False,\n",
    "    handleheight=1.0,\n",
    "    fontsize=font_size, title_fontsize=font_size\n",
    ")\n",
    "legend.get_title().set_ha('center')\n",
    "\n",
    "ax2.set_yticks(range(len(y_categories)))\n",
    "ax2.set_yticklabels([])\n",
    "tick_positions = np.arange(len(x_categories)) + 0.5\n",
    "ax2.set_xticks(tick_positions)\n",
    "ax2.set_xticklabels(x_categories, rotation=90, fontsize=font_size)\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "ax2.set_xlabel(\"Coprojection target\", fontsize=font_size)\n",
    "ax2.set_ylabel(\"\")\n",
    "\n",
    "plt.savefig(f\"{saving_path}/fig_2_heatmapbubble_combined.svg\", format=\"svg\")\n",
    "plt.savefig(f\"{saving_path}/fig_2_heatmapbubble_combined.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot mean cosine similarity of conditional probabilities\n",
    "#let's first calculate the mean conditional probability across mice\n",
    "key='homogenous_across_cubelet'\n",
    "which = 'cubelet'\n",
    "shuff = f'shuff_{which}'\n",
    "common_cols = all_combined[key].columns\n",
    "\n",
    "cols = [ 'VISl', 'VISli', 'VISpor', 'VISpl', 'VISal', 'VISp', 'VISam', 'VISa', 'VISpm', 'VISrl']\n",
    "cols = [col for col in cols if col in common_cols]\n",
    "cols_reordered = [item for item in cols if item in common_cols] + [item for item in common_cols if item not in cols]\n",
    "cols_reordered = [item for item in cols_reordered if item != 'AUDp']\n",
    "cond_prob_dict = {}\n",
    "shuff_cond_prob_dict = {}\n",
    "mouse_cond_prob_minus_shuff = {}\n",
    "for mouse in mice:\n",
    "    cond_prob_dict[mouse]= fpf.get_cond_prob(matrix = combined_dict[mouse][key], columns = cols_reordered, index = cols_reordered)\n",
    "    shuff_cond_prob_dict[mouse] = fpf.get_cond_prob(matrix = combined_dict[mouse][shuff], columns = cols_reordered, index = cols_reordered)\n",
    "    shuffled_cond_prob = pd.read_pickle(f'/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/collated_shuffles/shuffled_{which}_conditional_prob_{mouse}_collated.pkl')\n",
    "    mean_val_matrix = pd.DataFrame(data=np.zeros((len(cols_reordered), len(cols_reordered))), columns= cols_reordered, index=cols_reordered)\n",
    "    for column_name in shuffled_cond_prob.columns:\n",
    "        separated_words = column_name.split(', ')\n",
    "        mean_corr = shuffled_cond_prob[column_name].mean()\n",
    "        if separated_words[0] in cols_reordered and separated_words[1] in cols_reordered:\n",
    "                mean_val_matrix.loc[separated_words[0], separated_words[1]] = mean_corr\n",
    "    #shuff_cond_prob_dict[mouse] = mean_val_matrix\n",
    "    mouse_cond_prob_minus_shuff[mouse] = cond_prob_dict[mouse]-mean_val_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_numbers = pd.read_pickle(f'/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/collated_shuffles/shuffled__neuron_numbers_cubelet__collated.pkl')\n",
    "shuffled_2_combinations = pd.read_pickle(f'/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/collated_shuffles/shuffled_cubelet_2_comb__collated.pkl')\n",
    "shuffle_total_numbers = pd.read_pickle(f'/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/collated_shuffles/total_neuron_numbers_cubelet__collated.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorsal_stream = ['VISa', 'VISam', 'VISpm', 'VISrl']\n",
    "ventral_stream = ['VISpor', 'VISpl', 'VISl', 'VISli', 'VISal']\n",
    "\n",
    "def classify_stream(pair):\n",
    "    regions = pair.split(', ')\n",
    "    is_dorsal = [region in dorsal_stream for region in regions]\n",
    "    is_ventral = [region in ventral_stream for region in regions]\n",
    "    \n",
    "    if all(is_dorsal):\n",
    "        return 'dorsal'\n",
    "    elif all(is_ventral):\n",
    "        return 'ventral'\n",
    "    elif any(is_dorsal) and any(is_ventral):\n",
    "        return 'dorsal-ventral'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "dot_size = 3\n",
    "alpha_val = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "barcodes = all_combined['homogenous_across_cubelet']\n",
    "total_combinations = len(list(itertools.combinations(cols_reordered, 2)))\n",
    "all_cols = barcodes.columns\n",
    "cols_reordered = [item for item in cols if item in all_cols] + [item for item in all_cols if item not in cols]\n",
    "cols_reordered = [item for item in cols_reordered if item != 'AUDp']\n",
    "cols = ['VISal', 'VISl',  'VISli','VISpor', 'VISpl', 'VISp', 'VISam', 'VISa', 'VISpm', 'VISrl']\n",
    "cols = [col for col in cols if col in all_cols]\n",
    "probs_df = pd.DataFrame(index=['probs_actual', 'probs_joint', 'log_OR_actual', 'mean_shuf', 'p_value'])  \n",
    "for column_name in shuffled_2_combinations.columns:\n",
    "    if any(substring in column_name for substring in cols):\n",
    "        col, col_2= map(str.strip, column_name.split(','))\n",
    "# for col in cols_reordered:\n",
    "#     for col_2 in cols_reordered:\n",
    "#         if col != col_2:\n",
    "        if col in all_cols and col_2 in all_cols:\n",
    "            prob_df = pd.DataFrame()\n",
    "            prob_df[\"a\"] = barcodes[col].astype(bool)\n",
    "            prob_df[\"b\"] = barcodes[col_2].astype(bool)\n",
    "            prob_df[\"matching\"] = prob_df.apply(lambda x: 1 if x['a'] and x['b'] else 0, axis=1)\n",
    "            probs_actual = prob_df[\"matching\"].sum() / len(barcodes)\n",
    "            probs_joint = (prob_df[\"a\"].sum() / len(barcodes)) * (prob_df[\"b\"].sum() / len(barcodes))\n",
    "            probs_df.loc['probs_actual', f'{col}, {col_2}'] = probs_actual\n",
    "            probs_df.loc['probs_joint', f'{col}, {col_2}'] = probs_joint\n",
    "            if f'{col}, {col_2}' in shuffled_2_combinations.columns:\n",
    "                column_name = f'{col}, {col_2}'\n",
    "            elif f'{col_2}, {col}' in shuffled_2_combinations.columns:\n",
    "                column_name = f'{col_2}, {col}'\n",
    "            shuff_actual_prob = shuffled_2_combinations[column_name]/shuffle_total_numbers[0]\n",
    "            shuff_joint_prob = (shuffled_numbers[col]/shuffle_total_numbers[0]) * (shuffled_numbers[col_2]/shuffle_total_numbers[0])\n",
    "            # shuff_odds_actual = shuff_actual_prob/ (1-shuff_actual_prob)\n",
    "            # shuff_odds_joint = shuff_joint_prob/ (1-shuff_joint_prob)\n",
    "            shuff_effect = (shuff_actual_prob/shuff_joint_prob).astype(float)\n",
    "            shuff_log_effect = np.log2(shuff_effect+1e-3)\n",
    "            mean_shuff_log_effect = shuff_log_effect.mean()\n",
    "            # actual_odds = (probs_actual) / (1 - (probs_actual))\n",
    "            # joint_odds = (probs_joint) / (1 - (probs_joint))\n",
    "            actual_effect = probs_actual/probs_joint\n",
    "            # probs_df.loc['odds_actual', f'{col}, {col_2}'] = probs_actual\n",
    "            # probs_df.loc['odds_joint', f'{col}, {col_2}'] = joint_odds\n",
    "            probs_df.loc['mean_shuf', f'{col}, {col_2}'] = mean_shuff_log_effect\n",
    "            #probs_df.loc['mean_shuf_subtracted', f'{col}, {col_2}'] = np.log2(actual_effect - shuff_effect.mean())\n",
    "            probs_df.loc['log_OR_actual', f'{col}, {col_2}'] = np.log2(actual_effect +1e-3)\n",
    "            mu, std = norm.fit(shuff_effect)\n",
    "            if actual_effect >= shuff_effect.mean():\n",
    "                p_val = norm.sf(actual_effect, loc=mu, scale=std) * 2  # two-sided\n",
    "            else:\n",
    "                p_val = norm.cdf(actual_effect, loc=mu, scale=std) * 2\n",
    "            # if OR_actual >= oddd.mean():\n",
    "            #     p_val = ((sum(1 for value in oddd if value > OR_actual)+1)/(len(oddd)+1))*2\n",
    "            # elif val_to_comp < mean_corr:\n",
    "            #     p_val = ((sum(1 for value in oddd if value < OR_actual)+1)/(len(oddd)+1))*2 \n",
    "            p_val_adj = p_val* total_combinations\n",
    "            probs_df.loc['p_value', f'{col}, {col_2}'] = p_val_adj\n",
    "to_plot = probs_df.T\n",
    "to_plot['-log10_p_value'] = -np.log10(to_plot['p_value'])\n",
    "to_plot['shuf-sub'] = to_plot['log_OR_actual'] -to_plot['mean_shuf']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(1.5, 1.1), constrained_layout=True)\n",
    "fig = plt.figure(figsize=(18/2.54, 6/2.54))\n",
    "dict_to_look = cond_prob_dict  # Only use the first dictionary\n",
    "title = 'Actual'\n",
    "font_size = 6\n",
    "cosine_dict = {}\n",
    "for mouse in mice:\n",
    "    cosine_dict[mouse] = fpf.get_cosine_sim_of_probs(matrix=dict_to_look[mouse], cols=cols)\n",
    "\n",
    "cosine_df = pd.concat(cosine_dict.values()).groupby(level=0).mean()\n",
    "cosine_df = cosine_df.loc[cols][cols]\n",
    "\n",
    "ax = fig.add_axes([0.1, 0.25, 0.2, 0.6])\n",
    "cbax = fig.add_axes([0.31, 0.4, 0.01, 0.35])\n",
    "sb.heatmap(\n",
    "    data=fpf.convert_matrix_names(cosine_df),\n",
    "    cmap='Purples', #'RdBu_r',\n",
    "    xticklabels=True,\n",
    "    yticklabels=True,\n",
    "    ax=ax,\n",
    "    cbar_ax=cbax,\n",
    "    vmin=0.85,\n",
    "    vmax=1,\n",
    ")\n",
    "ax.tick_params(axis='y', which='major', labelsize=font_size, rotation=0)\n",
    "ax.tick_params(axis='x', which='major', labelsize=font_size, rotation=90)\n",
    "for _, spine in ax.spines.items():\n",
    "    spine.set_visible(True)\n",
    "    spine.set_color('black')\n",
    "    spine.set_linewidth(1)\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.outline.set_visible(True)\n",
    "cbar.outline.set_edgecolor('black')\n",
    "cbar.outline.set_linewidth(1)\n",
    "cbax.set_yticks([0.85, 1])\n",
    "cbax.tick_params(labelsize=font_size)\n",
    "cbax.set_title('Cosine\\nsimilarity', fontsize=font_size, loc='left')\n",
    "\n",
    "colors_to_colour = ff.get_colour_dict()\n",
    "alpha_val_stream = 1\n",
    "to_plot['-log10_p_value'] = to_plot['-log10_p_value'].clip(upper=50)\n",
    "to_plot['stream'] = to_plot.index.map(classify_stream)\n",
    "ax = fig.add_axes([0.46, 0.25, 0.24, 0.6])\n",
    "plt.scatter(\n",
    "    to_plot[to_plot['stream'] == 'other']['shuf-sub'],\n",
    "    to_plot[to_plot['stream'] == 'other']['-log10_p_value'],\n",
    "    color=colors_to_colour['OUT'], \n",
    "    s=dot_size, \n",
    "    alpha=1,\n",
    "    label=\"Other areas\"\n",
    ")\n",
    "plt.scatter(\n",
    "    to_plot[to_plot['stream'] == 'dorsal']['shuf-sub'],\n",
    "    to_plot[to_plot['stream'] == 'dorsal']['-log10_p_value'],\n",
    "    color=colors_to_colour['dorsal'], \n",
    "    alpha=alpha_val_stream, \n",
    "    s=dot_size,\n",
    "    label='Dorsal-Dorsal'\n",
    ")\n",
    "plt.scatter(\n",
    "    to_plot[to_plot['stream'] == 'ventral']['shuf-sub'],\n",
    "    to_plot[to_plot['stream'] == 'ventral']['-log10_p_value'],\n",
    "    color=colors_to_colour['ventral'], \n",
    "    alpha=alpha_val_stream, \n",
    "    s=dot_size, \n",
    "    label='Ventral-Ventral'\n",
    ")\n",
    "plt.scatter(\n",
    "    to_plot[to_plot['stream'] == 'dorsal-ventral']['shuf-sub'],\n",
    "    to_plot[to_plot['stream'] == 'dorsal-ventral']['-log10_p_value'],\n",
    "    color=colors_to_colour['dorso-ventral'], \n",
    "    alpha=alpha_val_stream, \n",
    "    s=dot_size, \n",
    "    label='Dorsal-Ventral'\n",
    ")\n",
    "\n",
    "plt.axhline(y=-np.log10(0.05), color='black', linestyle='--', linewidth=0.5)  # Horizontal line at p=0.05\n",
    "convert_dict = ff.get_convert_dict()\n",
    "\n",
    "areas_to_check = ['VISrl, AUDv', 'VISpl, VISli', 'VISam, VISpor', 'VISa, VISpm', 'VISli, VISpor', 'VISrl, VISli', 'VISrl, VISpm']\n",
    "for pair in areas_to_check:\n",
    "    areas = pair.split(', ') \n",
    "    x_val = to_plot.loc[pair, 'shuf-sub']\n",
    "    y_val = to_plot.loc[pair, '-log10_p_value']\n",
    "    offset_y = y_val + 2\n",
    "    if areas[0] in convert_dict:\n",
    "        areas[0] = convert_dict[areas[0]]\n",
    "    if areas[1] in convert_dict:\n",
    "        areas[1] = convert_dict[areas[1]]\n",
    "    # Scatter annotation text to avoid overlaps\n",
    "    # Use a simple vertical offset that increases for each annotation to reduce overlap\n",
    "    # Optionally, you can use a more advanced algorithm for better placement\n",
    "    offset_x = x_val + np.sign(x_val - 0.5)\n",
    "    plt.annotate(\n",
    "        f'{areas[0]}, {areas[1]}', \n",
    "        xy=(x_val, y_val), \n",
    "        xytext=(offset_x, y_val),  \n",
    "        fontsize=font_size, \n",
    "        ha='center', \n",
    "        va='center', \n",
    "        color='black',\n",
    "        arrowprops=dict(\n",
    "            arrowstyle=\"-\", \n",
    "            color=\"black\", \n",
    "            linewidth=0.5, \n",
    "            alpha=1, \n",
    "            shrinkA=0, \n",
    "            shrinkB=0,\n",
    "            connectionstyle=\"arc3,rad=0\"\n",
    "        )  \n",
    "    )\n",
    "sb.despine(ax=ax, offset=5)\n",
    "plt.xlabel('Log2(Actual/Shuffled Effect Size)', fontsize=font_size)\n",
    "plt.ylabel('-$log_{10}$(p-value)', fontsize=font_size)\n",
    "ax.tick_params(labelsize=font_size)\n",
    "plt.ylim(0, 55)\n",
    "plt.xlim(-2, 2)\n",
    "plt.legend(\n",
    "    loc='upper left', \n",
    "    prop={'size': 6}, \n",
    "    frameon=False, \n",
    "    bbox_to_anchor=(-.025, 1.15),\n",
    "    handlelength=1,\n",
    ")\n",
    "# ff.myPlotSettings_splitAxis(fig=fig, ax=ax, ytitle= ylabel, xtitle=xlabel, title='', mySize =font_size)\n",
    "\n",
    "stream_label_map = {\n",
    "    'dorsal': 'Dorsal-Dorsal',\n",
    "    'ventral': 'Ventral-Ventral',\n",
    "    'dorsal-ventral': 'Dorsal-Ventral',\n",
    "    'other': 'Other'\n",
    "}\n",
    "to_plot['stream_label'] = to_plot['stream'].map(stream_label_map)\n",
    "stream_order = ['Dorsal-Dorsal', 'Ventral-Ventral', 'Dorsal-Ventral']\n",
    "plot_data = to_plot[to_plot['stream_label'].isin(stream_order)]\n",
    "wrapped_labels = [textwrap.fill(label, width=8) for label in stream_order]\n",
    "\n",
    "ax = fig.add_axes([0.83, 0.35, 0.08, 0.5])\n",
    "dd = plot_data[plot_data['stream_label'] == 'Dorsal-Dorsal']['shuf-sub']\n",
    "vv = plot_data[plot_data['stream_label'] == 'Ventral-Ventral']['shuf-sub']\n",
    "dv = plot_data[plot_data['stream_label'] == 'Dorsal-Ventral']['shuf-sub']\n",
    "\n",
    "stat_dd_dv, p_dd_dv = mannwhitneyu(dd, dv, alternative='two-sided')\n",
    "stat_vv_dv, p_vv_dv = mannwhitneyu(vv, dv, alternative='two-sided')\n",
    "colors_dict = {\n",
    "    'Dorsal-Dorsal': colors_to_colour['dorsal'],\n",
    "    'Ventral-Ventral': colors_to_colour['ventral'],\n",
    "    'Dorsal-Ventral': colors_to_colour['dorso-ventral']\n",
    "}\n",
    "sb.swarmplot(\n",
    "    data=plot_data,\n",
    "    y='shuf-sub',\n",
    "    x='stream_label',\n",
    "    palette=colors_dict,\n",
    "    size=dot_size,\n",
    "    alpha=alpha_val,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.5,\n",
    "    ax=ax,\n",
    "    dodge=True,\n",
    "    hue='stream_label',\n",
    "    order=stream_order,\n",
    "    hue_order=stream_order,\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "for i, key in enumerate(stream_order):\n",
    "    values = plot_data[plot_data['stream_label'] == key]['shuf-sub'].values\n",
    "    xvals = np.full(len(values), i)\n",
    "    color = colors_dict[key]\n",
    "\n",
    "    # ax.scatter(\n",
    "    #     xvals, values,\n",
    "    #     marker='o',\n",
    "    #     facecolors='none',\n",
    "    #     edgecolors=color,\n",
    "    #     linewidth=0.5,\n",
    "    #     s=10  \n",
    "    # )\n",
    "    mean_val = np.mean(values)\n",
    "    ax.hlines(\n",
    "        y=mean_val,\n",
    "        xmin=i - 0.4,\n",
    "        xmax=i + 0.4,\n",
    "        colors=color,\n",
    "        linewidth=2\n",
    "    )\n",
    "sb.despine(ax=ax, offset=5)\n",
    "\n",
    "ax.set_xticks(range(len(stream_order)))\n",
    "ax.set_xticklabels(stream_order, rotation=45, fontsize=font_size, ha='right')\n",
    "y_max = plot_data['shuf-sub'].max()\n",
    "bar_height = y_max + 0.2\n",
    "text_offset = 0.05\n",
    "line_width = 0.5\n",
    "\n",
    "def add_sig_marker(x1, x2, y, p_val):\n",
    "    if p_val < 0.05:\n",
    "        ax.plot([x1, x1, x2, x2], [y, y + text_offset, y + text_offset, y],\n",
    "                lw=line_width, color='black')\n",
    "        ax.text((x1 + x2) / 2, y + text_offset + 0.02, '*', \n",
    "                ha='center', va='bottom', color='black', fontsize=10)\n",
    "if p_dd_dv < 0.05:\n",
    "    add_sig_marker(0, 2, bar_height, p_dd_dv)\n",
    "    bar_height += 0.2\n",
    "if p_vv_dv < 0.05:\n",
    "    add_sig_marker(1, 2, bar_height, p_vv_dv)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel('Log2(Actual/Shuffled Effect Size)', fontsize=font_size)\n",
    "ax.tick_params(labelsize=font_size)\n",
    "# ff.myPlotSettings_splitAxis(fig=fig, ax=ax, ytitle=ylabel, xtitle='', title='', mySize=5)\n",
    "fig.savefig(f\"{saving_path}/fig2_stream_effectsize.svg\", format=\"svg\")\n",
    "fig.savefig(f\"{saving_path}/fig2_stream_effectsize.pdf\", format=\"pdf\")\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "print(f\"Dorsal-Dorsal vs Dorsal-Ventral: U={stat_dd_dv:.3f}, p={p_dd_dv:.4f}\")\n",
    "print(f\"Ventral-Ventral vs Dorsal-Ventral: U={stat_vv_dv:.3f}, p={p_vv_dv:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot differences in frequency of targeting against AP soma position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proj_path = pathlib.Path(\"/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq\")\n",
    "with open(\"general_analysis_parameters.yaml\", \"r\") as file:\n",
    "    gen_parameters = yaml.safe_load(file)\n",
    "proj_path = gen_parameters['proj_path']\n",
    "HVA_cols = gen_parameters['HVA_cols'] #['VISp', 'VISpor', 'VISli', 'VISal', 'VISl', 'VISpl', 'VISpm', 'VISrl', 'VISam', 'VISa']\n",
    "\n",
    "mice = gen_parameters['MICE']\n",
    "combined_mice_dict = {}\n",
    "for mouse in mice:\n",
    "    new_dict = {}\n",
    "    parameters_path = (\n",
    "    f\"{proj_path}/{mouse}/Sequencing\")\n",
    "    parameters = fpf.load_parameters(directory=parameters_path)\n",
    "    barcodes = pd.read_pickle(f\"{parameters_path}/A1_barcodes_thresholded.pkl\")\n",
    "    barcodes = barcodes[barcodes.astype(bool).sum(axis=1)>0]\n",
    "    new_dict['homog_across_cubelet'] =fpf.homog_across_cubelet(parameters_path= parameters_path, barcode_matrix = barcodes, cortical=True, shuffled=False, IT_only=True, remove_AUDp_vis_cub=True)\n",
    "    combined_mice_dict[mouse] = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not ness since no barcodes are shared between mice, but in case of re-use\n",
    "# def add_prefix_to_index(df, prefix):\n",
    "#     df = df.copy()  # Avoid modifying the original DataFrame\n",
    "#     df.index = [f\"{prefix}_{idx}\" for idx in df.index]\n",
    "#     return df\n",
    "index_adj_combined_dict = {}\n",
    "\n",
    "for mouse in mice:\n",
    "    index_adj_combined_dict[mouse] = fpf.add_prefix_to_index(combined_mice_dict[mouse]['homog_across_cubelet'], mouse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'homog_across_cubelet'\n",
    "common_cols_cortex = fpf.get_common_columns(mice= mice, combined_dict=combined_mice_dict, key=key, cortex=True)\n",
    "combine_all_mice = pd.concat([\n",
    "    index_adj_combined_dict[k][common_cols_cortex] for k in mice\n",
    "])\n",
    "which_mice = pd.DataFrame(columns = ['mice'], index= combine_all_mice.index)\n",
    "for k in mice:\n",
    "    which_mice.loc[index_adj_combined_dict[k].index, 'mice'] = k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "mcc = MouseConnectivityCache()\n",
    "bg_atlas = BrainGlobeAtlas(\"allen_mouse_25um\", check_latest=False)\n",
    "AUDp_id = bg_atlas.structures['AUDp']['id']\n",
    "rsp = mcc.get_reference_space()\n",
    "AUDp_mask = rsp.make_structure_mask([AUDp_id], direct_only=False)\n",
    "indices_AUDp = np.argwhere(AUDp_mask == 1)\n",
    "VIS_mask = rsp.make_structure_mask([669], direct_only=False) #669 is id for whole visual cortex\n",
    "indices_VIS = np.argwhere(VIS_mask == 1)\n",
    "max_y_vis = np.max(indices_VIS[:, 0])\n",
    "min_y_vis = np.min(indices_VIS[:, 0])\n",
    "#select anterior and posterior parts of A1\n",
    "max_y = np.max(indices_AUDp[:, 0])\n",
    "min_y = np.min(indices_AUDp[:, 0])\n",
    "# AP_midpoint_A1 = ((max_y - min_y) /2) + min_y\n",
    "# posterior_neurons = indices_AUDp[indices_AUDp[:, 0]>=AP_midpoint_A1]\n",
    "# anterior_neurons = indices_AUDp[indices_AUDp[:, 0]<AP_midpoint_A1]\n",
    "#now select only the ipsiliateral side of where was injected\n",
    "x_midpoint = AUDp_mask.shape[2] // 2\n",
    "contra_mask = np.zeros_like(AUDp_mask, dtype=bool)\n",
    "contra_mask[:, :, x_midpoint:] = 1\n",
    "#lets get the coordinates for the centre of A1\n",
    "A1_masked = contra_mask * AUDp_mask\n",
    "A1_centroid_coords = np.argwhere(A1_masked == 1).mean(axis=0)\n",
    "\n",
    "#now lets load the barcodes\n",
    "proj_path = pathlib.Path(proj_path)\n",
    "#mice = ['FIAA45.6a', 'FIAA45.6d', 'FIAA55.4d']\n",
    "\n",
    "mouse_dict_AP_source = {}\n",
    "mouse_dict_AP_VC = {}\n",
    "mouse_barcodes_by_source = {}\n",
    "mouse_vis_main_dict = {}\n",
    "mouse_vis_coord = {}\n",
    "for mouse in mice:\n",
    "    #if mouse == 'FIAA45.6d':\n",
    "    AP_position_dict = {}\n",
    "    AP_position_vis_dict = {}\n",
    "    vis_main_dict = {}\n",
    "    barcodes = pd.read_pickle(f\"{proj_path}/{mouse}/Sequencing/A1_barcodes_thresholded_with_source.pkl\")\n",
    "    barcodes_no_soma = pd.read_pickle(f\"{proj_path}/{mouse}/Sequencing/A1_barcodes_thresholded.pkl\")\n",
    "    lcm_directory = proj_path/f\"{mouse}/LCM\"\n",
    "    ROI_3D = np.load(lcm_directory / \"ROI_3D_25.npy\")\n",
    "    all_VIS_ROI = np.unique(ROI_3D *  VIS_mask * contra_mask)\n",
    "    vis_coord = {}\n",
    "    #lets make sure we keep the same criteria of removing VIS rois where more than 10% is in AUDp\n",
    "    areas_only_grouped = fpf.get_area_volumes(\n",
    "        barcode_table_cols=barcodes_no_soma.columns,\n",
    "        lcm_directory=lcm_directory,\n",
    "        area_threshold=0.1,\n",
    "    )\n",
    "    #HVA_cols = ['VISli','VISpor', 'VISpl', 'VISl', 'VISp', 'VISal', 'VISam', 'VISpm', 'VISa', 'VISrl']\n",
    "    frac = areas_only_grouped.div(areas_only_grouped.sum(axis=1), axis=0)\n",
    "    frac_filtered = frac.loc[(frac[HVA_cols].gt(0).any(axis=1)) & (frac['AUDp'] > 0.1)].index\n",
    "    all_VIS_ROI = [sample for sample in all_VIS_ROI if sample != 0 and sample in barcodes_no_soma.columns and sample not in frac_filtered and areas_only_grouped[HVA_cols].loc[sample].sum()>0]\n",
    "\n",
    "    for sample in all_VIS_ROI:\n",
    "        centroid = np.argwhere(ROI_3D == sample).mean(axis=0)\n",
    "        vis_coord[sample] = centroid\n",
    "        AP_position_vis_dict[sample] = max_y_vis - centroid[0] #centroid[0]-min_y_vis\n",
    "        vis_main_dict[sample] = areas_only_grouped[HVA_cols].loc[sample].idxmax()\n",
    "    AP_samples = {}\n",
    "    AP_source_filtered = {}\n",
    "    all_AUDp_samples = np.unique(ROI_3D *  AUDp_mask * contra_mask)\n",
    "    all_AUDp_samples = [sample for sample in all_AUDp_samples if sample != 0]\n",
    "    all_AUDp_samples = [sample for sample in all_AUDp_samples if sample in barcodes.columns]\n",
    "    for sample in all_AUDp_samples:\n",
    "        centroid = np.argwhere(ROI_3D == sample).mean(axis=0)\n",
    "        AP_position_dict[sample] = max_y_vis - centroid[0]#-min_y#AP_midpoint_A1\n",
    "    mouse_dict_AP_source[mouse]=AP_position_dict\n",
    "    mouse_dict_AP_VC[mouse] = AP_position_vis_dict\n",
    "    mouse_vis_main_dict[mouse] = vis_main_dict\n",
    "    mouse_vis_coord[mouse] = vis_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get the coordinates for the centre of A1\n",
    "A1_masked = contra_mask * AUDp_mask\n",
    "A1_centroid_coords = np.argwhere(A1_masked == 1).mean(axis=0)\n",
    "vis_ipsi = VIS_mask * contra_mask\n",
    "VC_centroid_coords = np.argwhere(vis_ipsi == 1).mean(axis=0)\n",
    "# get list of sources from each barcode, then create a dictionary\n",
    "#soma = pd.DataFrame(barcodes.idxmax(axis=1))\n",
    "def get_AP_position(row, dictionary):\n",
    "    key = row[0]\n",
    "    if key in dictionary.keys():\n",
    "        return dictionary[key]\n",
    "    else:\n",
    "        return None  # or any other default value you want to use if the key is not found\n",
    "#make a dataframe with mean AP_pos of sample, mouse and AP_soma\n",
    "AP_soma_VC_sample = pd.DataFrame(columns=['Mouse', 'mean_AP_soma', 'AP_Vis', 'VC_majority', 'dist_3d', 'sample'])\n",
    "AP_soma_VC_sample_all = pd.DataFrame(columns=['Mouse', 'actual_AP_soma', 'AP_Vis'])\n",
    "barcodes_dict = {}\n",
    "AP_position_dict_list = {}\n",
    "for mouse in mice:\n",
    "    new_dict = {}\n",
    "    parameters_path = (\n",
    "    f\"{proj_path}/{mouse}/Sequencing\")\n",
    "    barcodes = pd.read_pickle(f\"{parameters_path}/A1_barcodes_thresholded_with_source.pkl\")\n",
    "    barcodes= fpf.add_prefix_to_index(barcodes, mouse)\n",
    "    soma = pd.DataFrame(barcodes.idxmax(axis=1))\n",
    "    soma['AP_position'] = soma.apply(lambda row: get_AP_position(row, mouse_dict_AP_source[mouse]), axis=1)\n",
    "    soma['mouse'] = mouse\n",
    "    #soma['uncorrected_AP']= soma.apply(lambda row: get_AP_position(row, mouse_dict_AP_source_uncorrected[mouse]), axis=1)\n",
    "    for sample in mouse_dict_AP_VC[mouse].keys():\n",
    "        indices_for_sample = barcodes[barcodes[sample]>0].index\n",
    "        if len(indices_for_sample)>2:\n",
    "            mean_AP=np.mean(soma.loc[indices_for_sample]['AP_position'])\n",
    "            uncorrected_meanAP = -(mean_AP) + max_y #back to non-normalised\n",
    "            A1_coord_updated = [uncorrected_meanAP, A1_centroid_coords[1], A1_centroid_coords[2]]\n",
    "            vis_cubelet_coord_updated = [mouse_vis_coord[mouse][sample][0], VC_centroid_coords[1], VC_centroid_coords[2]]\n",
    "            dist_3d = np.linalg.norm(np.array(A1_coord_updated) - np.array(vis_cubelet_coord_updated)) * 25\n",
    "            new_row= pd.DataFrame({'Mouse':[mouse], 'mean_AP_soma':[mean_AP*25], 'AP_Vis':[mouse_dict_AP_VC[mouse][sample]*25], 'VC_majority': [mouse_vis_main_dict[mouse][sample]], 'dist_3d': [dist_3d], 'sample': [sample]})\n",
    "            # bl = pd.DataFrame()\n",
    "            # bl['AP_postion'] = soma.loc[indices_for_sample]['AP_position']\n",
    "            # bl['Mouse'] = mouse\n",
    "            # bl['actual_AP_soma'] = mouse_dict_AP_VC[mouse][sample]\n",
    "            AP_soma_VC_sample = pd.concat([AP_soma_VC_sample, new_row])\n",
    "            #AP_soma_VC_sample_all = pd.concat([AP_soma_VC_sample_all, bl])\n",
    "    #barcodes_dict[mouse] = barcodes_assigned_area.drop(columns=['AUDp'])\n",
    "    #soma_filtered = soma.loc[combined_mice_dict[mouse]['homog_across_cubelet'].index]\n",
    "    AP_position_dict_list[mouse] = soma#soma_filtered\n",
    "    # mouse_euclidean_dist[mouse] = euclidean_dist\n",
    "\n",
    "AP_position_dict_list_combined = pd.concat([\n",
    "    AP_position_dict_list[k] for k in mice\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "convert_dict = ff.get_convert_dict()#{\n",
    "#     \"VISl\": \"LM\",\n",
    "#     \"VISrl\": \"RL\",\n",
    "#     \"VISal\": \"AL\",\n",
    "#     \"VISa\": \"A\",\n",
    "#     \"VISp\": \"V1\",\n",
    "#     \"VISpor\": \"POR\",\n",
    "#     \"VISli\": \"LI\",\n",
    "#     \"VISpl\": \"P\",\n",
    "#     \"VISpm\": \"PM\",\n",
    "#     \"VISam\": \"AM\"\n",
    "# }\n",
    "which_colour = ff.get_colour_dict(allen_nomenclature=True)\n",
    "AP_soma_VC_sample['converted'] = AP_soma_VC_sample['VC_majority'].map(convert_dict)\n",
    "which_colour_other = ff.get_colour_dict(allen_nomenclature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho, pval = pearsonr(AP_soma_VC_sample['AP_Vis'], AP_soma_VC_sample['mean_AP_soma'])\n",
    "saving_path = gen_parameters['fig_saving_path']\n",
    "font_size = gen_parameters['font_size']\n",
    "# Plotting regression plot with confidence interval\n",
    "# plt.figure(figsize=(4, 3))\n",
    "fig, ax = plt.subplots(figsize=(1, 1)) \n",
    "sb.regplot(\n",
    "    x='AP_Vis',\n",
    "    y='mean_AP_soma',\n",
    "    data=AP_soma_VC_sample, color='black', scatter=False,\n",
    "    ci=95, scatter_kws={'s':5}, line_kws={'linewidth':1}\n",
    ")\n",
    "scatter = sb.scatterplot(\n",
    "    x='AP_Vis', \n",
    "    y='mean_AP_soma', \n",
    "    data=AP_soma_VC_sample, \n",
    "    hue='converted', legend=False,\n",
    "    palette=which_colour_other,  # Apply color mapping from dictionary\n",
    "    s=5  # Scatter point size\n",
    ")\n",
    "handles, labels = scatter.get_legend_handles_labels()\n",
    "# ax.legend(\n",
    "#     handles=handles, \n",
    "#     labels=labels, \n",
    "#     title=\"VC area\", title_fontsize=font_size,\n",
    "#     bbox_to_anchor=(1.3, -0.3),  \n",
    "#     loc='lower left', \n",
    "#     borderaxespad=0, \n",
    "#     fontsize=font_size, \n",
    "#     handlelength=1,\n",
    "#     handletextpad=0.4,\n",
    "#     markerscale=0.2)\n",
    "\n",
    "plt.text(\n",
    "    0.7, 0.2,\n",
    "    f\"R = {rho:.2f}\\np = {pval:.2e}\",\n",
    "    ha='left',\n",
    "    va='top',\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=font_size,\n",
    "    bbox=dict(boxstyle='round', facecolor='white', alpha=0.0)\n",
    ")\n",
    "\n",
    "# Axis labels\n",
    "xlabel = 'Cubelet A-P\\nposition ($\\mu$m)'\n",
    "ylabel = 'Mean soma A-P\\nposition ($\\mu$m)'\n",
    "\n",
    "# Add Anterior/Posterior labels\n",
    "# plt.text(-0.02, -0.16, 'Posterior', transform=plt.gca().transAxes, fontsize=8, ha='left', va='bottom')\n",
    "\n",
    "plt.text(1.55, -0.3, 'Anterior', ha='right', va='bottom', transform=plt.gca().transAxes, fontsize=font_size)\n",
    "plt.text(-0.4, 1.1, 'Anterior', ha='center', va='bottom', transform=plt.gca().transAxes, fontsize=font_size)\n",
    "plt.text(-0.4, -0.3, 'Posterior', transform=plt.gca().transAxes, fontsize=font_size, va='bottom', ha='center')\n",
    "ff.myPlotSettings_splitAxis(fig=fig, ax=ax, ytitle= ylabel, xtitle=xlabel, title='', mySize =gen_parameters['font_size'])\n",
    "# plt.xlim(left=0)\n",
    "# plt.ylim(bottom=0)\n",
    "#plt.tight_layout()\n",
    "plt.xticks([0, 3000])\n",
    "# plt.yticks([0, 500, 1000])\n",
    "fig.savefig(f\"{saving_path}/fig_2_AP_vs_VISAP.svg\", format=\"svg\")\n",
    "fig.savefig(f\"{saving_path}/fig_2_AP_vs_VISAP.pdf\", format=\"pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if it was mainly Euclidean distance driving AP patterning, \n",
    "# we would expect AP cubelet bins with the same euclidean distance to a given soma AP position to have the same liklihood of projecting\n",
    "# we would expect the soma location for each VC projection to be more likely to be in equivalent AP position versus the closest distance\n",
    "#first lets split AC and VC into bins of 10 AP positions\n",
    "#next, for each VC bin, lets find the AC bin that is closest in euclidean distance\n",
    "#then lets find the bin that is closest in AP ranking\n",
    "#for each neuron targeting the VC, we ask if it is more likely to have a soma in equivalent AP bin or in closest distance bin, how does this comp to random bin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_bins = 8\n",
    "n_ac_bins = 4\n",
    "n_vc_bins = 4\n",
    "\n",
    "ac_span = (max_y - min_y)*25   \n",
    "vc_span = (max_y_vis - min_y_vis) *25 \n",
    "ac_bin_edges = np.linspace(0, ac_span, n_ac_bins + 1)\n",
    "vc_bin_edges = np.linspace(0, vc_span, n_vc_bins + 1)\n",
    "def get_bin_id(x, edges):\n",
    "    # np.searchsorted(..., side='right') returns the index of the bin to the right\n",
    "    # subtract 1 so that an x thats just below edges[i] ends up in bin i-1\n",
    "    return np.searchsorted(edges, x, side='right') - 1\n",
    "# AP_position_dict_list_combined['AC_bin_id']= AP_position_dict_list_combined['AP_position'].apply(lambda x: get_bin_id(x, ac_bin_edges))\n",
    "AP_soma_VC_sample['VC_bin_id']= AP_soma_VC_sample['AP_Vis'].apply(lambda x: get_bin_id(x, vc_bin_edges))\n",
    "data = [\n",
    "    {'mouse': mouse, 'sample': sample, 'AP': value}\n",
    "    for mouse, samples in mouse_dict_AP_source.items()\n",
    "    for sample, value in samples.items()\n",
    "]\n",
    "\n",
    "soma_AP_pos = pd.DataFrame(data)\n",
    "soma_AP_pos['AP_microns']= soma_AP_pos['AP']*25\n",
    "soma_AP_pos['AC_bin_id']= soma_AP_pos['AP_microns'].apply(lambda x: get_bin_id(x, ac_bin_edges))\n",
    "soma_AP_pos_A1_only = soma_AP_pos[~soma_AP_pos['AC_bin_id'].isin([-1, n_ac_bins])] #remove bins with centroids outside of A1 (since our initial sorting for annotating AP position in A1 is not on source samples, but any sample that happen to contain some A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if number of vc bins different to ac bins, we work out which each converts to\n",
    "# vc_bin_conversion = {}\n",
    "# conv_factor = n_vc_bins/n_ac_bins\n",
    "# for val in range(n_vc_bins):\n",
    "#     ac_bin = int(np.floor(val / conv_factor))\n",
    "#     ac_bin = min(ac_bin, n_ac_bins - 1)\n",
    "#     vc_bin_conversion[val] = ac_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_bin_centers = (ac_bin_edges[:-1] + ac_bin_edges[1:]) / 2\n",
    "vc_bin_centers = (vc_bin_edges[:-1] + vc_bin_edges[1:]) / 2\n",
    "ac_bin_dict = {i: center for i, center in enumerate(ac_bin_centers)}\n",
    "vc_bin_dict = {i: center for i, center in enumerate(vc_bin_centers)}\n",
    "VC_closest_soma_bin = {}\n",
    "VC_coord_dict = {}\n",
    "AC_coord_dict = {}\n",
    "VC_closest_soma_distances = {}\n",
    "empty_ac = np.zeros((1320, 800, 1140))\n",
    "distance_dict = {'ac_bin':[], 'vc_bin': [], 'dist': []}\n",
    "for bin_2 in range(n_vc_bins):\n",
    "    reverted_VIS_AP = -(vc_bin_dict[bin_2]/25) + max_y_vis\n",
    "    VC_coords= [reverted_VIS_AP, VC_centroid_coords[1], VC_centroid_coords[2]]\n",
    "    VC_coord_dict[bin_2] = [reverted_VIS_AP, VC_centroid_coords[2]]\n",
    "    dist_dict = {}\n",
    "    for bin in range(n_ac_bins):\n",
    "        reverted_soma_AP = -(ac_bin_dict[bin]/25) + max_y\n",
    "        soma_A1_coords = [reverted_soma_AP, A1_centroid_coords[1], A1_centroid_coords[2]]\n",
    "        AC_coord_dict[bin] = [reverted_soma_AP, A1_centroid_coords[2]]\n",
    "        empty_ac[int(soma_A1_coords[0]), int(soma_A1_coords[1]), int(soma_A1_coords[2])] = bin+1\n",
    "        dist_dict[bin] = np.linalg.norm(np.array(soma_A1_coords) - np.array(VC_coords)) \n",
    "        distance_dict['ac_bin'].append(bin)\n",
    "        distance_dict['vc_bin'].append(bin_2)\n",
    "        distance_dict['dist'].append(dist_dict[bin]*25)\n",
    "    min_dist = min(dist_dict, key=dist_dict.get)\n",
    "    VC_closest_soma_bin[bin_2] = 0\n",
    "    VC_closest_soma_distances[bin_2] = dist_dict[0] #only plot lines between ac bin zero and the others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cortex_id = bg_atlas.structures['Isocortex']['id']\n",
    "all_cortex = rsp.make_structure_mask([all_cortex_id], direct_only=False)\n",
    "AUDp_mask = rsp.make_structure_mask([AUDp_id], direct_only=False)\n",
    "indices_AUDp = np.argwhere(AUDp_mask == 1)\n",
    "all_cortex[indices_AUDp] = 2\n",
    "VIS_mask = rsp.make_structure_mask([669], direct_only=False) \n",
    "all_cortex[np.argwhere(AUDp_mask == 1)] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isocortex_id   = bg_atlas.structures['Isocortex']['id']\n",
    "isocortex_mask = rsp.make_structure_mask([isocortex_id], direct_only=False).astype(np.uint8)\n",
    "\n",
    "audp_mask      = rsp.make_structure_mask([AUDp_id], direct_only=False)\n",
    "vis_mask       = rsp.make_structure_mask([669],     direct_only=False)   # VIS\n",
    "\n",
    "all_cortex              = np.zeros_like(isocortex_mask, dtype=np.uint8)\n",
    "all_cortex[isocortex_mask == 1] = 1          # all cortex\n",
    "all_cortex[audp_mask     == 1] = 2           # AUDp\n",
    "all_cortex[vis_mask      == 1] = 3           # VIS cortex\n",
    "\n",
    "zproj = all_cortex.max(axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "fig_size = (3, 3)\n",
    "fig, ax = plt.subplots(figsize=fig_size)\n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "ax.set_facecolor('white')\n",
    "colors = ['white', 'gray', 'steelblue', 'orchid']  # 0: white, 1: red, 2: blue, others: gray\n",
    "cmap = ListedColormap(colors)\n",
    "bounds = [0, 0.5, 1.5, 2.5, 255]  # 0-0.5 -> white, 0.5-1.5 -> red, 1.5-2.5 -> blue, others -> gray\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "ax.imshow(zproj.T, origin='lower', cmap=cmap, norm=norm, interpolation='nearest')\n",
    "\n",
    "font_size = 8\n",
    "dx, dy = 2, 2\n",
    "for k, (x, y) in AC_coord_dict.items():\n",
    "    ax.scatter(x, y, s=8, color='black', zorder=3)\n",
    "    # ax.text(x + dx, y + dy, str(k), color='black', fontsize=font_size,\n",
    "    #         ha='left', va='center', zorder=4)\n",
    "\n",
    "# Plot VC points and links\n",
    "for k, (x, y) in VC_coord_dict.items():\n",
    "    ax.scatter(x, y, s=8, color='black', marker='x', zorder=3)\n",
    "    # ax.text(x + dx, y + dy, str(k), color='black', fontsize=font_size,\n",
    "    #         ha='left', va='center', zorder=4)\n",
    "\n",
    "    ac_bin = VC_closest_soma_bin.get(k)\n",
    "    if ac_bin in AC_coord_dict:\n",
    "        x_ac, y_ac = AC_coord_dict[ac_bin]\n",
    "        ax.plot([x, x_ac], [y, y_ac], c='black', linestyle='--', lw=1, alpha=1, zorder=2)\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "fig.canvas.draw()\n",
    "\n",
    "w, h = fig.canvas.get_width_height()\n",
    "plt.close(fig)\n",
    "\n",
    "img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "img = img.reshape((h, w, 3))\n",
    "img_rot = np.rot90(img, k=-1)\n",
    "img_rf = np.fliplr(img_rot)\n",
    "\n",
    "plt.figure(figsize=fig_size)\n",
    "plt.imshow(img_rf)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(f\"{saving_path}/supplementary/fig_s4_AP_vs_dist.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 2\n",
    "for num, edge in enumerate(ac_bin_edges):\n",
    "    if num != len(ac_bin_edges)-1:\n",
    "        reverted_bin_edge_min = int(-(ac_bin_edges[num]/25) + max_y)\n",
    "        reverted_bin_edge_max = int(-(ac_bin_edges[num+1]/25) + max_y)\n",
    "        print(number, reverted_bin_edge_min)\n",
    "        print(reverted_bin_edge_max)\n",
    "        #np.max(indices_VIS[:, 0])\n",
    "        # y_coord_AUD = indices_AUDp[:, 0]\n",
    "        #keep =  (indices_AUDp[:, 0] < reverted_bin_edge_min) & (indices_AUDp[:, 0] > reverted_bin_edge_max)\n",
    "        sel = np.array([ind for ind in indices_AUDp\n",
    "                if ind[0] <= reverted_bin_edge_min and\n",
    "                   ind[0] >  reverted_bin_edge_max])\n",
    "        if sel.size == 0:\n",
    "            print(\"No voxels in that z-band!\")\n",
    "        else:\n",
    "            x_idx, y_idx, z_idx = sel.T\n",
    "            all_cortex[x_idx, y_idx, z_idx] = number\n",
    "        number= number+1\n",
    "for num, edge in enumerate(vc_bin_edges):\n",
    "    if num != len(ac_bin_edges)-1:\n",
    "        reverted_bin_edge_min = int(-(vc_bin_edges[num]/25) + max_y_vis)\n",
    "        reverted_bin_edge_max = int(-(vc_bin_edges[num+1]/25) + max_y_vis)\n",
    "        print(number, reverted_bin_edge_min)\n",
    "        print(reverted_bin_edge_max)\n",
    "        #np.max(indices_VIS[:, 0])\n",
    "        # y_coord_AUD = indices_AUDp[:, 0]\n",
    "        #keep =  (indices_AUDp[:, 0] < reverted_bin_edge_min) & (indices_AUDp[:, 0] > reverted_bin_edge_max)\n",
    "        sel = np.array([ind for ind in indices_VIS\n",
    "                if ind[0] <= reverted_bin_edge_min and\n",
    "                   ind[0] >  reverted_bin_edge_max])\n",
    "        if sel.size == 0:\n",
    "            print(\"No voxels in that z-band!\")\n",
    "        else:\n",
    "            x_idx, y_idx, z_idx = sel.T\n",
    "            all_cortex[x_idx, y_idx, z_idx] = number\n",
    "        number= number+1\n",
    "zproj = all_cortex.max(axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "fig_size = (3, 3)\n",
    "fig, ax = plt.subplots(figsize=fig_size)\n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "ax.set_facecolor('white')\n",
    "# colors = ['white', 'gray', 'steelblue', 'orchid']  # 0: white, 1: red, 2: blue, others: gray\n",
    "# cmap = ListedColormap(colors)\n",
    "# bounds = [0, 0.5, 1.5, 2.5, 255]  # 0-0.5 -> white, 0.5-1.5 -> red, 1.5-2.5 -> blue, others -> gray\n",
    "# norm = BoundaryNorm(bounds, cmap.N)\n",
    "# len_total=20\n",
    "# base = plt.cm.get_cmap(\"tab20\", len_total - 1)  \n",
    "# colors = [\"white\"] + list(base.colors)           \n",
    "len_total = 20\n",
    "base = plt.cm.get_cmap(\"tab20\", len_total - 2)\n",
    "colors = [\"white\", \"grey\"] + list(base.colors)\n",
    "cmap = ListedColormap(colors)\n",
    "# ax.imshow(zproj.T, origin='lower', cmap=cmap,  )\n",
    "ax.imshow(zproj.T, origin='lower', cmap=cmap, vmin=0, vmax=len_total - 1)\n",
    "font_size = font_size\n",
    "dx, dy = 2, 2\n",
    "for k, (x, y) in AC_coord_dict.items():\n",
    "    ax.scatter(x, y, s=8, color='black', zorder=3)\n",
    "    # ax.text(x + dx, y + dy, str(k), color='black', fontsize=font_size,\n",
    "    #         ha='left', va='center', zorder=4)\n",
    "\n",
    "for k, (x, y) in VC_coord_dict.items():\n",
    "    ax.scatter(x, y, s=8, color='black', marker='x', zorder=3)\n",
    "    # ax.text(x + dx, y + dy, str(k), color='black', fontsize=font_size,\n",
    "    #         ha='left', va='center', zorder=4)\n",
    "\n",
    "    ac_bin = VC_closest_soma_bin.get(k)\n",
    "    if ac_bin in AC_coord_dict:\n",
    "        x_ac, y_ac = AC_coord_dict[ac_bin]\n",
    "        ax.plot([x, x_ac], [y, y_ac], c='black', linestyle='--', lw=1, alpha=1, zorder=2)\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "fig.canvas.draw()\n",
    "\n",
    "w, h = fig.canvas.get_width_height()\n",
    "plt.close(fig)\n",
    "\n",
    "img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "img = img.reshape((h, w, 3))\n",
    "img_rot = np.rot90(img, k=-1)\n",
    "img_rf = np.fliplr(img_rot)\n",
    "\n",
    "plt.figure(figsize=fig_size)\n",
    "plt.imshow(img_rf)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(f\"{saving_path}/supplementary/fig_s4_AP_vs_dist.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for every AC bin and VC bin combination, what is the fraction of input from that AC bin and distance\n",
    "distances_df = pd.DataFrame(distance_dict)\n",
    "distances_df_indiv_mice = pd.concat([distances_df.assign(mouse=mouse) for mouse in mice], ignore_index=True) #duplicate for each mouse\n",
    "distances_df_indiv_mice['frac_input'] = np.nan\n",
    "distances_df_indiv_mice['total_neurons_in_bin']= np.nan\n",
    "distances_df_indiv_mice['oberved'] = np.nan\n",
    "distances_df_indiv_mice['expected']= np.nan\n",
    "for ac_bin in range (n_ac_bins):\n",
    "    comparison_results = {'mouse': [], 'vc_bin': [], 'ac_bin_0_match_ratio': []}\n",
    "    for vc_bin in range(n_vc_bins):\n",
    "        for mouse in mice:\n",
    "            parameters_path = f\"{proj_path}/{mouse}/Sequencing\"\n",
    "            barcodes = pd.read_pickle(f\"{parameters_path}/A1_barcodes_thresholded_with_source.pkl\")\n",
    "            soma = pd.DataFrame(barcodes.idxmax(axis=1)) #get the source cubelet\n",
    "            samples_in_bin = AP_soma_VC_sample[\n",
    "                (AP_soma_VC_sample['VC_bin_id'] == vc_bin) &\n",
    "                (AP_soma_VC_sample['Mouse'] == mouse)\n",
    "            ]['sample'].to_list()\n",
    "            valid_samples_in_bin = [s for s in samples_in_bin if s in barcodes.columns]\n",
    "            soma_indices = barcodes[barcodes[valid_samples_in_bin].sum(axis=1) > 0].index #neurons projecting to that vc bin\n",
    "            soma_filtered = soma.loc[soma_indices] #\n",
    "            total_somas = len(soma_filtered) #total neurons in vc bin\n",
    "            ac_bin_0_samples = soma_AP_pos_A1_only[\n",
    "                (soma_AP_pos_A1_only['AC_bin_id'] == ac_bin) &\n",
    "                (soma_AP_pos_A1_only['mouse'] == mouse)\n",
    "            ]['sample'].to_list()\n",
    "            total_in_ac_bin = len(soma[soma[0].isin(ac_bin_0_samples)])\n",
    "            ac_bin_0_matches = len(soma_filtered[soma_filtered[0].isin(ac_bin_0_samples)])\n",
    "            expected = (total_somas*total_in_ac_bin)/len(barcodes)\n",
    "            match_ratio = ac_bin_0_matches / total_somas if total_somas > 0 else 0\n",
    "            comparison_results['mouse'].append(mouse)\n",
    "            comparison_results['vc_bin'].append(vc_bin)\n",
    "            comparison_results['ac_bin_0_match_ratio'].append(match_ratio)\n",
    "            distances_df_indiv_mice.loc[(distances_df_indiv_mice['vc_bin'] == vc_bin) & (distances_df_indiv_mice['mouse'] == mouse) & (distances_df_indiv_mice['ac_bin'] == ac_bin), 'frac_input'] = match_ratio\n",
    "            distances_df_indiv_mice.loc[(distances_df_indiv_mice['vc_bin'] == vc_bin) & (distances_df_indiv_mice['mouse'] == mouse) & (distances_df_indiv_mice['ac_bin'] == ac_bin), 'total_neurons_in_bin'] = total_somas\n",
    "            distances_df_indiv_mice.loc[(distances_df_indiv_mice['vc_bin'] == vc_bin) & (distances_df_indiv_mice['mouse'] == mouse) & (distances_df_indiv_mice['ac_bin'] == ac_bin), ['frac_input', 'total_neurons_in_bin', 'oberved', 'expected']] = [match_ratio, total_somas, ac_bin_0_matches, expected]\n",
    "\n",
    "    results_df = pd.DataFrame(comparison_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# distances_df_indiv_mice['observed/expected'] = distances_df_indiv_mice['oberved']/distances_df_indiv_mice['expected']\n",
    "# min_to_add = distances_df_indiv_mice[distances_df_indiv_mice['observed/expected']>0]['observed/expected'].min()*0.01\n",
    "# distances_df_indiv_mice['log_observed/expected'] = np.log2(distances_df_indiv_mice['observed/expected']+min_to_add)\n",
    "# filtered_df = distances_df_indiv_mice[distances_df_indiv_mice['mouse'].isin(mice)]\n",
    "\n",
    "# # Group by 'ac_bin' and 'vc_bin' and calculate the mean of 'frac_input'\n",
    "# grouped = filtered_df.groupby(['ac_bin', 'vc_bin'])['log_observed/expected'].mean().reset_index()\n",
    "\n",
    "# # Pivot for easier plotting (optional, depending on how you want to visualize it)\n",
    "# pivot_table = grouped.pivot(index='ac_bin', columns='vc_bin', values='log_observed/expected')\n",
    "\n",
    "# # abs_max = np.abs(pivot_table.values).max()\n",
    "\n",
    "# # # Plot as a heatmap\n",
    "# plt.figure(figsize=(3, 3))\n",
    "# # plt.imshow(pivot_table, aspect='auto', interpolation='nearest', cmap='coolwarm', vmin=-abs_max, vmax=abs_max)\n",
    "# sb.heatmap(pivot_table, cmap='coolwarm', center=0, cbar_kws={'label': 'Log2(Observed/Expected)'})\n",
    "# plt.xlabel('VC Target A-P Bin')\n",
    "# plt.ylabel('A1 Soma A-P Bin')\n",
    "# plt.title('Mean Observed/Expected Inputs')\n",
    "# plt.xticks(ticks=range(len(pivot_table.columns)), labels=pivot_table.columns)\n",
    "# plt.yticks(ticks=range(len(pivot_table.index)), labels=pivot_table.index)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances_pivot_table = distances_df.pivot(index='ac_bin', columns='vc_bin', values='dist')\n",
    "# plt.figure(figsize=(3, 3))\n",
    "# # plt.imshow(pivot_table, aspect='auto', interpolation='nearest', cmap='coolwarm', vmin=-abs_max, vmax=abs_max)\n",
    "# sb.heatmap(distances_pivot_table, cmap='coolwarm', cbar_kws={'label': 'Distance (um)'})\n",
    "# plt.xlabel('VC Target A-P Bin')\n",
    "# plt.ylabel('A1 Soma A-P Bin')\n",
    "# plt.title('Euclidean Distances')\n",
    "# plt.xticks(ticks=range(len(pivot_table.columns)), labels=pivot_table.columns)\n",
    "# plt.yticks(ticks=range(len(pivot_table.index)), labels=pivot_table.index)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_df_indiv_mice['observed/expected'] = distances_df_indiv_mice['oberved'] / distances_df_indiv_mice['expected']\n",
    "min_to_add = distances_df_indiv_mice[distances_df_indiv_mice['observed/expected'] > 0]['observed/expected'].min() * 0.01\n",
    "distances_df_indiv_mice['log_observed/expected'] = np.log2(distances_df_indiv_mice['observed/expected'] + min_to_add)\n",
    "\n",
    "filtered_df = distances_df_indiv_mice[distances_df_indiv_mice['mouse'].isin(mice)]\n",
    "grouped_log = filtered_df.groupby(['ac_bin', 'vc_bin'])['log_observed/expected'].mean().reset_index()\n",
    "pivot_log = grouped_log.pivot(index='ac_bin', columns='vc_bin', values='log_observed/expected')\n",
    "distances_pivot_table = distances_df.pivot(index='ac_bin', columns='vc_bin', values='dist')\n",
    "fig, axes = plt.subplots(1, 2, figsize=(3, 1.2))\n",
    "\n",
    "\n",
    "sb.heatmap(pivot_log, cmap='coolwarm', center=0, ax=axes[0],\n",
    "           cbar_kws={'label': 'Log2(Observed/Expected)'})\n",
    "axes[0].set_title('Observed/Expected', weight='bold')\n",
    "axes[0].set_xlabel('VC Target A-P Bin')\n",
    "axes[0].set_ylabel('A1 Soma A-P Bin')\n",
    "\n",
    "sb.heatmap(distances_pivot_table, cmap='coolwarm', ax=axes[1],\n",
    "           cbar_kws={'label': 'Distance (m)'})\n",
    "axes[1].set_title('Euclidean Distances', weight='bold')\n",
    "axes[1].set_xlabel('VC Target A-P Bin')\n",
    "axes[1].set_ylabel('')\n",
    "axes[0].tick_params(axis='y', labelrotation=0)\n",
    "axes[1].tick_params(axis='y', labelrotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "log_values = pivot_log.values.flatten()\n",
    "dist_values = distances_pivot_table.values.flatten()\n",
    "\n",
    "mask = ~np.isnan(log_values) & ~np.isnan(dist_values)\n",
    "corr = np.corrcoef(log_values[mask], dist_values[mask])[0, 1]\n",
    "\n",
    "print(f\"Pearson correlation between log(observed/expected) and distances: {corr:.3f}\")\n",
    "fig.savefig(f\"{saving_path}/supplementary/fig_s4_AP_vs_dist_heatmaps.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# distances_df_indiv_mice['ap_offset'] = (\n",
    "#     distances_df_indiv_mice['ac_bin'] - distances_df_indiv_mice['vc_bin']\n",
    "# ).abs()\n",
    "\n",
    "# df1 = distances_df_indiv_mice[['ap_offset', 'observed/expected']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "# df2 = distances_df_indiv_mice[['dist', 'observed/expected']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# r1, p1 = pearsonr(df1['ap_offset'], df1['observed/expected'])\n",
    "# r2, p2 = pearsonr(df2['dist'], df2['observed/expected'])\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(3, 1.5), sharey=True)\n",
    "# sb.regplot(\n",
    "#     x='ap_offset',\n",
    "#     y='observed/expected',\n",
    "#     data=distances_df_indiv_mice,\n",
    "#     ax=axes[0],\n",
    "#     color='black',\n",
    "#     scatter=True,\n",
    "#     ci=95,\n",
    "#     scatter_kws={'s': 1},\n",
    "#     line_kws={'linewidth': 0.5}\n",
    "# )\n",
    "# axes[0].set_title(f'ap_offset vs log(O/E)\\nPearson r={r1:.2f}, p={p1:.2e}')\n",
    "\n",
    "# sb.regplot(\n",
    "#     x='dist',\n",
    "#     y='observed/expected',\n",
    "#     data=distances_df_indiv_mice,\n",
    "#     ax=axes[1],\n",
    "#     color='black',\n",
    "#     scatter=True,\n",
    "#     ci=95,\n",
    "#     scatter_kws={'s': 1},\n",
    "#     line_kws={'linewidth': 0.5}\n",
    "# )\n",
    "# axes[1].set_title(f'dist vs log(O/E)\\nPearson r={r2:.2f}, p={p2:.2e}')\n",
    "# ff.myPlotSettings_splitAxis(fig=fig, ax=axes[0], ytitle= 'Observed/Expected Inputs', xtitle='Offset of A-P Bins', title='', mySize =gen_parameters['font_size'])\n",
    "# ff.myPlotSettings_splitAxis(fig=fig, ax=axes[1], ytitle= 'Observed/Expected Inputs', xtitle='Distance (m)', title='', mySize =gen_parameters['font_size'])\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_df_indiv_mice['ap_offset'] = (\n",
    "    distances_df_indiv_mice['ac_bin'] - distances_df_indiv_mice['vc_bin']\n",
    ").abs()\n",
    "\n",
    "df1 = distances_df_indiv_mice[['ap_offset', 'observed/expected']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "df2 = distances_df_indiv_mice[['dist', 'observed/expected']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "r1, p1 = pearsonr(df1['ap_offset'], df1['observed/expected'])\n",
    "r2, p2 = pearsonr(df2['dist'], df2['observed/expected'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(3, 1.5), sharey=True)\n",
    "sb.regplot(\n",
    "    x='ap_offset',\n",
    "    y='observed/expected',\n",
    "    data=distances_df_indiv_mice,\n",
    "    ax=axes[0],\n",
    "    color='black',\n",
    "    scatter=True,\n",
    "    ci=95,\n",
    "    scatter_kws={'s': 1},\n",
    "    line_kws={'linewidth': 0.5}\n",
    ")\n",
    "axes[0].text(\n",
    "    0.95, 0.95,\n",
    "    f'r={r1:.2f}\\np={p1:.2e}',\n",
    "    ha='right', va='top',\n",
    "    transform=axes[0].transAxes,\n",
    "    fontsize=gen_parameters['font_size']\n",
    ")\n",
    "sb.regplot(\n",
    "    x='dist',\n",
    "    y='observed/expected',\n",
    "    data=distances_df_indiv_mice,\n",
    "    ax=axes[1],\n",
    "    color='black',\n",
    "    scatter=True,\n",
    "    ci=95,\n",
    "    scatter_kws={'s': 1},\n",
    "    line_kws={'linewidth': 0.5}\n",
    ")\n",
    "axes[1].text(\n",
    "    0.95, 0.95,\n",
    "    f'r={r2:.2f}\\np={p2:.2e}',\n",
    "    ha='right', va='top',\n",
    "    transform=axes[1].transAxes,\n",
    "    fontsize=gen_parameters['font_size']\n",
    ")\n",
    "axes[1].tick_params(labelleft=True)\n",
    "ff.myPlotSettings_splitAxis(fig=fig, ax=axes[0], ytitle='Observed/Expected Inputs', xtitle=f'Offset between Equivalent A-P Bins\\n (Soma and VC target)', title='A-P Bin Offset', mySize=gen_parameters['font_size'])\n",
    "ff.myPlotSettings_splitAxis(fig=fig, ax=axes[1], ytitle='Observed/Expected Inputs', xtitle='Distance (m)', title='Euclidean Distances', mySize=gen_parameters['font_size'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(f\"{saving_path}/supplementary/fig_s4_AP_vs_dist_regplots.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_df_indiv_mice =pd.DataFrame(distances_df_indiv_mice)\n",
    "distances_df_indiv_mice['ap_offset'] = (distances_df_indiv_mice['ac_bin'] - distances_df_indiv_mice['vc_bin']).abs()\n",
    "distances_df_indiv_mice[\"n_input\"]   = (distances_df_indiv_mice[\"frac_input\"] * distances_df_indiv_mice[\"total_neurons_in_bin\"]).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = distances_df_indiv_mice.copy()\n",
    "font_size = gen_parameters['font_size']\n",
    "df[\"n_input\"]   = (df[\"frac_input\"] * df[\"total_neurons_in_bin\"]).round().astype(int)\n",
    "df[\"n_failure\"] = df[\"total_neurons_in_bin\"] - df[\"n_input\"]\n",
    "df[\"mouse_ac_bin\"] = df[\"mouse\"].astype(str) + \"_bin\" + df[\"ac_bin\"].astype(str)\n",
    "dummies = pd.get_dummies(df[\"mouse_ac_bin\"], drop_first=True)\n",
    "#df[\"ap_center\"] = df[\"ap_offset\"]+0.5 # put the scatter pts in the center of each barplot \n",
    "endog = df[[\"n_input\", \"n_failure\"]]\n",
    "groups = df[\"mouse_ac_bin\"].unique()\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(groups)))\n",
    "\n",
    "X1    = pd.concat([sm.add_constant(df[\"ap_offset\"]), dummies], axis=1)\n",
    "res1  = sm.GLM(endog, X1, family=sm.families.Binomial()).fit()\n",
    "X2    = pd.concat([sm.add_constant(df[\"dist\"]), dummies], axis=1)\n",
    "res2  = sm.GLM(endog, X2, family=sm.families.Binomial()).fit()\n",
    "mean_dist = df[\"dist\"].mean()\n",
    "X3    = pd.concat([sm.add_constant(df[[\"ap_offset\", \"dist\"]]), dummies], axis=1)\n",
    "res3  = sm.GLM(endog, X3, family=sm.families.Binomial()).fit()\n",
    "print(res1.summary())\n",
    "print(res2.summary())\n",
    "print(res3.summary())\n",
    "\n",
    "groups = df[\"mouse_ac_bin\"].unique()\n",
    "colors = plt.cm.tab20(np.arange(len(groups)))\n",
    "\n",
    "n_bins_ap = n_ac_bins\n",
    "ap_bins = pd.cut(df[\"ap_offset\"], bins=n_bins_ap)\n",
    "mean_ap = (\n",
    "    df.assign(ap_bin=ap_bins)\n",
    "      .groupby(\"ap_bin\")[\"frac_input\"]\n",
    "      .mean()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "n_bins_dist = n_ac_bins\n",
    "dist_bins = pd.cut(df[\"dist\"], bins=n_bins_dist)\n",
    "mean_dist = (\n",
    "    df.assign(dist_bin=dist_bins)\n",
    "      .groupby(\"dist_bin\")[\"frac_input\"]\n",
    "      .mean()\n",
    "      .reset_index()\n",
    ")\n",
    "mean_dist[\"left\"]  = mean_dist[\"dist_bin\"].apply(lambda iv: iv.left)\n",
    "mean_dist[\"width\"] = mean_dist[\"dist_bin\"].apply(lambda iv: iv.right - iv.left)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(2.6, 3), sharey=True, dpi=120)\n",
    "fig.subplots_adjust(right=0.75)\n",
    "mean_ap = (\n",
    "    df.groupby(\"ap_offset\")[\"frac_input\"]\n",
    "      .mean()\n",
    "      .reset_index()\n",
    ")\n",
    "ax = axes[0]\n",
    "what_plot = ax.bar(mean_ap[\"ap_offset\"],\n",
    "       mean_ap[\"frac_input\"],\n",
    "       width=1,\n",
    "       align=\"center\",\n",
    "       color=\"black\",\n",
    "       alpha=1,\n",
    "       zorder=0)\n",
    "\n",
    "for col, lbl in zip(colors, groups):\n",
    "    sub = df[df[\"mouse_ac_bin\"] == lbl]\n",
    "    ax.scatter(sub[\"ap_offset\"], sub[\"frac_input\"],\n",
    "               color=col, edgecolor=\"black\", s=5, linewidths=0.3, alpha=1, zorder=1)\n",
    "ax.tick_params(axis='both', which='major', labelsize=font_size)\n",
    "# ax.set_xlabel(\"A-P Bin Distance\", fontsize=font_size)\n",
    "# ax.set_ylabel(\"Fraction Input\", fontsize=font_size)\n",
    "x_label = \"A-P Bin Distance\"\n",
    "y_label = \"Fraction Input\"\n",
    "ax.margins(x=0.05) \n",
    "coef_ap = res1.params[\"ap_offset\"]\n",
    "p_ap    = res1.pvalues[\"ap_offset\"]\n",
    "ax.text(1.03, 0.95,\n",
    "        f\"$\\\\beta_{{ap}} = {coef_ap:.2f}$\\n$p = {p_ap:.2e}$\",\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"left\", va=\"top\",\n",
    "        fontsize=font_size,)\n",
    "ff.myPlotSettings_splitAxis(fig=what_plot, ax=ax, ytitle= y_label, xtitle=x_label, title='', mySize =gen_parameters['font_size'])\n",
    "ax.set_xticks([0, 1, 2, 3])\n",
    "ax = axes[1]\n",
    "what_plot = ax.bar(mean_dist[\"left\"], mean_dist[\"frac_input\"], width=mean_dist[\"width\"],\n",
    "       align=\"edge\", color=\"black\", alpha=1, zorder=0)\n",
    "for col, lbl in zip(colors, groups):\n",
    "    sub = df[df[\"mouse_ac_bin\"] == lbl]\n",
    "    ax.scatter(sub[\"dist\"], sub[\"frac_input\"],\n",
    "               color=col, edgecolor=\"black\", s=5, linewidths=0.3, alpha=1, zorder=1)\n",
    "ax.margins(x=0.05) \n",
    "#ax.set_title(\"Effect of Distance\")\n",
    "x_label= \"Euclidean Distance (m)\"\n",
    "\n",
    "#ax.set_xlim(df[\"dist\"].min(), df[\"dist\"].max())\n",
    "coef_dist = res2.params[\"dist\"]\n",
    "p_dist    = res2.pvalues[\"dist\"]\n",
    "ax.text(1.03, 0.95,\n",
    "        f\"$\\\\beta_{{dist}} = {coef_dist:.2e}$\\n$p = {p_dist:.2e}$\",\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"left\", va=\"top\",\n",
    "        fontsize=font_size,)\n",
    "ax.tick_params(axis='both', which='major', labelsize=font_size)\n",
    "\n",
    "coef_ap_corrected = res3.params[\"ap_offset\"]\n",
    "p_ap_corrected    = res3.pvalues[\"ap_offset\"]\n",
    "ff.myPlotSettings_splitAxis(fig=what_plot, ax=ax, ytitle= y_label, xtitle=x_label, title='', mySize =gen_parameters['font_size'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.xlim(left=0)\n",
    "# plt.ylim(bottom=0)\n",
    "#plt.tight_layout()\n",
    "\n",
    "fig.savefig(f\"{saving_path}/supplementary/fig_4_AP_vs_VISAP_vs_euclidean.svg\", format=\"svg\")\n",
    "print(f\"$\\\\beta_{{ap_corr}} = {coef_ap_corrected}$\\n$p = {p_ap_corrected:.2e}$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_AP_dict = {}\n",
    "where_AP_vis = {}\n",
    "cols = ['VISl', 'VISli', 'VISpor', 'VISpl', 'VISp', 'VISal', 'VISam', 'VISa', 'VISpm', 'VISrl']\n",
    "for col in cols:\n",
    "    vals = []\n",
    "    for mouse in mice:\n",
    "        mouse_ind = which_mice[which_mice['mice']==mouse].index\n",
    "        mouse_bcs = combine_all_mice.loc[mouse_ind]\n",
    "        proj_area = mouse_bcs[mouse_bcs[col]>0]\n",
    "        indices = proj_area.index\n",
    "        if len(proj_area)>0:\n",
    "            AP_positions = AP_position_dict_list_combined.loc[indices]['AP_position']\n",
    "            vals.append(np.mean(AP_positions))\n",
    "    VIS_id =bg_atlas.structures[col]['id']\n",
    "    rsp = mcc.get_reference_space()\n",
    "    VIS_area_mask = rsp.make_structure_mask([VIS_id], direct_only=False)\n",
    "    VIS_area_mask = VIS_area_mask* contra_mask\n",
    "    centroid = np.argwhere(VIS_area_mask == 1).mean(axis=0)\n",
    "    where_AP_vis[col] = max_y_vis - centroid[0]\n",
    "    area_AP_dict[col] = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HVA_colors_updated = {\n",
    "#     'VISp': '#6E665E',\n",
    "#     'VISpor': '#79B855',\n",
    "#     'VISli': '#AAC255',\n",
    "#     'VISpl': '#4C9E57',\n",
    "#     'VISl': '#D6C759',\n",
    "#     'VISal': '#C7A859',\n",
    "#     'VISrl': '#F0BE7E',\n",
    "#     'VISa': '#D78257',\n",
    "#     'VISam': '#C2543C',\n",
    "#     'VISpm': '#D7716C'\n",
    "# }\n",
    "convert_dict = ff.get_convert_dict()\n",
    "font_size = gen_parameters['font_size']\n",
    "\n",
    "# Example: Suppose 'where_AP_vis' has the same keys as 'area_AP_dict'.\n",
    "# Each key in 'where_AP_vis' might be a single float or an iterable.\n",
    "# For demonstration, let's say each entry is a single float.\n",
    "# You could do np.mean(...) if each entry is a list/array.\n",
    "\n",
    "# 1) Sort keys based on value in 'where_AP_vis'\n",
    "# If 'where_AP_vis[key]' is a single float:\n",
    "keys_sorted = sorted(\n",
    "    area_AP_dict.keys(),\n",
    "    key=lambda k: where_AP_vis[k]  # or np.mean(where_AP_vis[k]) if it's a list\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1.2, 1.4))\n",
    "\n",
    "# 2) Plot in the new sorted order\n",
    "for i, key in enumerate(keys_sorted):\n",
    "    positions = area_AP_dict[key]\n",
    "    values = [val*25 for val in positions]\n",
    "    color = which_colour[key]#HVA_colors_updated.get(key, \"black\")\n",
    "    \n",
    "    # Scatter each point\n",
    "    xvals = np.full(len(values), i)  # same x position for the group's points\n",
    "    ax.scatter(\n",
    "        xvals, values,\n",
    "        marker='o',\n",
    "        facecolors='none',\n",
    "        edgecolors=color,\n",
    "        s=5,\n",
    "        label=key\n",
    "    )\n",
    "    \n",
    "    # Draw a horizontal line at the mean\n",
    "    mean_val = np.mean(values)\n",
    "    ax.hlines(\n",
    "        y=mean_val,\n",
    "        xmin=i - 0.2,\n",
    "        xmax=i + 0.2,\n",
    "        colors=color,\n",
    "        linewidth=2\n",
    "    )\n",
    "\n",
    "# 3) Convert x-tick labels to readable names in the same sorted order\n",
    "converted_labels = [convert_dict.get(k, k) for k in keys_sorted]\n",
    "ff.myPlotSettings_splitAxis(fig=fig, ax=ax, ytitle= '', xtitle='', title='', mySize =font_size)\n",
    "ax.set_xticks(range(len(keys_sorted)))\n",
    "ax.set_xticklabels(converted_labels, rotation=90, size=font_size)\n",
    "ax.set_ylabel(\"Mean Soma A-P Position\", size=font_size)\n",
    "ax.set_ylim(bottom=0)\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"{saving_path}/fig2_meanAP_pos_area.svg\", format=\"svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot individual areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "area_dic= {}\n",
    "for area in combine_all_mice.columns:\n",
    "    area_df =pd.DataFrame(columns=['mouse', 'AP_position', 'proj_freq'])\n",
    "    ap_positions = AP_position_dict_list_combined.loc[combine_all_mice.index]['AP_position']\n",
    "    #area_correlations.loc['corr_all_mice', area] = combine_all_mice[area].astype(bool).astype(int).corr(ap_positions, method='spearman')\n",
    "    for mouse in mice:\n",
    "        mouse_ind = which_mice[which_mice['mice']==mouse].index\n",
    "        ap_corr_mouse = AP_position_dict_list_combined.loc[mouse_ind]['AP_position']\n",
    "        mouse_bcs = combine_all_mice.loc[mouse_ind].astype(bool).astype(int)\n",
    "        for AP in ap_corr_mouse.unique():\n",
    "            indices = ap_corr_mouse[ap_corr_mouse==AP]\n",
    "            if len(indices)<5:\n",
    "                continue\n",
    "            else:\n",
    "                freq = mouse_bcs.loc[indices.index][area].mean()\n",
    "                new_row = pd.DataFrame({\"mouse\": [mouse], \"AP_position\": [AP*25], \"proj_freq\": [freq]})\n",
    "                area_df = pd.concat([area_df, new_row], ignore_index=True)\n",
    "        area_dic[area] = area_df\n",
    "\n",
    "logistic_reg_area_dict = {}\n",
    "visual_areas = ['VISli','VISpor', 'VISpl', 'VISl', 'VISp', 'VISal', 'VISam', 'VISpm', 'VISa', 'VISrl']\n",
    "for mouse in mice:\n",
    "    mouse_ind = which_mice[which_mice['mice']==mouse].index\n",
    "    ap_corr_mouse = AP_position_dict_list_combined.loc[mouse_ind]['AP_position']\n",
    "    mouse_bcs = combine_all_mice.loc[mouse_ind][visual_areas].astype(bool).astype(int).copy()\n",
    "    for AP in ap_corr_mouse.unique():\n",
    "        indices = ap_corr_mouse[ap_corr_mouse==AP]\n",
    "        if len(indices)<5:\n",
    "            continue\n",
    "        else:\n",
    "            logistic_reg_area_dict[AP] = mouse_bcs.loc[indices.index]\n",
    "            logistic_reg_area_dict[AP]['mouse'] = mouse\n",
    "            logistic_reg_area_dict[AP]['AP_position'] = AP*25\n",
    "\n",
    "combined_df = pd.concat(logistic_reg_area_dict.values(), axis=0, ignore_index=False)\n",
    "\n",
    "results_popuplation_dict = {}\n",
    "df = combined_df.melt(id_vars=['mouse', 'AP_position'], var_name='Area', value_name='Projection')\n",
    "pval_df = pd.DataFrame(index=visual_areas, columns=['p_value', 'OR'])\n",
    "for area in visual_areas:\n",
    "    df_area = df[df['Area'] == area]\n",
    "    model = smf.logit('Projection ~ AP_position + mouse', data=df_area).fit(disp=False)\n",
    "    results = model.summary2().tables[1]\n",
    "    results_popuplation_dict[area] = smf.logit('Projection ~ AP_position', data=df_area).fit(disp=False)\n",
    "    pval_df.loc[area, 'p_value'] = results.loc['AP_position', 'P>|z|']\n",
    "    pval_df.loc[area, 'OR'] = np.exp(results.loc['AP_position', 'Coef.'])\n",
    "\n",
    "pval_df['p_value_corrected'] = pval_df['p_value']*len(visual_areas)\n",
    "HVA_colors_updated = {\n",
    "    'VISp': '#6E665E',\n",
    "    'VISpor': '#79B855',\n",
    "    'VISli': '#AAC255',\n",
    "    'VISpl': '#4C9E57',\n",
    "    'VISl': '#D6C759',\n",
    "    'VISal': '#C7A859',\n",
    "    'VISrl': '#F0BE7E',\n",
    "    'VISa': '#D78257',\n",
    "    'VISam': '#C2543C',\n",
    "    'VISpm': '#D7716C'\n",
    "}\n",
    "convert_dict = {\n",
    "    \"VISl\": \"LM\",\n",
    "    \"VISrl\": \"RL\",\n",
    "    \"VISal\": \"AL\",\n",
    "    \"VISa\": \"A\",\n",
    "    \"VISp\": \"V1\",\n",
    "    \"VISpor\": \"POR\",\n",
    "    \"VISli\": \"LI\",\n",
    "    \"VISpl\": \"P\",\n",
    "    \"VISpm\": \"PM\",\n",
    "    \"VISam\": \"AM\"\n",
    "}\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mc\n",
    "import colorsys\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "def adjust_color(color, amount=1.0):\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    r, g, b = mc.to_rgb(c)\n",
    "    h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "    l = max(min(l * amount, 1.0), 0.0)\n",
    "    r, g, b = colorsys.hls_to_rgb(h, l, s)\n",
    "    return (r, g, b)\n",
    "\n",
    "HVA_colors_updated = ff.get_colour_dict(allen_nomenclature=True)\n",
    "areas_to_plot = ['VISam', 'VISrl', 'VISpor', 'VISpl']\n",
    "num_bins = 8\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(2.7, 1.6)) \n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (ax, area) in enumerate(zip(axes, areas_to_plot)):\n",
    "    model = results_popuplation_dict[area]\n",
    "    main_color = HVA_colors_updated.get(area, 'black')\n",
    "    fit_color = adjust_color(main_color, 0.7)\n",
    "    ci_color  = adjust_color(main_color, 1.3)\n",
    "\n",
    "    df_area = df[df['Area'] == area].copy()\n",
    "    ap_vals = df_area['AP_position'].values\n",
    "    proj_vals = df_area['Projection'].values\n",
    "    bin_edges = np.linspace(ap_vals.min(), ap_vals.max(), num_bins+1)\n",
    "    bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "    bin_proportions = []\n",
    "    for i in range(num_bins):\n",
    "        in_bin = (ap_vals >= bin_edges[i]) & (ap_vals < bin_edges[i+1])\n",
    "        if np.sum(in_bin) > 0:\n",
    "            bin_proportions.append(proj_vals[in_bin].mean())\n",
    "        else:\n",
    "            bin_proportions.append(np.nan)\n",
    "    \n",
    "    valid = ~np.isnan(bin_proportions)\n",
    "    ax.plot(bin_centers[valid],\n",
    "            np.array(bin_proportions)[valid],\n",
    "            'o',\n",
    "            label='Binned data',\n",
    "            color=main_color, markersize=2,\n",
    "            alpha=0.7)\n",
    "\n",
    "    ap_grid = np.linspace(ap_vals.min(), ap_vals.max(), 100)\n",
    "    new_data = pd.DataFrame({'AP_position': ap_grid})\n",
    "    \n",
    "    pred = model.get_prediction(new_data)\n",
    "    pred_df = pred.summary_frame(alpha=0.05)\n",
    "    yhat  = pred_df['predicted']\n",
    "    lower = pred_df['ci_lower']\n",
    "    upper = pred_df['ci_upper']\n",
    "    \n",
    "    ax.plot(ap_grid, yhat, '-', color=fit_color, linewidth=1)\n",
    "    ax.fill_between(ap_grid, lower, upper, color=ci_color, alpha=0.3)\n",
    "\n",
    "    ff.myPlotSettings_splitAxis(\n",
    "        fig=fig, ax=ax,\n",
    "        ytitle='Frequency',\n",
    "        xtitle=\"Soma A-P Position\",\n",
    "        title=\"\",\n",
    "        axisColor='k',\n",
    "        mySize=font_size\n",
    "    )\n",
    "    \n",
    "    \n",
    "    p_corrected = pval_df.loc[area, 'p_value_corrected']\n",
    "    print (f'p value for {area} is {p_corrected:.2g}')\n",
    "    if idx < 2:\n",
    "        ax.text(0.05, 1, f\"{convert_dict[area]}\",\n",
    "                transform=ax.transAxes,\n",
    "                ha='left', va='top',\n",
    "                fontsize=font_size, color='black')\n",
    "    else:\n",
    "        ax.text(0.95, 1, f\"{convert_dict[area]}\",\n",
    "                transform=ax.transAxes,\n",
    "                ha='right', va='top',\n",
    "                fontsize=5, color='black')\n",
    "\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax.set_xlim(left=0)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.set_xticks([0, 500, 1000, 1500])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(f\"{saving_path}/fig2_proj_prob_AP.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check medial-lateral position differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_atlas = BrainGlobeAtlas(\"allen_mouse_25um\", check_latest=False)\n",
    "AUDp_id =bg_atlas.structures['AUDp']['id']\n",
    "rsp = mcc.get_reference_space()\n",
    "AUDp_mask = rsp.make_structure_mask([AUDp_id], direct_only=False)\n",
    "indices_AUDp = np.argwhere(AUDp_mask == 1)\n",
    "VIS_mask = rsp.make_structure_mask([669], direct_only=False) #669 is id for whole visual cortex\n",
    "indices_VIS = np.argwhere(np.logical_and(VIS_mask, contra_mask))\n",
    "indices_AUDp_contra = np.argwhere(np.logical_and(AUDp_mask, contra_mask))\n",
    "min_x = indices_AUDp_contra[:, 2].min() \n",
    "max_x = indices_AUDp_contra[:, 2].max() \n",
    "max_x_vis = np.max(indices_VIS[:, 2])\n",
    "min_x_vis = np.min(indices_VIS[:, 2])\n",
    "#select anterior and posterior parts of A1\n",
    "#max_x = np.max(indices_AUDp[:, 2])\n",
    "#min_x = np.min(indices_AUDp[:, 2])\n",
    "# AP_midpoint_A1 = ((max_y - min_y) /2) + min_y\n",
    "# posterior_neurons = indices_AUDp[indices_AUDp[:, 0]>=AP_midpoint_A1]\n",
    "# anterior_neurons = indices_AUDp[indices_AUDp[:, 0]<AP_midpoint_A1]\n",
    "#now select only the ipsiliateral side of where was injected\n",
    "x_midpoint = AUDp_mask.shape[2] // 2\n",
    "contra_mask = np.zeros_like(AUDp_mask, dtype=bool)\n",
    "contra_mask[:, :, x_midpoint:] = 1\n",
    "#lets get the coordinates for the centre of A1\n",
    "A1_masked = contra_mask * AUDp_mask\n",
    "A1_centroid_coords = np.argwhere(A1_masked == 1).mean(axis=0)\n",
    "\n",
    "#now lets load the barcodes\n",
    "proj_path = pathlib.Path(gen_parameters['proj_path'])\n",
    "mice = gen_parameters['MICE']\n",
    "mouse_dict_ML_source = {}\n",
    "mouse_dict_ML_VC = {}\n",
    "mouse_barcodes_by_source = {}\n",
    "mouse_vis_main_dict = {}\n",
    "mouse_vis_coord = {}\n",
    "for mouse in mice:\n",
    "    #if mouse == 'FIAA45.6d':\n",
    "    ML_position_dict = {}\n",
    "    AP_position_vis_dict = {}\n",
    "    vis_main_dict = {}\n",
    "    barcodes = pd.read_pickle(f\"{proj_path}/{mouse}/Sequencing/A1_barcodes_thresholded_with_source.pkl\")\n",
    "    barcodes_no_soma = pd.read_pickle(f\"{proj_path}/{mouse}/Sequencing/A1_barcodes_thresholded.pkl\")\n",
    "    lcm_directory = proj_path/f\"{mouse}/LCM\"\n",
    "    ROI_3D = np.load(lcm_directory / \"ROI_3D_25.npy\")\n",
    "    all_VIS_ROI = np.unique(ROI_3D *  VIS_mask * contra_mask)\n",
    "    vis_coord = {}\n",
    "    #lets make sure we keep the same criteria of removing VIS rois where more than 10% is in AUDp\n",
    "    areas_only_grouped = fpf.get_area_volumes(\n",
    "        barcode_table_cols=barcodes_no_soma.columns,\n",
    "        lcm_directory=lcm_directory,\n",
    "        area_threshold=0.1,\n",
    "    )\n",
    "    visual_areas = ['VISli','VISpor', 'VISpl', 'VISl', 'VISp', 'VISal', 'VISam', 'VISpm', 'VISa', 'VISrl']\n",
    "    frac = areas_only_grouped.div(areas_only_grouped.sum(axis=1), axis=0)\n",
    "    frac_filtered = frac.loc[(frac[visual_areas].gt(0).any(axis=1)) & (frac['AUDp'] > 0.1)].index\n",
    "    all_VIS_ROI = [sample for sample in all_VIS_ROI if sample != 0 and sample in barcodes_no_soma.columns and sample not in frac_filtered and areas_only_grouped[visual_areas].loc[sample].sum()>0]\n",
    "\n",
    "    for sample in all_VIS_ROI:\n",
    "        centroid = np.argwhere(ROI_3D == sample).mean(axis=0)\n",
    "        vis_coord[sample] = centroid\n",
    "        AP_position_vis_dict[sample] = centroid[2] - min_x_vis #max_x_vis - centroid[2]  #centroid[0]-min_y_vis\n",
    "        vis_main_dict[sample] = areas_only_grouped[visual_areas].loc[sample].idxmax()\n",
    "    AP_samples = {}\n",
    "    AP_source_filtered = {}\n",
    "    all_AUDp_samples = np.unique(ROI_3D *  AUDp_mask * contra_mask)\n",
    "    all_AUDp_samples = [sample for sample in all_AUDp_samples if sample != 0]\n",
    "    all_AUDp_samples = [sample for sample in all_AUDp_samples if sample in barcodes.columns]\n",
    "    for sample in all_AUDp_samples:\n",
    "        centroid = np.argwhere(ROI_3D == sample).mean(axis=0)\n",
    "        ML_position_dict[sample] =  centroid[2] - min_x  #max_x -centroid[2]  #-min_y#AP_midpoint_A1\n",
    "    mouse_dict_ML_source[mouse]=ML_position_dict\n",
    "    mouse_dict_ML_VC[mouse] = AP_position_vis_dict\n",
    "    mouse_vis_main_dict[mouse] = vis_main_dict\n",
    "    mouse_vis_coord[mouse] = vis_coord\n",
    "\n",
    "def get_ML_position(row, dictionary):\n",
    "    key = row[0]\n",
    "    if key in dictionary.keys():\n",
    "        return dictionary[key]\n",
    "    else:\n",
    "        return None  # or any other default value you want to use if the key is not found\n",
    "#make a dataframe with mean AP_pos of sample, mouse and AP_soma\n",
    "ML_soma_VC_sample = pd.DataFrame(columns=['Mouse', 'mean_ML_soma', 'ML_Vis', 'VC_majority', 'dist_3d', 'sample'])\n",
    "ML_soma_VC_sample_all = pd.DataFrame(columns=['Mouse', 'actual_ML_soma', 'ML_Vis'])\n",
    "barcodes_dict = {}\n",
    "\n",
    "ML_position_dict_list = {}\n",
    "for mouse in mice:\n",
    "    new_dict = {}\n",
    "    parameters_path = (\n",
    "    f\"{proj_path}/{mouse}/Sequencing\")\n",
    "    barcodes = pd.read_pickle(f\"{parameters_path}/A1_barcodes_thresholded_with_source.pkl\")\n",
    "    barcodes= fpf.add_prefix_to_index(barcodes, mouse)\n",
    "    soma = pd.DataFrame(barcodes.idxmax(axis=1))\n",
    "    soma['ML_position'] = soma.apply(lambda row: get_ML_position(row, mouse_dict_ML_source[mouse]), axis=1)\n",
    "    #soma['uncorrected_AP']= soma.apply(lambda row: get_ML_position(row, mouse_dict_AP_source_uncorrected[mouse]), axis=1)\n",
    "    for sample in mouse_dict_ML_VC[mouse].keys():\n",
    "        indices_for_sample = barcodes[barcodes[sample]>0].index\n",
    "        if len(indices_for_sample)>2:\n",
    "            mean_ML= np.mean(soma.loc[indices_for_sample]['ML_position'])\n",
    "            uncorrected_meanML = mean_ML + min_x #back to non-normalised\n",
    "            A1_coord_updated = [A1_centroid_coords[0], A1_centroid_coords[1], uncorrected_meanML]\n",
    "            dist_3d = np.linalg.norm(np.array(A1_coord_updated) - np.array(mouse_vis_coord[mouse][sample])) * 25\n",
    "            new_row= pd.DataFrame({'Mouse':[mouse], 'mean_ML_soma':[(mean_ML)*25], 'ML_Vis':[mouse_dict_ML_VC[mouse][sample]*25], 'VC_majority': [mouse_vis_main_dict[mouse][sample]], 'dist_3d': [dist_3d], 'sample': [sample]})\n",
    "            bl = pd.DataFrame()\n",
    "            bl['ML_postion'] = soma.loc[indices_for_sample]['ML_position']\n",
    "            bl['Mouse'] = mouse\n",
    "            bl['actual_ML_soma'] = mouse_dict_ML_VC[mouse][sample]\n",
    "            ML_soma_VC_sample = pd.concat([ML_soma_VC_sample, new_row])\n",
    "            ML_soma_VC_sample_all = pd.concat([ML_soma_VC_sample_all, bl])\n",
    "    #barcodes_dict[mouse] = barcodes_assigned_area.drop(columns=['AUDp'])\n",
    "    #soma_filtered = soma.loc[combined_mice_dict[mouse]['homog_across_cubelet'].index]\n",
    "    ML_position_dict_list[mouse] = soma#soma_filtered\n",
    "    # mouse_euclidean_dist[mouse] = euclidean_dist\n",
    "# ML_position_dict_list_combined= pd.concat([ML_position_dict_list['FIAA45.6a'], ML_position_dict_list['FIAA45.6d'], ML_position_dict_list['FIAA55.4d']])\n",
    "\n",
    "ML_position_dict_list_combined = pd.concat([\n",
    "    ML_position_dict_list[k] for k in mice\n",
    "])\n",
    "ML_soma_VC_sample['converted'] = ML_soma_VC_sample['VC_majority'].map(convert_dict)\n",
    "rho, pval = pearsonr(ML_soma_VC_sample['ML_Vis'], ML_soma_VC_sample['mean_ML_soma'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_size = gen_parameters['font_size']\n",
    "fig, ax = plt.subplots(figsize=(3, 1.5)) \n",
    "sb.regplot(\n",
    "    x='ML_Vis',\n",
    "    y='mean_ML_soma',\n",
    "    data=ML_soma_VC_sample, color='black', scatter=False,\n",
    "    ci=95, scatter_kws={'s':5}, line_kws={'linewidth':1}\n",
    ")\n",
    "scatter = sb.scatterplot(\n",
    "    x='ML_Vis', \n",
    "    y='mean_ML_soma', \n",
    "    data=ML_soma_VC_sample, \n",
    "    hue='converted', \n",
    "    palette=which_colour_other,  \n",
    "    s=5, legend=True,      \n",
    ")\n",
    "\n",
    "handles, labels = scatter.get_legend_handles_labels()\n",
    "\n",
    "ax.legend(\n",
    "    handles=handles, frameon=False,\n",
    "    labels=labels, \n",
    "    title=\"Main VC area\", \n",
    "    bbox_to_anchor=(1.3, -0.2),  \n",
    "    loc='lower left', \n",
    "    borderaxespad=0, \n",
    "    fontsize=font_size, \n",
    "    handlelength=1,\n",
    "    handletextpad=0.4,\n",
    "    markerscale=0.2)\n",
    "leg = ax.get_legend()        # the auto legend\n",
    "leg.set_title(\"Main VC area\", prop={'size': font_size})\n",
    "for txt in leg.get_texts():\n",
    "    txt.set_fontsize(font_size)\n",
    "plt.text(\n",
    "    0.8, 0.2,\n",
    "    f\"R = {rho:.2f}\\np = {pval:.2e}\",\n",
    "    ha='left',\n",
    "    va='top',\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=font_size,\n",
    "    bbox=dict(boxstyle='round', facecolor='white', alpha=0.0)\n",
    ")\n",
    "xlabel = 'Visual Cortex M-L Position'\n",
    "ylabel = 'Mean Soma M-L Position'\n",
    "plt.text(1.15, -0.2, 'Lateral', ha='right', va='bottom', transform=plt.gca().transAxes, fontsize=font_size)\n",
    "plt.text(-0.1, 1.15, 'Lateral', ha='center', va='bottom', transform=plt.gca().transAxes, fontsize=font_size)\n",
    "plt.text(-0.1, -0.2, 'Medial', transform=plt.gca().transAxes, fontsize=font_size, va='bottom', ha='center')\n",
    "ff.myPlotSettings_splitAxis(fig=fig, ax=ax, ytitle= ylabel, xtitle=xlabel, title='', mySize =font_size)\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"{saving_path}/supplementary/fig_s4_ML_vs_VISML.svg\", format=\"svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HVA_colors_updated = {\n",
    "#     'VISp': '#6E665E',\n",
    "#     'VISpor': '#79B855',\n",
    "#     'VISli': '#AAC255',\n",
    "#     'VISpl': '#4C9E57',\n",
    "#     'VISl': '#D6C759',\n",
    "#     'VISal': '#C7A859',\n",
    "#     'VISrl': '#F0BE7E',\n",
    "#     'VISa': '#D78257',\n",
    "#     'VISam': '#C2543C',\n",
    "#     'VISpm': '#D7716C'\n",
    "# }\n",
    "# convert_dict = {\n",
    "#     \"VISl\": \"LM\",\n",
    "#     \"VISrl\": \"RL\",\n",
    "#     \"VISal\": \"AL\",\n",
    "#     \"VISa\": \"A\",\n",
    "#     \"VISp\": \"V1\",\n",
    "#     \"VISpor\": \"POR\",\n",
    "#     \"VISli\": \"LI\",\n",
    "#     \"VISpl\": \"P\",\n",
    "#     \"VISpm\": \"PM\",\n",
    "#     \"VISam\": \"AM\"\n",
    "# }\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(3, 3))\n",
    "\n",
    "# keys = list(area_AP_dict.keys())\n",
    "\n",
    "# for i, key in enumerate(keys):\n",
    "#     values = area_AP_dict[key]\n",
    "#     # Pull color from the dictionary; default to black if key not found\n",
    "#     color = HVA_colors_updated.get(key, \"black\")\n",
    "    \n",
    "#     # 1) Plot individual points as a scatter\n",
    "#     xvals = np.full(len(values), i)  # same x position for the group's points\n",
    "#     ax.scatter(xvals, values,marker='o',\n",
    "#     facecolors='none',    \n",
    "#     edgecolors=color, s=30, label=key, color=color)\n",
    "    \n",
    "#     # 2) Draw a horizontal line at the mean in the same color\n",
    "#     mean_val = np.mean(values)\n",
    "#     ax.hlines(y=mean_val, xmin=i - 0.2, xmax=i + 0.2, \n",
    "#               colors=color, linewidth=2)\n",
    "\n",
    "# converted_labels = [convert_dict.get(k, k) for k in keys]\n",
    "# ax.set_xticks(range(len(keys)))\n",
    "# ax.set_xticklabels(converted_labels, rotation=90, size=12)\n",
    "\n",
    "# ax.set_ylabel(\"Mean Normalised Soma A-P Position\", size=11)\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "area_dic= {}\n",
    "for area in combine_all_mice.columns:\n",
    "    area_df =pd.DataFrame(columns=['mouse', 'AP_position', 'proj_freq'])\n",
    "    ap_positions = AP_position_dict_list_combined.loc[combine_all_mice.index]['AP_position']\n",
    "    #area_correlations.loc['corr_all_mice', area] = combine_all_mice[area].astype(bool).astype(int).corr(ap_positions, method='spearman')\n",
    "    for mouse in mice:\n",
    "        mouse_ind = which_mice[which_mice['mice']==mouse].index\n",
    "        ap_corr_mouse = AP_position_dict_list_combined.loc[mouse_ind]['AP_position']\n",
    "        mouse_bcs = combine_all_mice.loc[mouse_ind].astype(bool).astype(int)\n",
    "        for AP in ap_corr_mouse.unique():\n",
    "            indices = ap_corr_mouse[ap_corr_mouse==AP]\n",
    "            if len(indices)<5:\n",
    "                continue\n",
    "            else:\n",
    "                freq = mouse_bcs.loc[indices.index][area].mean()\n",
    "                new_row = pd.DataFrame({\"mouse\": [mouse], \"AP_position\": [AP*25], \"proj_freq\": [freq]})\n",
    "                area_df = pd.concat([area_df, new_row], ignore_index=True)\n",
    "        area_dic[area] = area_df\n",
    "\n",
    "logistic_reg_area_dict = {}\n",
    "visual_areas = ['VISli','VISpor', 'VISpl', 'VISl', 'VISp', 'VISal', 'VISam', 'VISpm', 'VISa', 'VISrl']\n",
    "for mouse in mice:\n",
    "    mouse_ind = which_mice[which_mice['mice']==mouse].index\n",
    "    ap_corr_mouse = AP_position_dict_list_combined.loc[mouse_ind]['AP_position']\n",
    "    mouse_bcs = combine_all_mice.loc[mouse_ind][visual_areas].astype(bool).astype(int).copy()\n",
    "    for AP in ap_corr_mouse.unique():\n",
    "        indices = ap_corr_mouse[ap_corr_mouse==AP]\n",
    "        if len(indices)<5:\n",
    "            continue\n",
    "        else:\n",
    "            logistic_reg_area_dict[AP] = mouse_bcs.loc[indices.index]\n",
    "            logistic_reg_area_dict[AP]['mouse'] = mouse\n",
    "            logistic_reg_area_dict[AP]['AP_position'] = AP*25\n",
    "\n",
    "combined_df = pd.concat(logistic_reg_area_dict.values(), axis=0, ignore_index=False)\n",
    "\n",
    "results_popuplation_dict = {}\n",
    "df = combined_df.melt(id_vars=['mouse', 'AP_position'], var_name='Area', value_name='Projection')\n",
    "pval_df = pd.DataFrame(index=visual_areas, columns=['p_value', 'OR'])\n",
    "for area in visual_areas:\n",
    "    df_area = df[df['Area'] == area]\n",
    "    model = smf.logit('Projection ~ AP_position + mouse', data=df_area).fit(disp=False)\n",
    "    results = model.summary2().tables[1]\n",
    "    results_popuplation_dict[area] = smf.logit('Projection ~ AP_position', data=df_area).fit(disp=False)\n",
    "    pval_df.loc[area, 'p_value'] = results.loc['AP_position', 'P>|z|']\n",
    "    pval_df.loc[area, 'OR'] = np.exp(results.loc['AP_position', 'Coef.'])\n",
    "\n",
    "pval_df['p_value_corrected'] = pval_df['p_value']*len(visual_areas)\n",
    "HVA_colors_updated = {\n",
    "    'VISp': '#6E665E',\n",
    "    'VISpor': '#79B855',\n",
    "    'VISli': '#AAC255',\n",
    "    'VISpl': '#4C9E57',\n",
    "    'VISl': '#D6C759',\n",
    "    'VISal': '#C7A859',\n",
    "    'VISrl': '#F0BE7E',\n",
    "    'VISa': '#D78257',\n",
    "    'VISam': '#C2543C',\n",
    "    'VISpm': '#D7716C'\n",
    "}\n",
    "convert_dict = {\n",
    "    \"VISl\": \"LM\",\n",
    "    \"VISrl\": \"RL\",\n",
    "    \"VISal\": \"AL\",\n",
    "    \"VISa\": \"A\",\n",
    "    \"VISp\": \"V1\",\n",
    "    \"VISpor\": \"POR\",\n",
    "    \"VISli\": \"LI\",\n",
    "    \"VISpl\": \"P\",\n",
    "    \"VISpm\": \"PM\",\n",
    "    \"VISam\": \"AM\"\n",
    "}\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mc\n",
    "import colorsys\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "def adjust_color(color, amount=1.0):\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    r, g, b = mc.to_rgb(c)\n",
    "    h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "    l = max(min(l * amount, 1.0), 0.0)\n",
    "    r, g, b = colorsys.hls_to_rgb(h, l, s)\n",
    "    return (r, g, b)\n",
    "\n",
    "HVA_colors_updated = ff.get_colour_dict(allen_nomenclature=True)\n",
    "areas_to_plot = ['VISam', 'VISrl', 'VISpor', 'VISpl']\n",
    "num_bins = 8\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(2.2, 1.8)) \n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (ax, area) in enumerate(zip(axes, areas_to_plot)):\n",
    "    model = results_popuplation_dict[area]\n",
    "    main_color = HVA_colors_updated.get(area, 'black')\n",
    "    fit_color = adjust_color(main_color, 0.7)\n",
    "    ci_color  = adjust_color(main_color, 1.3)\n",
    "\n",
    "    df_area = df[df['Area'] == area].copy()\n",
    "    ap_vals = df_area['AP_position'].values\n",
    "    proj_vals = df_area['Projection'].values\n",
    "    bin_edges = np.linspace(ap_vals.min(), ap_vals.max(), num_bins+1)\n",
    "    bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "    bin_proportions = []\n",
    "    for i in range(num_bins):\n",
    "        in_bin = (ap_vals >= bin_edges[i]) & (ap_vals < bin_edges[i+1])\n",
    "        if np.sum(in_bin) > 0:\n",
    "            bin_proportions.append(proj_vals[in_bin].mean())\n",
    "        else:\n",
    "            bin_proportions.append(np.nan)\n",
    "    \n",
    "    valid = ~np.isnan(bin_proportions)\n",
    "    ax.plot(bin_centers[valid],\n",
    "            np.array(bin_proportions)[valid],\n",
    "            'o',\n",
    "            label='Binned data',\n",
    "            color=main_color, markersize=2,\n",
    "            alpha=0.7)\n",
    "\n",
    "    ap_grid = np.linspace(ap_vals.min(), ap_vals.max(), 100)\n",
    "    new_data = pd.DataFrame({'AP_position': ap_grid})\n",
    "    \n",
    "    pred = model.get_prediction(new_data)\n",
    "    pred_df = pred.summary_frame(alpha=0.05)\n",
    "    yhat  = pred_df['predicted']\n",
    "    lower = pred_df['ci_lower']\n",
    "    upper = pred_df['ci_upper']\n",
    "    \n",
    "    ax.plot(ap_grid, yhat, '-', color=fit_color, linewidth=1)\n",
    "    ax.fill_between(ap_grid, lower, upper, color=ci_color, alpha=0.3)\n",
    "\n",
    "    ff.myPlotSettings_splitAxis(\n",
    "        fig=fig, ax=ax,\n",
    "        ytitle=r\"$\\it{P}$ Projection\",\n",
    "        xtitle=\"Soma A-P Position\",\n",
    "        title=\"\",\n",
    "        axisColor='k',\n",
    "        mySize=6\n",
    "    )\n",
    "    \n",
    "    \n",
    "    p_corrected = pval_df.loc[area, 'p_value_corrected']\n",
    "    print (f'p value for {area} is {p_corrected:.2g}')\n",
    "    if idx < 2:\n",
    "        ax.text(0.05, 1, f\"{convert_dict[area]}\",\n",
    "                transform=ax.transAxes,\n",
    "                ha='left', va='top',\n",
    "                fontsize=5, color='black')\n",
    "    else:\n",
    "        ax.text(0.95, 1, f\"{convert_dict[area]}\",\n",
    "                transform=ax.transAxes,\n",
    "                ha='right', va='top',\n",
    "                fontsize=5, color='black')\n",
    "\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax.set_xlim(left=0)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.set_xticks([0, 500, 1000])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(f\"{saving_path}/fig2_proj_prob_AP.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_reg_area_dict = {}\n",
    "# visual_areas = ['VISli','VISpor', 'VISpl', 'VISl', 'VISp', 'VISal', 'VISam', 'VISpm', 'VISa', 'VISrl']\n",
    "# for mouse in mice:\n",
    "#     mouse_ind = which_mice[which_mice['mice']==mouse].index\n",
    "#     ap_corr_mouse = AP_position_dict_list_combined.loc[mouse_ind]['AP_position']\n",
    "#     mouse_bcs = combine_all_mice.loc[mouse_ind][visual_areas].astype(bool).astype(int).copy()\n",
    "#     for AP in ap_corr_mouse.unique():\n",
    "#         indices = ap_corr_mouse[ap_corr_mouse==AP]\n",
    "#         if len(indices)<5:\n",
    "#             continue\n",
    "#         else:\n",
    "#             logistic_reg_area_dict[AP] = mouse_bcs.loc[indices.index]\n",
    "#             logistic_reg_area_dict[AP]['mouse'] = mouse\n",
    "#             logistic_reg_area_dict[AP]['AP_position'] = AP*25\n",
    "\n",
    "# combined_df = pd.concat(logistic_reg_area_dict.values(), axis=0, ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_popuplation_dict = {}\n",
    "# df = combined_df.melt(id_vars=['mouse', 'AP_position'], var_name='Area', value_name='Projection')\n",
    "# pval_df = pd.DataFrame(index=visual_areas, columns=['p_value', 'OR'])\n",
    "# for area in visual_areas:\n",
    "#     df_area = df[df['Area'] == area]\n",
    "#     model = smf.logit('Projection ~ AP_position + mouse', data=df_area).fit(disp=False)\n",
    "#     results = model.summary2().tables[1]\n",
    "#     results_popuplation_dict[area] = smf.logit('Projection ~ AP_position', data=df_area).fit(disp=False)\n",
    "#     pval_df.loc[area, 'p_value'] = results.loc['AP_position', 'P>|z|']\n",
    "#     pval_df.loc[area, 'OR'] = np.exp(results.loc['AP_position', 'Coef.'])\n",
    "\n",
    "# pval_df['p_value_corrected'] = pval_df['p_value']*len(visual_areas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HVA_colors_updated = {\n",
    "#     'VISp': '#6E665E',\n",
    "#     'VISpor': '#79B855',\n",
    "#     'VISli': '#AAC255',\n",
    "#     'VISpl': '#4C9E57',\n",
    "#     'VISl': '#D6C759',\n",
    "#     'VISal': '#C7A859',\n",
    "#     'VISrl': '#F0BE7E',\n",
    "#     'VISa': '#D78257',\n",
    "#     'VISam': '#C2543C',\n",
    "#     'VISpm': '#D7716C'\n",
    "# }\n",
    "# convert_dict = {\n",
    "#     \"VISl\": \"LM\",\n",
    "#     \"VISrl\": \"RL\",\n",
    "#     \"VISal\": \"AL\",\n",
    "#     \"VISa\": \"A\",\n",
    "#     \"VISp\": \"V1\",\n",
    "#     \"VISpor\": \"POR\",\n",
    "#     \"VISli\": \"LI\",\n",
    "#     \"VISpl\": \"P\",\n",
    "#     \"VISpm\": \"PM\",\n",
    "#     \"VISam\": \"AM\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Suppose you've already run your logistic regressions and have:\n",
    "# # results_dict[area] = fitted model\n",
    "# # df is your long-form DataFrame with columns: ['mouse','AP_position','Area','Projection']\n",
    "\n",
    "# # Choose four areas to plot\n",
    "# areas_to_plot = ['VISam', 'VISrl', 'VISpor', 'VISpl']  # Example subset of 4 areas\n",
    "\n",
    "# # Number of bins for raw-data plotting\n",
    "# num_bins = 8\n",
    "\n",
    "# # Create a 22 figure\n",
    "# fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(1, 4))\n",
    "# axes = axes.flatten()  # Flatten to iterate easily over 4 axes\n",
    "\n",
    "# for ax, area in zip(axes, areas_to_plot):\n",
    "#     # Extract the logistic regression model for this area\n",
    "#     model = results_popuplation_dict[area]\n",
    "#     main_color = HVA_colors_updated.get(area, 'black')\n",
    "#     # Subset the data for this area\n",
    "#     df_area = df[df['Area'] == area].copy()\n",
    "\n",
    "#     # ------------------------------------------------------------\n",
    "#     # 1) Plot the raw data as binned proportions\n",
    "#     # ------------------------------------------------------------\n",
    "#     # We'll bin AP_position into intervals and compute the proportion of projecting neurons\n",
    "#     ap_vals = df_area['AP_position'].values\n",
    "#     proj_vals = df_area['Projection'].values\n",
    "\n",
    "#     # Define bin edges\n",
    "#     bin_edges = np.linspace(ap_vals.min(), ap_vals.max(), num_bins+1)\n",
    "#     bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "#     bin_proportions = []\n",
    "#     for i in range(num_bins):\n",
    "#         in_bin = (ap_vals >= bin_edges[i]) & (ap_vals < bin_edges[i+1])\n",
    "#         if np.sum(in_bin) > 0:\n",
    "#             bin_proportions.append(proj_vals[in_bin].mean())  # fraction projecting\n",
    "#         else:\n",
    "#             bin_proportions.append(np.nan)\n",
    "\n",
    "#     # Plot the binned proportions (exclude bins with no data)\n",
    "#     valid = ~np.isnan(bin_proportions)\n",
    "#     ax.plot(bin_centers[valid],\n",
    "#             np.array(bin_proportions)[valid],\n",
    "#             'o',\n",
    "#             label='Binned data (raw)', color=main_color,\n",
    "#             alpha=0.7)\n",
    "\n",
    "#     # ------------------------------------------------------------\n",
    "#     # 2) Plot the fitted logistic curve (+ confidence intervals)\n",
    "#     # ------------------------------------------------------------\n",
    "#     # Create a fine grid of AP positions\n",
    "#     ap_grid = np.linspace(ap_vals.min(), ap_vals.max(), 100)\n",
    "\n",
    "#     # Choose one mouse as reference for prediction (since \"mouse\" is in the model)\n",
    "#     reference_mouse = df_area['mouse'].unique()[0]\n",
    "#     new_data = pd.DataFrame({\n",
    "#         'AP_position': ap_grid,\n",
    "#         'mouse': reference_mouse  # or choose another\n",
    "#     })\n",
    "\n",
    "#     # Use model.get_prediction(...) to get predicted means + confidence intervals\n",
    "#     pred = model.get_prediction(new_data)\n",
    "#     # Convert to a DataFrame\n",
    "#     pred_df = pred.summary_frame(alpha=0.05)  # 95% CI => alpha=0.05\n",
    "\n",
    "#     # Depending on statsmodels version, columns may be named slightly differently:\n",
    "#     # Check if 'mean_ci_lower'/'mean_ci_upper' or 'obs_ci_lower'/'obs_ci_upper'\n",
    "#     yhat = pred_df['predicted']\n",
    "#     lower = pred_df['ci_lower']\n",
    "#     upper = pred_df['ci_upper']\n",
    "\n",
    "#     # Plot the fitted logistic curve\n",
    "#     ax.plot(ap_grid, yhat, '-', label='Logistic fit')\n",
    "\n",
    "#     # Fill the CI region\n",
    "#     ax.fill_between(ap_grid, lower, upper, alpha=0.3, label='95% CI')\n",
    "\n",
    "#     # ------------------------------------------------------------\n",
    "#     # 3) Aesthetics and labels\n",
    "#     # ------------------------------------------------------------\n",
    "#     ax.set_title(f\"Logistic Regression: {area}\")\n",
    "#     ax.set_xlabel(\"AP Position\")\n",
    "#     ax.set_ylabel(\"Probability of Projection\")\n",
    "#     #ax.set_ylim(-0.05, 1.05)  # just a little margin\n",
    "#     ax.legend()\n",
    "\n",
    "# # If fewer than 4 areas, any remaining axes wont be used; hide them.\n",
    "# if len(areas_to_plot) < 4:\n",
    "#     for unused_ax in axes[len(areas_to_plot):]:\n",
    "#         unused_ax.set_visible(False)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as mc\n",
    "# import colorsys\n",
    "# from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "# def adjust_color(color, amount=1.0):\n",
    "#     \"\"\"\n",
    "#     Adjust the brightness of a given color.\n",
    "#     amount < 1.0 => darker\n",
    "#     amount > 1.0 => lighter\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         c = mc.cnames[color]  # if color is a named color like 'red'\n",
    "#     except:\n",
    "#         c = color            # else assume it's a hex or RGB tuple\n",
    "#     r, g, b = mc.to_rgb(c)\n",
    "#     h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "#     # Scale the lightness\n",
    "#     l = max(min(l * amount, 1.0), 0.0)\n",
    "#     r, g, b = colorsys.hls_to_rgb(h, l, s)\n",
    "#     return (r, g, b)\n",
    "\n",
    "# HVA_colors_updated = ff.get_colour_dict(allen_nomenclature=True)\n",
    "# areas_to_plot = ['VISam', 'VISrl', 'VISpor', 'VISpl']\n",
    "# num_bins = 8\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(1.2, 3.3))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for ax, area in zip(axes, areas_to_plot):\n",
    "#     model = results_popuplation_dict[area]  # your fitted logistic model for this area\n",
    "#     main_color = HVA_colors_updated.get(area, 'black')\n",
    "#     fit_color = adjust_color(main_color, 0.7)  # darker line\n",
    "#     ci_color  = adjust_color(main_color, 1.3)  # lighter fill\n",
    "#     df_area = df[df['Area'] == area].copy()\n",
    "#     ap_vals = df_area['AP_position'].values\n",
    "#     proj_vals = df_area['Projection'].values\n",
    "#     bin_edges = np.linspace(ap_vals.min(), ap_vals.max(), num_bins+1)\n",
    "#     bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "#     bin_proportions = []\n",
    "#     for i in range(num_bins):\n",
    "#         in_bin = (ap_vals >= bin_edges[i]) & (ap_vals < bin_edges[i+1])\n",
    "#         if np.sum(in_bin) > 0:\n",
    "#             bin_proportions.append(proj_vals[in_bin].mean())\n",
    "#         else:\n",
    "#             bin_proportions.append(np.nan)\n",
    "    \n",
    "#     valid = ~np.isnan(bin_proportions)\n",
    "#     subplot = ax.plot(bin_centers[valid],\n",
    "#             np.array(bin_proportions)[valid],\n",
    "#             'o',\n",
    "#             label='Binned data',\n",
    "#             color=main_color, markersize=2,\n",
    "#             alpha=0.7)\n",
    "    \n",
    "#     # 2) Logistic curve + confidence interval\n",
    "#     ap_grid = np.linspace(ap_vals.min(), ap_vals.max(), 100)\n",
    "#     #reference_mouse = df_area['mouse'].unique()[0]\n",
    "#     new_data = pd.DataFrame({\n",
    "#         'AP_position': ap_grid\n",
    "#     })\n",
    "    \n",
    "#     pred = model.get_prediction(new_data)\n",
    "#     pred_df = pred.summary_frame(alpha=0.05)  # 95% CI\n",
    "#     yhat  = pred_df['predicted']\n",
    "#     lower = pred_df['ci_lower']\n",
    "#     upper = pred_df['ci_upper']\n",
    "    \n",
    "#     ax.plot(ap_grid, yhat, '-',\n",
    "#             label='Logistic fit',\n",
    "#             color=fit_color,\n",
    "#             linewidth=1)\n",
    "#     ax.fill_between(ap_grid, lower, upper,\n",
    "#                     color=ci_color,\n",
    "#                     alpha=0.3,\n",
    "#                     label='95% CI')\n",
    "#     ff.myPlotSettings_splitAxis(fig=subplot,ax=ax,ytitle= r\"$\\it{P}$ Projection\",xtitle=\"Soma A-P Position\",title=convert_dict[area],axisColor = 'k', mySize=5)\n",
    "#     p_corrected = pval_df.loc[area, 'p_value_corrected']\n",
    "#     ax.text(\n",
    "#         0.05, 1,  \n",
    "#         (f\"p={p_corrected:.2g}\"), \n",
    "#         transform=ax.transAxes,\n",
    "#         ha='left', va='top',\n",
    "#         fontsize=5, color='black'\n",
    "#     )\n",
    "#     ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "# plt.subplots_adjust(hspace=2)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# #fig.savefig(f\"{saving_path}/fig2_proj_prob_AP.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mc\n",
    "import colorsys\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "def adjust_color(color, amount=1.0):\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    r, g, b = mc.to_rgb(c)\n",
    "    h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "    l = max(min(l * amount, 1.0), 0.0)\n",
    "    r, g, b = colorsys.hls_to_rgb(h, l, s)\n",
    "    return (r, g, b)\n",
    "\n",
    "HVA_colors_updated = ff.get_colour_dict(allen_nomenclature=True)\n",
    "areas_to_plot = ['VISam', 'VISrl', 'VISpor', 'VISpl']\n",
    "num_bins = 8\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(2.2, 1.8)) \n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (ax, area) in enumerate(zip(axes, areas_to_plot)):\n",
    "    model = results_popuplation_dict[area]\n",
    "    main_color = HVA_colors_updated.get(area, 'black')\n",
    "    fit_color = adjust_color(main_color, 0.7)\n",
    "    ci_color  = adjust_color(main_color, 1.3)\n",
    "\n",
    "    df_area = df[df['Area'] == area].copy()\n",
    "    ap_vals = df_area['AP_position'].values\n",
    "    proj_vals = df_area['Projection'].values\n",
    "    bin_edges = np.linspace(ap_vals.min(), ap_vals.max(), num_bins+1)\n",
    "    bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "    bin_proportions = []\n",
    "    for i in range(num_bins):\n",
    "        in_bin = (ap_vals >= bin_edges[i]) & (ap_vals < bin_edges[i+1])\n",
    "        if np.sum(in_bin) > 0:\n",
    "            bin_proportions.append(proj_vals[in_bin].mean())\n",
    "        else:\n",
    "            bin_proportions.append(np.nan)\n",
    "    \n",
    "    valid = ~np.isnan(bin_proportions)\n",
    "    ax.plot(bin_centers[valid],\n",
    "            np.array(bin_proportions)[valid],\n",
    "            'o',\n",
    "            label='Binned data',\n",
    "            color=main_color, markersize=2,\n",
    "            alpha=0.7)\n",
    "\n",
    "    ap_grid = np.linspace(ap_vals.min(), ap_vals.max(), 100)\n",
    "    new_data = pd.DataFrame({'AP_position': ap_grid})\n",
    "    \n",
    "    pred = model.get_prediction(new_data)\n",
    "    pred_df = pred.summary_frame(alpha=0.05)\n",
    "    yhat  = pred_df['predicted']\n",
    "    lower = pred_df['ci_lower']\n",
    "    upper = pred_df['ci_upper']\n",
    "    \n",
    "    ax.plot(ap_grid, yhat, '-', color=fit_color, linewidth=1)\n",
    "    ax.fill_between(ap_grid, lower, upper, color=ci_color, alpha=0.3)\n",
    "\n",
    "    ff.myPlotSettings_splitAxis(\n",
    "        fig=fig, ax=ax,\n",
    "        ytitle=r\"$\\it{P}$ Projection\",\n",
    "        xtitle=\"Soma A-P Position\",\n",
    "        title=\"\",\n",
    "        axisColor='k',\n",
    "        mySize=6\n",
    "    )\n",
    "    \n",
    "    \n",
    "    p_corrected = pval_df.loc[area, 'p_value_corrected']\n",
    "    print (f'p value for {area} is {p_corrected:.2g}')\n",
    "    if idx < 2:\n",
    "        ax.text(0.05, 1, f\"{convert_dict[area]}\",\n",
    "                transform=ax.transAxes,\n",
    "                ha='left', va='top',\n",
    "                fontsize=5, color='black')\n",
    "    else:\n",
    "        ax.text(0.95, 1, f\"{convert_dict[area]}\",\n",
    "                transform=ax.transAxes,\n",
    "                ha='right', va='top',\n",
    "                fontsize=5, color='black')\n",
    "\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax.set_xlim(left=0)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.set_xticks([0, 500, 1000])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(f\"{saving_path}/fig2_proj_prob_AP.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "# results_popuplation_dict = {}\n",
    "# df = combined_df.melt(id_vars=['mouse', 'AP_position'], var_name='Area', value_name='Projection')\n",
    "# pval_df = pd.DataFrame(index=visual_areas, columns=['p_value', 'OR'])\n",
    "# for area in visual_areas:\n",
    "#     df_area = df[df['Area'] == area]\n",
    "#     model = smf.logit('Projection ~ AP_position', data=df_area).fit(disp=False)\n",
    "#     results = model.summary2().tables[1]\n",
    "#     results_popuplation_dict[area] = smf.logit('Projection ~ AP_position', data=df_area).fit(disp=False)\n",
    "\n",
    "# pval_df['p_value_corrected'] = pval_df['p_value']*len(visual_areas)\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(1.2, 3.3))\n",
    "# axes = axes.flatten()\n",
    "# num_bins = 8\n",
    "# areas_to_plot = ['VISam', 'VISrl', 'VISpor', 'VISpl']\n",
    "\n",
    "# for ax, area in zip(axes, areas_to_plot):\n",
    "#     model = results_popuplation_dict[area]\n",
    "#     main_color = HVA_colors_updated.get(area, 'black')\n",
    "#     fit_color = adjust_color(main_color, 0.7)\n",
    "#     ci_color  = adjust_color(main_color, 1.3)\n",
    "#     df_area = df[df['Area'] == area].copy()\n",
    "#     ap_vals = df_area['AP_position'].values\n",
    "#     proj_vals = df_area['Projection'].values\n",
    "    \n",
    "#     # 1) Plot binned data points (population level)\n",
    "#     bin_edges = np.linspace(ap_vals.min(), ap_vals.max(), num_bins+1)\n",
    "#     bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "#     bin_proportions = []\n",
    "    \n",
    "#     for i in range(num_bins):\n",
    "#         in_bin = (ap_vals >= bin_edges[i]) & (ap_vals < bin_edges[i+1])\n",
    "#         if np.sum(in_bin) > 0:\n",
    "#             bin_proportions.append(proj_vals[in_bin].mean()) #for each bin, get the projection frequency\n",
    "#         else:\n",
    "#             bin_proportions.append(np.nan)\n",
    "    \n",
    "#     valid = ~np.isnan(bin_proportions)\n",
    "#     ax.plot(\n",
    "#         bin_centers[valid],\n",
    "#         np.array(bin_proportions)[valid],\n",
    "#         'o',\n",
    "#         label='Binned data',\n",
    "#         color=main_color,\n",
    "#         markersize=2,\n",
    "#         alpha=0.8\n",
    "#     )\n",
    "    \n",
    "#     # 2) Plot logistic regression fit (full model)\n",
    "#     ap_grid = np.linspace(ap_vals.min(), ap_vals.max(), 200)\n",
    "#     new_data = pd.DataFrame({'AP_position': ap_grid})\n",
    "    \n",
    "#     pred = model.get_prediction(new_data)\n",
    "#     pred_df = pred.summary_frame(alpha=0.05)\n",
    "    \n",
    "#     yhat = pred_df['predicted']\n",
    "#     lower = pred_df['ci_lower']\n",
    "#     upper = pred_df['ci_upper']\n",
    "    \n",
    "#     ax.plot(ap_grid, yhat, '-', color=fit_color, linewidth=1)\n",
    "#     ax.fill_between(ap_grid, lower, upper, color=ci_color, alpha=0.3)\n",
    "    \n",
    "#     # 3) Styling\n",
    "#     ff.myPlotSettings_splitAxis(\n",
    "#         fig=fig,\n",
    "#         ax=ax,\n",
    "#         ytitle=r\"$\\it{P}$ Projection\",\n",
    "#         xtitle=\"Soma A-P Position\",\n",
    "#         title=convert_dict[area],\n",
    "#         axisColor='k',\n",
    "#         mySize=5\n",
    "#     )\n",
    "    \n",
    "#     p_corrected = pval_df.loc[area, 'p_value_corrected']\n",
    "#     ax.text(\n",
    "#         0.05, 1,\n",
    "#         f\"p={p_corrected:.2g}\",\n",
    "#         transform=ax.transAxes,\n",
    "#         ha='left', va='top',\n",
    "#         fontsize=5,\n",
    "#         color='black'\n",
    "#     )\n",
    "#     ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "# plt.subplots_adjust(hspace=2)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# areas_to_plot = ['VISam', 'VISrl', 'VISpor', 'VISpl']\n",
    "# num_bins = 8\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(1.2, 3.3))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for ax, area in zip(axes, areas_to_plot):\n",
    "#     model = results_popuplation_dict[area]  # your fitted logistic model\n",
    "#     main_color = HVA_colors_updated.get(area, 'black')\n",
    "#     fit_color = adjust_color(main_color, 0.7)  # darker line\n",
    "#     ci_color  = adjust_color(main_color, 1.3)  # lighter fill\n",
    "\n",
    "#     # -------------------------------------------------------\n",
    "#     # 1) Population-level binned data (ALL mice combined)\n",
    "#     # -------------------------------------------------------\n",
    "#     df_area = df[df['Area'] == area].copy()\n",
    "#     ap_vals = df_area['AP_position'].values\n",
    "#     proj_vals = df_area['Projection'].values\n",
    "    \n",
    "#     bin_edges = np.linspace(ap_vals.min(), ap_vals.max(), num_bins+1)\n",
    "#     bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "#     bin_proportions = []\n",
    "#     for i in range(num_bins):\n",
    "#         in_bin = (ap_vals >= bin_edges[i]) & (ap_vals < bin_edges[i+1])\n",
    "#         if np.sum(in_bin) > 0:\n",
    "#             bin_proportions.append(proj_vals[in_bin].mean())\n",
    "#         else:\n",
    "#             bin_proportions.append(np.nan)\n",
    "#     valid = ~np.isnan(bin_proportions)\n",
    "#     ax.plot(\n",
    "#         bin_centers[valid],\n",
    "#         np.array(bin_proportions)[valid],\n",
    "#         'o',\n",
    "#         label='Binned data (population)',\n",
    "#         color=main_color,\n",
    "#         markersize=2,\n",
    "#         alpha=0.8\n",
    "#     )\n",
    "    \n",
    "#     # -------------------------------------------------------\n",
    "#     # 2) Plot each mouse's fitted logistic curve\n",
    "#     #    using the mouse's REAL AP_position values\n",
    "#     # -------------------------------------------------------\n",
    "#     all_mice = df_area['mouse'].unique()\n",
    "#     for m in all_mice:\n",
    "#         df_m = df_area[df_area['mouse'] == m].copy()\n",
    "#         if df_m.empty:\n",
    "#             continue  # just in case\n",
    "\n",
    "#         # Sort by AP_position to get a left-to-right line\n",
    "#         df_m.sort_values('AP_position', inplace=True)\n",
    "\n",
    "#         # Use get_prediction on the real AP positions\n",
    "#         pred = model.get_prediction(df_m)\n",
    "#         pred_df = pred.summary_frame(alpha=0.05)  # 95% CI\n",
    "\n",
    "#         # The predicted probabilities and CI for each row\n",
    "#         yhat  = pred_df['predicted']\n",
    "#         lower = pred_df['ci_lower']\n",
    "#         upper = pred_df['ci_upper']\n",
    "        \n",
    "#         # Plot a line for this mouse\n",
    "#         ax.plot(\n",
    "#             df_m['AP_position'],\n",
    "#             yhat,\n",
    "#             '-',\n",
    "#             linewidth=1,\n",
    "#             color=fit_color,\n",
    "#             alpha=0.9\n",
    "#         )\n",
    "#         # Fill confidence interval\n",
    "#         ax.fill_between(\n",
    "#             df_m['AP_position'],\n",
    "#             lower, upper,\n",
    "#             color=ci_color,\n",
    "#             alpha=0.1\n",
    "#         )\n",
    "    \n",
    "#     # -------------------------------------------------------\n",
    "#     # 3) Styling\n",
    "#     # -------------------------------------------------------\n",
    "#     # Example: using your custom function for axis formatting\n",
    "#     ff.myPlotSettings_splitAxis(\n",
    "#         fig=fig,  # or pass subplot if needed\n",
    "#         ax=ax,\n",
    "#         ytitle=r\"$\\it{P}$ Projection\",\n",
    "#         xtitle=\"Soma A-P Position\",\n",
    "#         title=convert_dict[area],\n",
    "#         axisColor='k',\n",
    "#         mySize=5\n",
    "#     )\n",
    "    \n",
    "#     # Show a p-value if you have one\n",
    "#     p_corrected = pval_df.loc[area, 'p_value_corrected']\n",
    "#     ax.text(\n",
    "#         0.05, 1,\n",
    "#         f\"p={p_corrected:.2g}\",\n",
    "#         transform=ax.transAxes,\n",
    "#         ha='left', va='top',\n",
    "#         fontsize=5, color='black'\n",
    "#     )\n",
    "\n",
    "# plt.subplots_adjust(hspace=2)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'AP_position': ap_grid\n",
    "})\n",
    "\n",
    "pred = model.get_prediction(new_data, transform=True)  # depends on your library\n",
    "pred_df = pred.summary_frame(alpha=0.05)\n",
    "\n",
    "# Plot one line & fill\n",
    "plt.plot(ap_grid, pred_df['predicted'], '-', color=fit_color)\n",
    "plt.fill_between(ap_grid, pred_df['ci_lower'], pred_df['ci_upper'], \n",
    "                color=ci_color, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for fig S4, lets compare conditional probability given targeting AP position in vis cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MouseConnectivityCache(resolution=25)\n",
    "rsp = mcc.get_reference_space()\n",
    "VIS_mask = rsp.make_structure_mask([669], direct_only=False) #669 is id for whole visual cortex\n",
    "indices_VIS = np.argwhere(VIS_mask == 1)\n",
    "\n",
    "#select anterior and posterior parts of A1\n",
    "max_y = np.max(indices_VIS[:, 0])\n",
    "min_y = np.min(indices_VIS[:, 0])\n",
    "AP_midpoint_VIS = ((max_y - min_y) /2) + min_y\n",
    "# posterior_neurons = indices_AUDp[indices_AUDp[:, 0]>=AP_midpoint_A1]\n",
    "# anterior_neurons = indices_AUDp[indices_AUDp[:, 0]<AP_midpoint_A1]\n",
    "#now select only the ipsiliateral side of where was injected\n",
    "x_midpoint = VIS_mask.shape[2] // 2\n",
    "contra_mask = np.zeros_like(VIS_mask, dtype=bool)\n",
    "contra_mask[:, :, x_midpoint:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take AP position of cubelets containing visual cortex (and also specifically V1)\n",
    "proj_path = pathlib.Path(\"/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq\")\n",
    "HVA_cols = ['VISp', 'VISpor', 'VISli', 'VISal', 'VISl', 'VISpl', 'VISpm', 'VISrl', 'VISam', 'VISa']\n",
    "mice = ['FIAA45.6a', 'FIAA45.6d', 'FIAA55.4d']\n",
    "AP_position_dict = {}\n",
    "AP_cond_prob_dict = {}\n",
    "for mouse in mice:\n",
    "    new_dict = {}\n",
    "    cond_prob_dict = {}\n",
    "    parameters_path = (\n",
    "    f\"/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/{mouse}/Sequencing\")\n",
    "    parameters = fpf.load_parameters(directory=parameters_path)\n",
    "    barcodes = pd.read_pickle(f\"{parameters_path}/A1_barcodes_thresholded.pkl\")\n",
    "    #sample_vol_and_regions =pd.read_pickle(pathlib.Path(parameters['lcm_directory'])/'sample_vol_and_regions.pkl')\n",
    "    areas_only_grouped = fpf.get_area_volumes(\n",
    "        barcode_table_cols=barcodes.columns,\n",
    "        lcm_directory=pathlib.Path(parameters['lcm_directory']),\n",
    "        area_threshold=0.5) #must contain at least 50% visual cortex\n",
    "    V1_containing = areas_only_grouped[areas_only_grouped['VISp']>0].index.to_list()\n",
    "    lcm_directory = pathlib.Path(parameters['lcm_directory'])\n",
    "    ROI_3D = np.load(lcm_directory / \"ROI_3D_25.npy\")\n",
    "    for sample in V1_containing:\n",
    "        if sample in barcodes.columns:\n",
    "            centroid = np.argwhere(ROI_3D == sample).mean(axis=0)\n",
    "            filtered_bc = barcodes[barcodes[sample]>0]\n",
    "            if len(filtered_bc)<5:\n",
    "                continue\n",
    "            new_dict[sample] = centroid[0]-min_y\n",
    "            filtered_bc.drop(columns=[sample], inplace=True)\n",
    "            filtered_with_area = fpf.homog_across_cubelet(parameters_path= parameters_path, barcode_matrix = filtered_bc, cortical=True, shuffled=False, IT_only=True)\n",
    "            cond_prob_dict[sample] = filtered_with_area.astype(bool).mean(axis=0)\n",
    "    AP_position_dict[mouse] = new_dict\n",
    "    AP_cond_prob_dict[mouse] = cond_prob_dict\n",
    "#for each mouse, given that a cubelet is in a particular AP position, what are the probablity of targeting other areas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_areas = ['VISa', 'VISal', 'VISam', 'VISpm', 'VISp', 'VISpor', 'VISrl', 'VISl', 'VISli', 'VISpl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_dic= {}\n",
    "for area in visual_areas:\n",
    "    area_df =pd.DataFrame(columns=['mouse', 'AP_position', 'conditional_prob'])\n",
    "    # ap_positions = AP_position_dict_list_combined.loc[combine_all_mice.index]['AP_position']\n",
    "    #area_correlations.loc['corr_all_mice', area] = combine_all_mice[area].astype(bool).astype(int).corr(ap_positions, method='spearman')\n",
    "    for mouse in mice:\n",
    "        for sample in AP_position_dict[mouse].keys():\n",
    "            AP_pos = AP_position_dict[mouse][sample]\n",
    "            cond_prob = AP_cond_prob_dict[mouse][sample][area]\n",
    "            new_row = pd.DataFrame({\"mouse\": [mouse], \"AP_position\": [AP_pos], \"conditional_prob\": [cond_prob]})\n",
    "            area_df = pd.concat([area_df, new_row], ignore_index=True)\n",
    "    area_dic[area] = area_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "area_p_values = pd.DataFrame(columns=['p_value', 'p_val_adj'])\n",
    "area_results = {}\n",
    "for area in visual_areas:\n",
    "    df_long = area_dic[area]\n",
    "    model = smf.mixedlm(\n",
    "        formula=\"conditional_prob ~ AP_position\",\n",
    "        data=df_long,\n",
    "        groups=df_long[\"mouse\"],  # random intercept only\n",
    "        re_formula=\"1\"            # or omit if you want the default random intercept\n",
    "    )\n",
    "\n",
    "    res = model.fit()\n",
    "    area_results[area]=res\n",
    "\n",
    "    # Extract the p-value for the slope of AP_position\n",
    "    p_value_ap = res.pvalues[\"AP_position\"]\n",
    "    area_p_values.loc[area, 'p_value'] = p_value_ap\n",
    "    area_p_values.loc[area, 'p_val_adj'] = p_value_ap*len(visual_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.colors as mcolors\n",
    "convert_dict = {\n",
    "    \"VISrl\": \"RL\",\n",
    "    \"VISal\": \"AL\",\n",
    "    \"VISa\": \"A\",\n",
    "    \"VISp\": \"V1\",\n",
    "    \"VISpor\": \"POR\",\n",
    "    \"VISli\": \"LI\",\n",
    "    \"VISpl\": \"P\",\n",
    "    \"VISpm\": \"PM\",\n",
    "    \"VISrl\": \"RL\",\n",
    "    \"VISam\": \"AM\",\n",
    "    \"VISl\": \"LM\"\n",
    "}\n",
    "HVA_colors_updated = {\n",
    "    'VISp': '#6E665E', 'VISpor': '#79B855', 'VISli': '#AAC255', 'VISpl': '#4C9E57', \n",
    "    'VISl': '#D6C759', 'VISal': '#C7A859', 'VISrl': '#F0BE7E', 'VISa': '#D78257', \n",
    "    'VISam': '#C2543C', 'VISpm': '#D7716C'\n",
    "}\n",
    "\n",
    "areas = ['VISa', 'VISpor', 'VISl', 'VISrl']\n",
    "HVA_only = [s for s in visual_areas if s != 'VISp']\n",
    "fig, axes = plt.subplots(3, 3, figsize=(7, 5), sharex=False, sharey=False)\n",
    "\n",
    "for i, area in enumerate(HVA_only):\n",
    "    row, col = divmod(i, 3)\n",
    "    ax = axes[row, col]\n",
    "    df_long = area_dic[area]\n",
    "\n",
    "    main_color = HVA_colors_updated.get(area, 'black')\n",
    "\n",
    "    ap_range = np.linspace(df_long[\"AP_position\"].min(), df_long[\"AP_position\"].max(), 50)\n",
    "    \n",
    "    pred_df = pd.DataFrame({\n",
    "        \"mouse\": [\"AverageMouse\"] * len(ap_range),\n",
    "        \"AP_position\": ap_range\n",
    "    })\n",
    "    \n",
    "    pred_df[\"conditional_prob_pred\"] = area_results[area].predict(pred_df)\n",
    "\n",
    "    ap_position_se = area_results[area].bse[\"AP_position\"]\n",
    "    intercept_se = area_results[area].bse[\"Intercept\"]\n",
    "\n",
    "    ci_margin = 1.96 * np.sqrt(intercept_se**2 + (ap_range * ap_position_se)**2)\n",
    "    pred_df[\"lower_CI\"] = pred_df[\"conditional_prob_pred\"] - ci_margin\n",
    "    pred_df[\"upper_CI\"] = pred_df[\"conditional_prob_pred\"] + ci_margin\n",
    "\n",
    "    mouse_ids = df_long[\"mouse\"].unique()\n",
    "    color_palette = sb.dark_palette(main_color, len(mouse_ids), reverse=True)\n",
    "\n",
    "    for j, mouse in enumerate(mouse_ids):\n",
    "        sb.scatterplot(\n",
    "            data=df_long[df_long[\"mouse\"] == mouse], \n",
    "            x=\"AP_position\", y=\"conditional_prob\", \n",
    "            color=color_palette[j], \n",
    "            alpha=0.9, ax=ax\n",
    "        )\n",
    "    \n",
    "    ax.plot(\n",
    "        pred_df[\"AP_position\"], \n",
    "        pred_df[\"conditional_prob_pred\"], \n",
    "        color=main_color, \n",
    "        linewidth=2,\n",
    "        label=\"Mixed Model Fit\"\n",
    "    )\n",
    "    \n",
    "    ax.fill_between(\n",
    "        pred_df[\"AP_position\"], \n",
    "        pred_df[\"lower_CI\"], \n",
    "        pred_df[\"upper_CI\"], \n",
    "        color=main_color, alpha=0.2, label=\"95% CI\"\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"\")\n",
    "    \n",
    "    p_value_corrected = f\"p={area_p_values.loc[area]['p_val_adj']:.2g}\"\n",
    "    ax.text(\n",
    "        0.05, 0.82,  \n",
    "        p_value_corrected, \n",
    "        transform=ax.transAxes,\n",
    "        ha='left', va='top',\n",
    "        fontsize=10, color='black'\n",
    "    )\n",
    "\n",
    "    ax.text(\n",
    "        0.05, 0.97,  \n",
    "        convert_dict[area], \n",
    "        transform=ax.transAxes,\n",
    "        ha='left', va='top',\n",
    "        fontsize=12, fontweight='bold', color='black'\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"A-P position\")\n",
    "    ax.set_ylabel(f\"P({convert_dict[area]}|V1 A-P)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about madial lateral positioning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MouseConnectivityCache(resolution=25)\n",
    "rsp = mcc.get_reference_space()\n",
    "VIS_mask = rsp.make_structure_mask([669], direct_only=False) #669 is id for whole visual cortex\n",
    "\n",
    "\n",
    "#select anterior and posterior parts of A1\n",
    "x_midpoint = VIS_mask.shape[2] // 2\n",
    "contra_mask = np.zeros_like(VIS_mask, dtype=bool)\n",
    "contra_mask[:, :, x_midpoint:] = 1\n",
    "VIS_mask_ipsi = VIS_mask*contra_mask\n",
    "indices_VIS = np.argwhere(VIS_mask_ipsi == 1)\n",
    "max_x = np.max(indices_VIS[:, 2])\n",
    "min_x = np.min(indices_VIS[:, 2])\n",
    "ML_midpoint_VIS = ((max_x - min_x) / 2) + min_x\n",
    "\n",
    "# AP_midpoint_VIS = ((max_y - min_y) /2) + min_y\n",
    "# posterior_neurons = indices_AUDp[indices_AUDp[:, 0]>=AP_midpoint_A1]\n",
    "# anterior_neurons = indices_AUDp[indices_AUDp[:, 0]<AP_midpoint_A1]\n",
    "#now select only the ipsiliateral side of where was injected\n",
    "# x_midpoint = VIS_mask.shape[2] // 2\n",
    "# contra_mask = np.zeros_like(VIS_mask, dtype=bool)\n",
    "# contra_mask[:, :, x_midpoint:] = 1\n",
    "#take AP position of cubelets containing visual cortex (and also specifically V1)\n",
    "proj_path = pathlib.Path(\"/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq\")\n",
    "HVA_cols = ['VISp', 'VISpor', 'VISli', 'VISal', 'VISl', 'VISpl', 'VISpm', 'VISrl', 'VISam', 'VISa']\n",
    "mice = ['FIAA45.6a', 'FIAA45.6d', 'FIAA55.4d']\n",
    "ML_position_dict = {}\n",
    "ML_cond_prob_dict = {}\n",
    "for mouse in mice:\n",
    "    new_dict = {}\n",
    "    cond_prob_dict = {}\n",
    "    parameters_path = (\n",
    "    f\"/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/{mouse}/Sequencing\")\n",
    "    parameters = fpf.load_parameters(directory=parameters_path)\n",
    "    barcodes = pd.read_pickle(f\"{parameters_path}/A1_barcodes_thresholded.pkl\")\n",
    "    #sample_vol_and_regions =pd.read_pickle(pathlib.Path(parameters['lcm_directory'])/'sample_vol_and_regions.pkl')\n",
    "    areas_only_grouped = fpf.get_area_volumes(\n",
    "        barcode_table_cols=barcodes.columns,\n",
    "        lcm_directory=pathlib.Path(parameters['lcm_directory']),\n",
    "        area_threshold=0.5) #must contain at least 30% visual cortex\n",
    "    V1_containing = areas_only_grouped[areas_only_grouped['VISp']>0].index.to_list()\n",
    "    lcm_directory = pathlib.Path(parameters['lcm_directory'])\n",
    "    ROI_3D = np.load(lcm_directory / \"ROI_3D_25.npy\")\n",
    "    for sample in V1_containing:\n",
    "        if sample in barcodes.columns:\n",
    "            centroid = np.argwhere(ROI_3D == sample).mean(axis=0)\n",
    "            filtered_bc = barcodes[barcodes[sample]>0]\n",
    "            if len(filtered_bc)<5:\n",
    "                continue\n",
    "            new_dict[sample] = centroid[2]-min_x\n",
    "            filtered_bc.drop(columns=[sample], inplace=True)\n",
    "            filtered_with_area = fpf.homog_across_cubelet(parameters_path= parameters_path, barcode_matrix = filtered_bc, cortical=True, shuffled=False, IT_only=True)\n",
    "            cond_prob_dict[sample] = filtered_with_area.astype(bool).mean(axis=0)\n",
    "    ML_position_dict[mouse] = new_dict\n",
    "    ML_cond_prob_dict[mouse] = cond_prob_dict\n",
    "#for each mouse, given that a cubelet is in a particular AP position, what are the probablity of targeting other areas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "area_dic= {}\n",
    "for area in visual_areas:\n",
    "    area_df =pd.DataFrame(columns=['mouse', 'AP_position', 'conditional_prob'])\n",
    "    # ap_positions = AP_position_dict_list_combined.loc[combine_all_mice.index]['AP_position']\n",
    "    #area_correlations.loc['corr_all_mice', area] = combine_all_mice[area].astype(bool).astype(int).corr(ap_positions, method='spearman')\n",
    "    for mouse in mice:\n",
    "        for sample in ML_position_dict[mouse].keys():\n",
    "            AP_pos = ML_position_dict[mouse][sample]\n",
    "            cond_prob = ML_cond_prob_dict[mouse][sample][area]\n",
    "            new_row = pd.DataFrame({\"mouse\": [mouse], \"AP_position\": [AP_pos], \"conditional_prob\": [cond_prob]})\n",
    "            area_df = pd.concat([area_df, new_row], ignore_index=True)\n",
    "    area_dic[area] = area_df\n",
    "area_p_values = pd.DataFrame(columns=['p_value', 'p_val_adj'])\n",
    "area_results = {}\n",
    "for area in visual_areas:\n",
    "    df_long = area_dic[area]\n",
    "    model = smf.mixedlm(\n",
    "        formula=\"conditional_prob ~ AP_position\",\n",
    "        data=df_long,\n",
    "        groups=df_long[\"mouse\"],  # random intercept only\n",
    "        re_formula=\"1\"            # or omit if you want the default random intercept\n",
    "    )\n",
    "\n",
    "    res = model.fit()\n",
    "    area_results[area]=res\n",
    "\n",
    "    # Extract the p-value for the slope of AP_position\n",
    "    p_value_ap = res.pvalues[\"AP_position\"]\n",
    "    area_p_values.loc[area, 'p_value'] = p_value_ap\n",
    "    area_p_values.loc[area, 'p_val_adj'] = p_value_ap*len(visual_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.colors as mcolors\n",
    "convert_dict = {\n",
    "    \"VISl\": \"LM\",\n",
    "    \"VISrl\": \"RL\",\n",
    "    \"VISal\": \"AL\",\n",
    "    \"VISa\": \"A\",\n",
    "    \"VISp\": \"V1\",\n",
    "    \"VISpor\": \"POR\",\n",
    "    \"VISli\": \"LI\",\n",
    "    \"VISpl\": \"P\",\n",
    "    \"VISpm\": \"PM\",\n",
    "    \"VISam\": \"AM\"\n",
    "}\n",
    "HVA_colors_updated = {\n",
    "    'VISp': '#6E665E', 'VISpor': '#79B855', 'VISli': '#AAC255', 'VISpl': '#4C9E57', \n",
    "    'VISl': '#D6C759', 'VISal': '#C7A859', 'VISrl': '#F0BE7E', 'VISa': '#D78257', \n",
    "    'VISam': '#C2543C', 'VISpm': '#D7716C'\n",
    "}\n",
    "\n",
    "areas = ['VISa', 'VISpor', 'VISl', 'VISrl']\n",
    "HVA_only = [s for s in visual_areas if s != 'VISp']\n",
    "fig, axes = plt.subplots(3, 3, figsize=(7, 5), sharex=False, sharey=False)\n",
    "\n",
    "for i, area in enumerate(HVA_only):\n",
    "    row, col = divmod(i, 3)\n",
    "    ax = axes[row, col]\n",
    "    df_long = area_dic[area]\n",
    "\n",
    "    main_color = HVA_colors_updated.get(area, 'black')\n",
    "\n",
    "    ap_range = np.linspace(df_long[\"AP_position\"].min(), df_long[\"AP_position\"].max(), 50)\n",
    "    \n",
    "    pred_df = pd.DataFrame({\n",
    "        \"mouse\": [\"AverageMouse\"] * len(ap_range),\n",
    "        \"AP_position\": ap_range\n",
    "    })\n",
    "    \n",
    "    pred_df[\"conditional_prob_pred\"] = area_results[area].predict(pred_df)\n",
    "\n",
    "    ap_position_se = area_results[area].bse[\"AP_position\"]\n",
    "    intercept_se = area_results[area].bse[\"Intercept\"]\n",
    "\n",
    "    ci_margin = 1.96 * np.sqrt(intercept_se**2 + (ap_range * ap_position_se)**2)\n",
    "    pred_df[\"lower_CI\"] = pred_df[\"conditional_prob_pred\"] - ci_margin\n",
    "    pred_df[\"upper_CI\"] = pred_df[\"conditional_prob_pred\"] + ci_margin\n",
    "\n",
    "    mouse_ids = df_long[\"mouse\"].unique()\n",
    "    color_palette = sb.dark_palette(main_color, len(mouse_ids), reverse=True)\n",
    "\n",
    "    for j, mouse in enumerate(mouse_ids):\n",
    "        sb.scatterplot(\n",
    "            data=df_long[df_long[\"mouse\"] == mouse], \n",
    "            x=\"AP_position\", y=\"conditional_prob\", \n",
    "            color=color_palette[j], \n",
    "            alpha=0.9, ax=ax\n",
    "        )\n",
    "    \n",
    "    ax.plot(\n",
    "        pred_df[\"AP_position\"], \n",
    "        pred_df[\"conditional_prob_pred\"], \n",
    "        color=main_color, \n",
    "        linewidth=2,\n",
    "        label=\"Mixed Model Fit\"\n",
    "    )\n",
    "    \n",
    "    ax.fill_between(\n",
    "        pred_df[\"AP_position\"], \n",
    "        pred_df[\"lower_CI\"], \n",
    "        pred_df[\"upper_CI\"], \n",
    "        color=main_color, alpha=0.2, label=\"95% CI\"\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"\")\n",
    "    \n",
    "    p_value_corrected = f\"p={area_p_values.loc[area]['p_val_adj']:.2g}\"\n",
    "    ax.text(\n",
    "        0.05, 0.82,  \n",
    "        p_value_corrected, \n",
    "        transform=ax.transAxes,\n",
    "        ha='left', va='top',\n",
    "        fontsize=10, color='black'\n",
    "    )\n",
    "\n",
    "    ax.text(\n",
    "        0.05, 0.97,  \n",
    "        convert_dict[area], \n",
    "        transform=ax.transAxes,\n",
    "        ha='left', va='top',\n",
    "        fontsize=12, fontweight='bold', color='black'\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"M-L position\")\n",
    "    ax.set_ylabel(f\"P({convert_dict[area]}|V1 M-L)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
