{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import yaml\n",
    "import pathlib\n",
    "import os\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sb\n",
    "from preprocessing_sequencing import preprocess_sequences as ps\n",
    "from matplotlib import rcParams\n",
    "import statistics\n",
    "from final_processing import final_processing_functions as fpf\n",
    "import ast\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify which mouse id barcodes need to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = 'FIAA55.4d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"general_analysis_parameters.yaml\", \"r\") as file:\n",
    "    gen_parameters = yaml.safe_load(file)\n",
    "proj_path = '/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq'\n",
    "parameters_path = pathlib.Path(\n",
    "    f\"{proj_path}/{mouse}/Sequencing\")\n",
    "# parameters_path = pathlib.Path(parameters_path)\n",
    "parameters = ps.load_parameters(directory=str(parameters_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run barcode matching job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.barcode_matching(\n",
    "    sorting_directory=str(parameters_path / \"final_processed_sequences\"),\n",
    "    use_slurm=False,)\n",
    "    #slurm_folder=\"/camp/home/turnerb/slurm_logs\",\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set minimum count thresholds for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_across_sample = pd.read_pickle(\n",
    "    str(parameters_path / \"final_processed_sequences/barcodes_across_sample.pkl\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine cut-off for total counts for barcode across dataset\n",
    "max_y = 100\n",
    "rcParams[\"figure.figsize\"] = 8, 5\n",
    "interpolate_on_x = len(np.flip(np.sort(barcodes_across_sample.sum(axis=1)))) - len(\n",
    "    np.flip(np.sort(barcodes_across_sample.sum(axis=1)))[\n",
    "        np.flip(np.sort(barcodes_across_sample.sum(axis=1))) < max_y\n",
    "    ]\n",
    ")\n",
    "plt.loglog(np.flip(np.sort(barcodes_across_sample.sum(axis=1))), label=parameters[\"MOUSE\"])\n",
    "plt.xlabel(\"rank\")\n",
    "plt.ylabel(\"total barcode counts\")\n",
    "plt.axhline(y=max_y, linestyle=\"dashed\", color=\"Black\", label=\"cut-off\", alpha=0.5)\n",
    "plt.axvline(x=interpolate_on_x, linestyle=\"dashed\", color=\"Black\", alpha=0.5)\n",
    "plt.title(\n",
    "    f\"total count per barcode across MAPseq dataset ranked (x={interpolate_on_x})\"\n",
    ")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter barcodes that are not seen above a minimum amount of times\n",
    "filtered_barcodes = barcodes_across_sample[barcodes_across_sample.sum(axis=1) >= max_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = parameters['negative_control_samples']\n",
    "rcParams[\"figure.figsize\"] = 5, 5\n",
    "cmap = plt.get_cmap(\"tab20c\")\n",
    "\n",
    "negs = filtered_barcodes[negative_samples].melt(\n",
    "    var_name=\"samples\", value_name=\"barcode_counts\"\n",
    ")\n",
    "colours_picking = sb.color_palette(\"tab20c\")[0:3]\n",
    "plt.pie(\n",
    "    negs[negs[\"barcode_counts\"] > 0][\"barcode_counts\"].value_counts(),\n",
    "    labels=negs[negs[\"barcode_counts\"] > 0][\"barcode_counts\"]\n",
    "    .value_counts()\n",
    "    .index.values.tolist(),\n",
    "    colors=colours_picking,\n",
    ")\n",
    "plt.title(\n",
    "    f\"barcode umi counts in negative controls \\n n = {len(negs[negs.barcode_counts>0])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_barcode_count_per_sample = 2\n",
    "for x in range(1, min_barcode_count_per_sample):\n",
    "    filtered_barcodes = filtered_barcodes.replace(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rename tubes, so sample names in sequencing data is the same as tube names\n",
    "#filtered_barcodes = fpf.rename_tubes(barcode_table =filtered_barcodes, parameters_path= parameters_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise based on spike in RNA levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorting_dir = parameters_path / \"final_processed_sequences\"\n",
    "# spike-in normalisation, generate table of spike counts per sample\n",
    "spike_counts = pd.DataFrame(columns=[\"sample\", \"spike_count\"])\n",
    "for sample in os.listdir(sorting_dir):\n",
    "    if sample.startswith(\"spike_counts\"):\n",
    "        sample_name = sample.split(\"spike_counts_\", 1)\n",
    "        sample_name = sample_name[1][: -len(\".csv\")]\n",
    "        sample_num = float(sample_name[2:])\n",
    "        sample_reading = pd.read_csv(sorting_dir / sample)\n",
    "        sample_reading[\"counts\"] = sample_reading[\"counts\"].astype(\"int\")\n",
    "        sum_counts = sample_reading[\"counts\"].sum()\n",
    "        new_row = pd.DataFrame(\n",
    "            {\"sample\": sample_num, \"spike_count\": sum_counts}, index=[0]\n",
    "        )\n",
    "        spike_counts = pd.concat([spike_counts, new_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribtution of spike-in reads and decide cut-off threshold\n",
    "rcParams[\"figure.figsize\"] = 5, 5\n",
    "plt.hist(spike_counts[\"spike_count\"], bins=20)\n",
    "plt.xlabel(\"total spike umi count\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.title(\"distribution of spike counts across samples\")\n",
    "plt.axvline(x=50, color=\"black\", linestyle=\"dashed\", label=\"cut-off\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove spikes that are below certain threshold, then normalise total counts in each sample by relative spike-count\n",
    "\n",
    "spike_cutoff = 10\n",
    "spike_thresh = list(spike_counts[spike_counts[\"spike_count\"] < spike_cutoff][\"sample\"])\n",
    "filtered_barcodes_QC = filtered_barcodes.drop((spike_thresh), axis=1)\n",
    "spikes_thresholded = spike_counts[spike_counts[\"spike_count\"] > spike_cutoff]\n",
    "median_spike = statistics.median(spikes_thresholded[\"spike_count\"].to_list())\n",
    "spikes_thresholded[\"normalisation_factor\"] = (\n",
    "    spikes_thresholded[\"spike_count\"] / median_spike\n",
    ")\n",
    "filtered_barcodes_spike_normalised = filtered_barcodes_QC.copy()\n",
    "for i, row in spikes_thresholded.iterrows():\n",
    "    if row[\"sample\"] in filtered_barcodes_spike_normalised.columns:\n",
    "        filtered_barcodes_spike_normalised[row[\"sample\"]] = (\n",
    "            filtered_barcodes_spike_normalised[row[\"sample\"]]\n",
    "            / row[\"normalisation_factor\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename tubes, so sample names in sequencing data is the same as tube names\n",
    "filtered_barcodes_spike_normalised = fpf.rename_tubes(barcode_table =filtered_barcodes_spike_normalised, parameters_path= parameters_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's locate the soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcm_dir =parameters['lcm_directory']\n",
    "ROI_3D = np.load(f\"{lcm_dir}/ROI_3D_25.npy\")\n",
    "#remove barcodes only found less than two samples\n",
    "filtered_barcodes_spike_normalised=filtered_barcodes_spike_normalised[filtered_barcodes_spike_normalised.astype(bool).sum(axis=1)>2]\n",
    "adj_roi = fpf.find_adjacent_samples(ROI_array= ROI_3D, samples_to_look= filtered_barcodes_spike_normalised.columns, parameters_path=str(parameters_path))\n",
    "# for key in list(adj_roi.keys()):\n",
    "#     adj_roi[key] = [sample for sample in adj_roi[key] if sample not in failed_RT] #make sure we're not including the samples we removed \n",
    "# now set adjacent columns to zero\n",
    "for i in np.unique(filtered_barcodes_spike_normalised.idxmax(axis=1)):\n",
    "    to_rename = [col for col in adj_roi[i] if col in filtered_barcodes_spike_normalised.columns]\n",
    "    filtered_barcodes_spike_normalised.loc[filtered_barcodes_spike_normalised.idxmax(axis=1)==i, to_rename] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the distribution max/2nd max look like?\n",
    "filtered_barcodes_abundance = pd.DataFrame()\n",
    "filtered_barcodes_abundance[\"highest\"] = filtered_barcodes_spike_normalised.max(axis=1)\n",
    "filtered_barcodes_abundance[\"second\"] = (filtered_barcodes_spike_normalised.apply(lambda row: row.nlargest(2).values[-1], axis=1) )\n",
    "\n",
    "filtered_barcodes_abundance[\"relative_to_max\"] = np.log10(\n",
    "    filtered_barcodes_abundance[\"highest\"] / filtered_barcodes_abundance[\"second\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_cut_off = 5\n",
    "fig, ax = plt.subplots(2, figsize=(5, 10))\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "slope = 1\n",
    "intercept = np.log10(ratio_cut_off)\n",
    "x_vals = np.array((0, 5))\n",
    "y_vals = intercept + slope * x_vals\n",
    "\n",
    "ax[0].hist(filtered_barcodes_abundance[\"relative_to_max\"], alpha=0.5,  color = 'slategray', bins=np.arange(0, 4, 0.2))\n",
    "ax[0].axvline(np.log10(ratio_cut_off),color='black', linestyle='-', alpha = 0.3)\n",
    "ax[0].set_xlabel('log10(max/2nd max)')\n",
    "ax[0,].set_ylabel('frequency')\n",
    "\n",
    "ax[1].scatter(\n",
    "    x=np.log10(filtered_barcodes_abundance[\"second\"]),\n",
    "    y=np.log10(filtered_barcodes_abundance[\"highest\"]),\n",
    "    s=1,\n",
    "    alpha=0.1,\n",
    ")\n",
    "ax[1].plot(\n",
    "   x_vals, y_vals, \"--\", c=\"grey\", label=f\"x{ratio_cut_off} enrichment of soma\", alpha=0.3\n",
    ")\n",
    "ax[1].set_xlabel('log10(max/2nd max)')\n",
    "ax[1].set_ylabel('frequency')\n",
    "plt.suptitle('Frequency distribution 1st / 2nd max counts of barcodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set minimum soma to second max ratio and set the main projection target to be minimum 10 counts\n",
    "soma_thresh = np.log10(ratio_cut_off)\n",
    "filtered_soma_barcodes = filtered_barcodes_spike_normalised[\n",
    "    (filtered_barcodes_abundance[\"relative_to_max\"] > soma_thresh) & (filtered_barcodes_abundance[\"second\"] >= 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(filtered_soma_barcodes.astype(bool).sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's select barcodes that have A1 as a source site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sample table, get main region\n",
    "sample_vol_path = parameters['lcm_directory']+'/sample_vol_and_regions.pkl'\n",
    "#fpf.get_main_region(sample_vol=sample_vol_path, parameters_path= str(parameters_path), use_slurm=True, slurm_folder=\"/camp/home/turnerb/slurm_logs\", job_dependency=lrf_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vol_and_regions =pd.read_pickle(pathlib.Path(parameters['lcm_directory'])/'sample_vol_and_regions.pkl')\n",
    "AUDp_containing = sample_vol_and_regions[sample_vol_and_regions['main']=='AUDp']['ROI Number'].to_list()\n",
    "filtered_soma_barcodes =filtered_soma_barcodes[filtered_soma_barcodes.idxmax(axis=1).isin(AUDp_containing)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As further QC, remove samples where reverse transcription failed. Here, all samples with no MAPseq counts removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_RT = filtered_soma_barcodes.loc[:, (filtered_soma_barcodes == 0).all()].columns\n",
    "filtered_soma_barcodes.drop(columns=failed_RT, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_barcodes.to_pickle(parameters_path/'A1_barcodes_thresholded_with_source.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDp_containing = [sample for sample in AUDp_containing if sample in filtered_soma_barcodes.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove source samples for analysis\n",
    "filtered_soma_barcodes.drop(columns=AUDp_containing, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_barcodes.to_pickle(parameters_path/'A1_barcodes_thresholded.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAPseq_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
