{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/camp/home/turnerb/.conda/envs/MAPseq_processing/lib/python3.8/site-packages/flexiznam/schema/sequencing_data.py:11: UserWarning: Could not find `sequencing_extensions` in config. Please update config file\n",
      "  class SequencingData(Dataset):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from final_processing import final_processing_functions as fpf\n",
    "import pathlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import ks_2samp\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "from matplotlib import rcParams\n",
    "import yaml\n",
    "import figure_formatting as ff\n",
    "from scipy.stats import pearsonr\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"general_analysis_parameters.yaml\", \"r\") as file:\n",
    "    gen_parameters = yaml.safe_load(file)\n",
    "rcParams['font.sans-serif'] = gen_parameters['font']\n",
    "rcParams['font.family'] = gen_parameters['font']\n",
    "rcParams['font.size'] = gen_parameters['font_size']\n",
    "font_size = gen_parameters['font_size']\n",
    "saving_path = gen_parameters['fig_saving_path']\n",
    "mice = gen_parameters['MICE']\n",
    "proj_path = gen_parameters['proj_path']\n",
    "\n",
    "# saving_path = '/nemo/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/figs'\n",
    "# mice = ['FIAA45.6a', 'FIAA45.6d', 'FIAA55.4d']\n",
    "combined_dict = {}\n",
    "area_dict = {}\n",
    "for num, mouse in enumerate(mice):\n",
    "    new_dict = {}\n",
    "    parameters_path = (\n",
    "    f\"{proj_path}/{mouse}/Sequencing\")\n",
    "    barcodes = pd.read_pickle(f\"{parameters_path}/A1_barcodes_thresholded.pkl\")\n",
    "    lcm_dir =  pathlib.Path(\n",
    "    f\"{proj_path}/{mouse}/LCM\")\n",
    "    area_dict[mouse] = fpf.get_area_volumes(\n",
    "        barcode_table_cols=barcodes.columns,\n",
    "        lcm_directory=lcm_dir, area_threshold=0,\n",
    "    )\n",
    "    barcodes = fpf.add_prefix_to_index(barcodes, mouse)\n",
    "    new_dict['homogenous_across_cubelet'] = fpf.homog_across_cubelet(parameters_path=parameters_path, barcode_matrix = barcodes, cortical=True, IT_only=True, shuffled=False)\n",
    "    new_dict['homogenous_across_area'] = fpf.homog_across_area(parameters_path=parameters_path, barcode_matrix = barcodes, cortical=True, IT_only=True, shuffled=False)\n",
    "    new_dict['area_is_main']= fpf.area_is_main(parameters_path=parameters_path, barcode_matrix = barcodes, cortical=True, IT_only=True, shuffled=False)\n",
    "    new_dict['max_counts'] = barcodes.max(axis=1)\n",
    "    combined_dict[mouse] = new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_names =['homogenous_across_cubelet', 'homogenous_across_area', 'area_is_main']\n",
    "all_mice = {}\n",
    "for i, key in enumerate(analysis_names):\n",
    "    common_columns = fpf.get_common_columns(mice=mice, combined_dict=combined_dict, key=key, cortex=False)\n",
    "    all_mice[key] = pd.concat([\n",
    "    combined_dict[k][key][common_columns]\n",
    "    for k in mice\n",
    "])\n",
    "    #all_mice[key] = pd.concat([combined_dict['FIAA45.6a'][key][common_columns], combined_dict['FIAA45.6d'][key][common_columns], combined_dict['FIAA55.4d'][key][common_columns]], ignore_index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "\n",
    "key='homogenous_across_cubelet'\n",
    "visual_areas = ['VISli','VISpor', 'VISpl', 'VISl', 'VISp', 'VISal', 'VISam', 'VISpm', 'VISa', 'VISrl']\n",
    "vis_adj =[vis for vis in visual_areas if vis in all_mice[key].columns]\n",
    "vis_proj = all_mice[key][all_mice[key][vis_adj].astype(bool).sum(axis=1)>0]\n",
    "#data = vis_proj[vis_adj].astype(bool).sum(axis=1).value_counts()\n",
    "data = vis_proj[vis_adj].astype(bool).sum(axis=1)\n",
    "fig, ax = plt.subplots(figsize=(1, 1.5))  \n",
    "counts = np.bincount(data, minlength=11)\n",
    "\n",
    "ax.bar(np.arange(11)[1:], counts[1:] / np.sum(counts), color='black',edgecolor='black')\n",
    "ax.set_xticks([1, 10])\n",
    "ax.set_xlabel('# visual areas targeted')\n",
    "ax.set_ylabel('Proportion of\\nVC-projecting cells')\n",
    "sb.despine(ax=ax, offset=5)\n",
    "\n",
    "max_counts_list = [data[\"max_counts\"] for data in combined_dict.values()]\n",
    "\n",
    "# Concatenate all 'max_counts' dataframes\n",
    "concatenated_max_counts = pd.concat(max_counts_list, ignore_index=False)\n",
    "max_counts = concatenated_max_counts.loc[vis_proj[vis_adj].index]\n",
    "saving_path = '/nemo/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/figs'\n",
    "\n",
    "fig.savefig(f\"{saving_path}/vc_projection_counts.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supp figure showing how max cubelet barcode count per barcode changes with number of visual areas targeted\n",
    "fig, ax = plt.subplots(figsize=(1.2, 1.2))\n",
    "df = pd.DataFrame({\"x\": data, \"y\": np.log2(max_counts)})\n",
    "sb.barplot(x=\"x\", y=\"y\", data=df, alpha=0.6, color=\"purple\", ci=None)\n",
    "\n",
    "sb.stripplot(x=\"x\", y=\"y\", data=df, color=\"black\", alpha=0.1, jitter=True)\n",
    "# plt.xlabel(\"# visual areas targeted\")\n",
    "# plt.ylabel(\"log2(max count)\")\n",
    "ff.myPlotSettings_splitAxis(fig=fig, ax=ax, ytitle= 'log2(max count)', xtitle='# Visual Areas Targeted', title='', mySize =5)\n",
    "fig.savefig(f\"{saving_path}/supplementary/extended_fig_3b_change_in_vis_areas_versus_max_count.svg\", format=\"svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# layers = ['upper', 'lower']\n",
    "# mouse_layer_dict = {}\n",
    "# for num, mouse in enumerate(mice):\n",
    "#     new_dict = {}\n",
    "#     parameters_path = (\n",
    "#     f\"/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/{mouse}/Sequencing\")\n",
    "#     barcodes = pd.read_pickle(f\"{parameters_path}/A1_barcodes_thresholded_with_source.pkl\")\n",
    "#     parameters = fpf.load_parameters(directory=parameters_path)\n",
    "#     sample_vol_and_regions = pd.read_pickle(pathlib.Path(parameters['lcm_directory'])/'sample_vol_and_regions.pkl')\n",
    "#     sample_vol_and_regions['fractions'] = sample_vol_and_regions['breakdown'].apply(ast.literal_eval)\n",
    "#     sample_vol_and_regions['regions'] = sample_vol_and_regions['regions'].apply(ast.literal_eval)\n",
    "#     AUDp_containing = sample_vol_and_regions[sample_vol_and_regions['main']=='AUDp']['ROI Number'].to_list()\n",
    "#     AUDp_containing = [sample for sample in AUDp_containing if sample in barcodes.columns]\n",
    "#     for layer in layers:\n",
    "#         area_dict = {}\n",
    "#         barcodes_new = barcodes[barcodes.idxmax(axis=1).isin(parameters[f'{layer}_layer'])].drop(columns=AUDp_containing)\n",
    "#         barcodes_new = barcodes_new[\n",
    "#             (barcodes_new[[f for f in parameters['cortical_samples'] if f in barcodes_new.columns]].astype(bool).sum(axis=1) > 0) &\n",
    "#             (barcodes_new[[s for s in parameters['tectum_samples'] if s in barcodes_new.columns]].astype(bool).sum(axis=1) == 0) &\n",
    "#             (barcodes_new[[s for s in parameters['thalamus_samples'] if s in barcodes_new.columns]].astype(bool).sum(axis=1) == 0)\n",
    "#         ]\n",
    "#         area_dict['area_is_main'] = fpf.area_is_main(parameters_path=parameters_path, barcode_matrix = barcodes_new, cortical=True, shuffled=False)\n",
    "#        # missing_cols = set(all_mice[key].columns) - set(area_dict['area_is_main'].columns) #since there is some zero values for regions that are looked at\n",
    "#         #for col in missing_cols:\n",
    "#         #    area_dict['area_is_main'][col] = 0\n",
    "#         area_dict['homogenous_across_cubelet'] = fpf.homog_across_cubelet(parameters_path=parameters_path, barcode_matrix = barcodes_new, cortical=True, IT_only=True, shuffled=False)\n",
    "#         area_dict['homogenous_across_area'] = fpf.homog_across_area(parameters_path=parameters_path, barcode_matrix = barcodes_new, cortical=True, IT_only=True, shuffled=False)\n",
    "#         new_dict[f'{layer}_layer'] = area_dict\n",
    "#         # print(f\"Creating barcodes for {layer} layer in {mouse}\")\n",
    "#         # print(area_dict['homogenous_across_area'])\n",
    "    \n",
    "#     mouse_layer_dict[mouse] = new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_mouse_layer(df, mouse_label, layer_label):\n",
    "#     df['Mouse'] = mouse_label\n",
    "#     df['Layer'] = layer_label\n",
    "#     return df\n",
    "# visual_areas = ['VISli','VISpor', 'VISpl', 'VISl', 'VISp', 'VISal', 'VISam', 'VISpm', 'VISa', 'VISrl']\n",
    "# key = 'homogenous_across_cubelet'\n",
    "# new_layer_dict = {}\n",
    "# for mouse in mice:\n",
    "#     mini_dict = {}\n",
    "#     for layer in layers:\n",
    "#         mini_dict[f'{layer}_layer'] = mouse_layer_dict[mouse][f'{layer}_layer'][key][visual_areas].astype(bool).astype(int)\n",
    "#         mini_dict[f'{layer}_layer'] = add_mouse_layer(mini_dict[f'{layer}_layer'], mouse, layer)\n",
    "#     concatenated_df = pd.concat(mini_dict.values(), axis=0, ignore_index=False)\n",
    "#     new_layer_dict[mouse] = concatenated_df\n",
    "# combined_df = pd.concat(new_layer_dict.values(), axis=0, ignore_index=False)\n",
    "# combined_df = combined_df.dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# results = {}\n",
    "# df = combined_df.melt(id_vars=['Mouse', 'Layer'], var_name='Area', value_name='Projection')\n",
    "# pval_df = pd.DataFrame(index=visual_areas, columns=['p_value', 'OR'])\n",
    "# for area in visual_areas:\n",
    "#     df_area = df[df['Area'] == area]\n",
    "#     model = smf.logit('Projection ~ Layer + Mouse', data=df_area).fit(disp=False)\n",
    "#     results = model.summary2().tables[1]\n",
    "#     pval_df.loc[area, 'p_value'] = results.loc['Layer[T.upper]', 'P>|z|']\n",
    "#     pval_df.loc[area, 'OR'] = np.exp(results.loc['Layer[T.upper]', 'Coef.'])\n",
    "\n",
    "# pval_df['p_value_corrected'] = pval_df['p_value']*len(pval_df)\n",
    "# summary_df = pd.DataFrame(index = mice, columns = visual_areas)\n",
    "# for mouse in mice:\n",
    "#     dff = new_layer_dict[mouse]\n",
    "#     for area in visual_areas:\n",
    "#         freq_upper = dff[dff['Layer']=='upper'][area].mean()\n",
    "#         freq_lower = dff[dff['Layer']=='lower'][area].mean()\n",
    "#         summary_df.loc[mouse, area] = freq_upper/freq_lower\n",
    "# visual_areas = summary_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pval_df = fpf.convert_matrix_names(pval_df)\n",
    "# summary_df = fpf.convert_matrix_names(summary_df)\n",
    "# new_order = ['LM', 'LI', 'POR', 'P', 'AL', 'V1', 'AM', 'A', 'PM', 'RL']\n",
    "# summary_df = summary_df[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(2.5, 2))  # Adjusted figure size for better layout\n",
    "# area_means = summary_df.mean(axis=0)\n",
    "# max_value = summary_df.max().max()\n",
    "# sb.barplot(x=new_order, y=area_means, color='black', ci=None, width=0.9, zorder=1)\n",
    "# for i, area in enumerate(new_order):\n",
    "#     for mouse in summary_df.index:\n",
    "#         plt.scatter(\n",
    "#             i, \n",
    "#             summary_df.loc[mouse, area], \n",
    "#             color='grey', s=20, zorder=2\n",
    "#         )\n",
    "# heights = []\n",
    "# for i, area in enumerate(new_order):\n",
    "#     asterisk_height = summary_df[area].max() + 0.1  \n",
    "#     p_value = pval_df.loc[area, 'p_value_corrected']  \n",
    "#     if p_value <= 0.001:\n",
    "#         asterisk = '***'\n",
    "#     elif p_value <= 0.01:\n",
    "#         asterisk = '**'\n",
    "#     elif p_value <= 0.05:\n",
    "#         asterisk = '*'\n",
    "#     else:\n",
    "#         asterisk = None  # No asterisk if p > 0.05\n",
    "    \n",
    "#     if asterisk:  # Add asterisk if significance is present\n",
    "#         plt.text(\n",
    "#             i,  \n",
    "#             asterisk_height,\n",
    "#             asterisk, \n",
    "#             ha='center', va='bottom', fontsize=16, color='black', weight='bold'\n",
    "#         )\n",
    "#         heights.append(asterisk_height)\n",
    "# plt.axhline(y=1, color='red', linestyle='--', linewidth=2)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.ylim(0, np.max(heights) + 0.5) \n",
    "# ylabel = 'Upper vs Deep Layer A1 Neuron \\n Targeting Frequency'\n",
    "# ff.myPlotSettings_splitAxis(fig=fig, ax=ax, ytitle= ylabel, xtitle='', title='', mySize =7)\n",
    "# fig.savefig(f\"{saving_path}/supplementary/upper_vs_deep.svg\", format=\"svg\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcc = MouseConnectivityCache()\n",
    "# structure_tree = mcc.get_structure_tree()\n",
    "# rsp = mcc.get_reference_space()\n",
    "# plt.rcParams[\"font.size\"] = 5\n",
    "# a1_dist_dict = {}\n",
    "# visual_areas = ['VISli', 'VISpor', 'VISpl', 'VISl', 'VISp', 'VISal', 'VISam', 'VISpm', 'VISa', 'VISrl']\n",
    "# HVA_colors_updated = ff.get_colour_dict(allen_nomenclature=True)\n",
    "# # HVA_colors_updated = {\n",
    "# #     'VISp': '#6E665E', 'VISpor': '#79B855', 'VISli': '#AAC255', 'VISpl': '#4C9E57', \n",
    "# #     'VISl': '#D6C759', 'VISal': '#C7A859', 'VISrl': '#F0BE7E', 'VISa': '#D78257', \n",
    "# #     'VISam': '#C2543C', 'VISpm': '#D7716C'\n",
    "# # }\n",
    "\n",
    "# structure = structure_tree.get_structures_by_acronym(['AUDp'])\n",
    "# structure_id = structure[0]['id']\n",
    "# mask = rsp.make_structure_mask([structure_id], direct_only=False)\n",
    "# A1_coord = (np.mean(np.where(mask == 1)[0]), np.mean(np.where(mask == 1)[1]), np.mean(np.where(mask == 1)[2]))\n",
    "\n",
    "# fig, axes = plt.subplots(2, 1, figsize=(1.2, 3), sharex=True)\n",
    "\n",
    "# plt.subplots_adjust(hspace=0.5)  # Increases vertical spacing between subplots\n",
    "\n",
    "# def exponential_decay(x, a, b):\n",
    "#     return a * np.exp(-b * x)\n",
    "\n",
    "# key_to_plot = 'homogenous_across_cubelet'\n",
    "# areas = all_mice[key_to_plot].columns.drop(['Contra', 'AUDp'])\n",
    "# vis_adj = [vis for vis in visual_areas if vis in all_mice[key_to_plot].columns]\n",
    "\n",
    "# distance_from_a1 = pd.DataFrame(index=areas, columns=['dist'])\n",
    "# for col in areas:\n",
    "#     structure = structure_tree.get_structures_by_acronym([col])\n",
    "#     structure_id = structure[0]['id']\n",
    "#     mask = rsp.make_structure_mask([structure_id], direct_only=False)\n",
    "#     vis_coord = np.mean(np.where(mask == 1)[0]), np.mean(np.where(mask == 1)[1]), np.mean(np.where(mask == 1)[2])\n",
    "#     distance_from_a1.loc[col] = np.linalg.norm(np.array(A1_coord) - np.array(vis_coord)) * 25\n",
    "\n",
    "# a1_dist_dict[key_to_plot] = distance_from_a1\n",
    "\n",
    "# freq_df = pd.DataFrame(columns=areas, index=mice)\n",
    "# freq_df_strength = pd.DataFrame(columns=areas, index=mice)\n",
    "# for mouse in mice:\n",
    "#     freq_df.loc[mouse] = combined_dict[mouse][key_to_plot][areas].astype(bool).sum(axis=0) / len(combined_dict[mouse][key_to_plot])\n",
    "#     freq_df_strength.loc[mouse] = combined_dict[mouse][key_to_plot][areas].where(combined_dict[mouse][key_to_plot][areas] > 0).mean(axis=0)\n",
    "# distances = pd.Series(a1_dist_dict[key_to_plot].iloc[:, 0], index=areas)\n",
    "# distances = pd.to_numeric(distances, errors='coerce')\n",
    "# for which_one, which_type in enumerate([freq_df, freq_df_strength]):\n",
    "#     means = pd.to_numeric(which_type.mean(), errors='coerce')\n",
    "#     errors = pd.to_numeric(which_type.std(), errors='coerce')\n",
    "\n",
    "#     if len(distances) > 1 and (means > 0).any() and not distances.isnull().any() and not means.isnull().any():\n",
    "#         try:\n",
    "#             params, _ = curve_fit(exponential_decay, distances.values, means.values, p0=(max(means), 0.001))\n",
    "#             fitted_x = np.linspace(min(distances), max(distances), 100)\n",
    "#             fitted_y = exponential_decay(fitted_x, *params)\n",
    "#             what_plot = axes[which_one].plot(fitted_x, fitted_y, color='k', linestyle='dotted', label='Exponential Fit')\n",
    "            \n",
    "#             fitted_values = exponential_decay(distances.values, *params)\n",
    "#             ks_stat, ks_p_value = ks_2samp(means.values, fitted_values)\n",
    "#             print(f\"KS Statistic: {ks_stat}, p-value: {ks_p_value}\")\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error fitting exponential curve for key {key_to_plot}: {e}\")\n",
    "\n",
    "#     for area in areas:\n",
    "#         color = HVA_colors_updated.get(area, 'lightgrey')\n",
    "#         axes[which_one].errorbar(distances[area], means[area], yerr=errors[area], fmt='o', color='black', mfc=color, mec=color, capsize=3, markersize=2, elinewidth=0.5)\n",
    "#         # axes[1].errorbar(distances[area], means[area], yerr=errors[area], fmt='o', ecolor='black', mfc=color, mec=color, capsize=5)\n",
    "#     ff.myPlotSettings_splitAxis(fig=what_plot, ax=axes[which_one], ytitle= '', xtitle='Distance from A1 (µm)', title='', mySize =5)\n",
    "# axes[0].set_ylabel('Frequency of Targeting')\n",
    "# axes[1].set_ylabel('Mean Projection Strength')\n",
    "# axes[0].tick_params(labelbottom=True)\n",
    "# convert_dict = ff.get_convert_dict()\n",
    "\n",
    "# visual_legend_elements = [\n",
    "#     Line2D([0], [0], marker='o', color='w', \n",
    "#            label=convert_dict.get(area, area),  # Convert name using dictionary\n",
    "#            markerfacecolor=color, markersize=4, linestyle='None')\n",
    "#     for area, color in HVA_colors_updated.items()\n",
    "# ]\n",
    "\n",
    "# fig.legend(handles=visual_legend_elements, loc='center left', bbox_to_anchor=(1.01, 0.5), fontsize=5, prop={'family': 'Arial'})\n",
    "# # visual_legend_elements = [\n",
    "# #     Line2D([0], [0], marker='o', color='w', label=area, markerfacecolor=color, markersize=8, linestyle='None')\n",
    "# #     for area, color in HVA_colors_updated.items()\n",
    "# # ]\n",
    "\n",
    "# # fig.legend(handles=visual_legend_elements, loc='center left', bbox_to_anchor=(1.01, 0.5), fontsize=10)\n",
    "\n",
    "# for ax in axes:\n",
    "#     ax.legend(loc='upper right', fontsize=5)\n",
    "# #fig.savefig(f\"{saving_path}/fig2_dist_vs_proj.svg\", format=\"svg\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MouseConnectivityCache()\n",
    "structure_tree = mcc.get_structure_tree()\n",
    "rsp = mcc.get_reference_space()\n",
    "\n",
    "a1_dist_dict = {}\n",
    "visual_areas = ['VISli', 'VISpor', 'VISpl', 'VISl', 'VISp', 'VISal', 'VISam', 'VISpm', 'VISa', 'VISrl']\n",
    "HVA_colors_updated = ff.get_colour_dict(allen_nomenclature=True)\n",
    "\n",
    "structure = structure_tree.get_structures_by_acronym(['AUDp'])\n",
    "structure_id = structure[0]['id']\n",
    "mask = rsp.make_structure_mask([structure_id], direct_only=False)\n",
    "A1_coord = (np.mean(np.where(mask == 1)[0]), np.mean(np.where(mask == 1)[1]), np.mean(np.where(mask == 1)[2]))\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(2.2, 1.2))\n",
    "fig, axes = plt.subplots(1, 2, figsize=(3, 1)) \n",
    "plt.subplots_adjust(wspace=1)\n",
    "#plt.subplots_adjust(hspace=0.5)  # Increases vertical spacing between subplots\n",
    "\n",
    "def exponential_decay(x, a, b):\n",
    "    return a * np.exp(-b * x)\n",
    "\n",
    "key_to_plot = 'homogenous_across_cubelet'\n",
    "areas = all_mice[key_to_plot].columns.drop(['Contra', 'AUDp'])\n",
    "vis_adj = [vis for vis in visual_areas if vis in all_mice[key_to_plot].columns]\n",
    "\n",
    "distance_from_a1 = pd.DataFrame(index=areas, columns=['dist'])\n",
    "for col in areas:\n",
    "    structure = structure_tree.get_structures_by_acronym([col])\n",
    "    structure_id = structure[0]['id']\n",
    "    mask = rsp.make_structure_mask([structure_id], direct_only=False)\n",
    "    vis_coord = np.mean(np.where(mask == 1)[0]), np.mean(np.where(mask == 1)[1]), np.mean(np.where(mask == 1)[2])\n",
    "    distance_from_a1.loc[col] = np.linalg.norm(np.array(A1_coord) - np.array(vis_coord)) * 25\n",
    "\n",
    "a1_dist_dict[key_to_plot] = distance_from_a1\n",
    "\n",
    "freq_df = pd.DataFrame(columns=areas, index=mice)\n",
    "freq_df_strength = pd.DataFrame(columns=areas, index=mice)\n",
    "for mouse in mice:\n",
    "    freq_df.loc[mouse] = combined_dict[mouse][key_to_plot][areas].astype(bool).sum(axis=0) / len(combined_dict[mouse][key_to_plot])\n",
    "    freq_df_strength.loc[mouse] = combined_dict[mouse][key_to_plot][areas].where(combined_dict[mouse][key_to_plot][areas] > 0).mean(axis=0)\n",
    "freq_df_strength= freq_df_strength*1e9 #convert to mm3\n",
    "distances = pd.Series(a1_dist_dict[key_to_plot].iloc[:, 0], index=areas)\n",
    "distances = pd.to_numeric(distances, errors='coerce')\n",
    "for which_one, which_type in enumerate([freq_df, freq_df_strength]):\n",
    "    means = pd.to_numeric(which_type.mean(), errors='coerce')\n",
    "    errors = pd.to_numeric(which_type.std(), errors='coerce')\n",
    "\n",
    "    if len(distances) > 1 and (means > 0).any() and not distances.isnull().any() and not means.isnull().any():\n",
    "        try:\n",
    "            params, _ = curve_fit(exponential_decay, distances.values, means.values, p0=(max(means), 0.001))\n",
    "            fitted_x = np.linspace(min(distances), max(distances), 100)\n",
    "            fitted_y = exponential_decay(fitted_x, *params)\n",
    "            what_plot = axes[which_one].plot(\n",
    "                fitted_x, \n",
    "                fitted_y, \n",
    "                color='black', \n",
    "                linewidth=0.5, \n",
    "                linestyle='dotted',\n",
    "                label=f'Exponential\\nFit'\n",
    "            )\n",
    "            fitted_values = exponential_decay(distances.values, *params)\n",
    "            ks_stat, ks_p_value = ks_2samp(means.values, fitted_values)\n",
    "            print(f\"KS Statistic: {ks_stat}, p-value: {ks_p_value}, legnth scale: {1/params[1]}\")\n",
    "\n",
    "            # make cross-validated predictions by holding out one value at a time\n",
    "            for i in range(len(distances)):\n",
    "                # Create a mask for all indices except the current one\n",
    "                mask = np.ones(len(distances), dtype=bool)\n",
    "                mask[i] = False\n",
    "                # Calculate the fitted value for the current index\n",
    "                params, _ = curve_fit(exponential_decay, distances.values[mask], means.values[mask], p0=(max(means), 0.001))\n",
    "                # Store the fitted value in the array\n",
    "                fitted_values[i] = exponential_decay(distances.values[i], *params)\n",
    "\n",
    "            # quantify the goodness of fit as the correlation between the observed and fitted values\n",
    "            correlation, correlation_p_value = pearsonr(means.values, fitted_values)\n",
    "            print(f\"Correlation: {correlation}, p-value: {correlation_p_value}\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting exponential curve for key {key_to_plot}: {e}\")\n",
    "\n",
    "    for area in areas:\n",
    "        color = HVA_colors_updated.get(area, 'lightgrey')\n",
    "        axes[which_one].errorbar(\n",
    "            distances[area], \n",
    "            means[area], \n",
    "            yerr=errors[area], \n",
    "            fmt='o',\n",
    "            color='black', \n",
    "            mfc=color, \n",
    "            mec=color, \n",
    "            capsize=0.5,\n",
    "            capthick=0.5,\n",
    "            markersize=2, \n",
    "            elinewidth=0.5\n",
    "        )\n",
    "        # axes[1].errorbar(distances[area], means[area], yerr=errors[area], fmt='o', ecolor='black', mfc=color, mec=color, capsize=5)\n",
    "    ff.myPlotSettings_splitAxis(fig=what_plot, ax=axes[which_one], ytitle= '', xtitle='Distance (µm)', title='', mySize =font_size)\n",
    "axes[0].set_ylabel('Projection probability')\n",
    "axes[1].set_ylabel('Projection strength (mm$^{-3}$)')\n",
    "#axes[1].yaxis.set_major_formatter(FuncFormatter(lambda y, _: f'{y:.2f}'))\n",
    "axes[0].tick_params(labelbottom=True)\n",
    "convert_dict = ff.get_convert_dict()\n",
    "visual_legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', \n",
    "           label=convert_dict.get(area, area),  # Convert name using dictionary\n",
    "           markerfacecolor=color, markersize=3, linestyle='None')\n",
    "    for area, color in HVA_colors_updated.items()\n",
    "]\n",
    "\n",
    "fig.legend(handles=visual_legend_elements, loc='center left', bbox_to_anchor=(0.9, 0.5), fontsize=font_size, prop={'family': 'Arial'}, frameon =False)#since we have the fig legend in the other plots\n",
    "# visual_legend_elements = [\n",
    "#     Line2D([0], [0], marker='o', color='w', label=area, markerfacecolor=color, markersize=8, linestyle='None')\n",
    "#     for area, color in HVA_colors_updated.items()\n",
    "# ]\n",
    "\n",
    "# fig.legend(handles=visual_legend_elements, loc='center left', bbox_to_anchor=(1.01, 0.5), fontsize=10)\n",
    "\n",
    "for ax in axes:\n",
    "#     ax.legend(loc='upper right', fontsize=font_size,bbox_to_anchor=(1.5, 1.2),frameon=False)\n",
    "    #  ax.set_xlim(left=0)\n",
    "    ax.set_xticks([0, 2000, 4000])\n",
    "\n",
    "fig.savefig(f\"{saving_path}/fig2_dist_vs_proj.svg\", format=\"svg\")\n",
    "fig.savefig(f\"{saving_path}/fig2_dist_vs_proj.pdf\", format=\"pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the mean volume of ipsi cortical projections?\n",
    "volumes = []\n",
    "for mouse in mice:\n",
    "     lcm_dir =  pathlib.Path(\n",
    "    f\"{proj_path}/{mouse}/LCM\")\n",
    "     parameters_path = f'{proj_path}/{mouse}/Sequencing'\n",
    "     parameters = fpf.load_parameters(directory=parameters_path)\n",
    "     sample_vol_and_regions = pd.read_pickle(\n",
    "        lcm_dir / \"sample_vol_and_regions.pkl\"\n",
    "    )\n",
    "     ipsi_cortex = [sample for sample in parameters['cortical_samples'] if sample not in parameters['contra']]\n",
    "     which_table = sample_vol_and_regions[sample_vol_and_regions['ROI Number'].isin(ipsi_cortex)]\n",
    "\n",
    "     #vols = which_table['vol_in_atlas'].to_list()\n",
    "     vols = which_table['Volume (um^3)'].to_list()\n",
    "     volumes.extend(vols)\n",
    "mean_vol = np.mean(volumes)\n",
    "# SEM_micron = np.std(volumes)/np.sqrt(len(volumes))\n",
    "mean_vol_cubic_mm = mean_vol * 1e-9\n",
    "SD_mm= (np.std(volumes))* 1e-9\n",
    "print(f'mean vol = {mean_vol_cubic_mm} mm3 +- {SD_mm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouse = 'FIAA55.4d'\n",
    "# parameters_path = pathlib.Path(f\"/camp/lab/znamenskiyp/home/shared/projects/turnerb_A1_MAPseq/{mouse}/Sequencing\")\n",
    "# parameters = ps.load_parameters(directory=str(parameters_path))\n",
    "# sample_vol_path = parameters['lcm_directory']+'/sample_vol_and_regions.pkl'\n",
    "# fpf.get_main_region(sample_vol=sample_vol_path, parameters_path= str(parameters_path), use_slurm=True, slurm_folder=\"/camp/home/turnerb/slurm_logs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
